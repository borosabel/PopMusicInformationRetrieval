{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T16:59:49.814027Z",
     "start_time": "2024-10-14T16:59:49.805343Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:59:50.338019Z",
     "start_time": "2024-10-14T16:59:50.325457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import random\n",
    "import torch as th\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "30ec1e4f3c907ee3",
   "execution_count": 82,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.373730Z",
     "start_time": "2024-10-14T16:00:20.371457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # This cell is only intented to create a subset of data so I can present it effectively without needing to wait too much on testing.\n",
    "#\n",
    "# # SAMPLE GUNSHOT DATASET\n",
    "# # Load the gunshot DataFrame\n",
    "# gunshot_df = pd.read_csv('./filtered_gunshot_metadata_glocks.csv')\n",
    "# gunshot_df = gunshot_df[['filename', 'gunshot_location_in_seconds', 'num_gunshots']]\n",
    "#\n",
    "# gunshot_df['gunshot_location_in_seconds'] = gunshot_df['gunshot_location_in_seconds'].apply(\n",
    "#     lambda x: utils.preprocess_gunshot_times(x, include_first_gunshot_only=True)\n",
    "# ).tolist()\n",
    "#\n",
    "# sampled_gunshot_df = gunshot_df.sample(n=100, random_state=42)\n",
    "# destination_directory = './selected_gunshots'\n",
    "# os.makedirs(destination_directory, exist_ok=True)\n",
    "# new_paths = []\n",
    "#\n",
    "# for path in sampled_gunshot_df['filename']:\n",
    "#     filename = os.path.basename(path)\n",
    "#     destination_path = os.path.join(destination_directory, filename)\n",
    "#     shutil.copy(path, destination_path)\n",
    "#     new_paths.append(destination_path)\n",
    "#\n",
    "# sampled_gunshot_df['filename'] = new_paths\n",
    "# sampled_gunshot_df.to_pickle('./sampled_gunshot_metadata.pkl')\n",
    "#\n",
    "# # SAMPLE MUSIC DATASET\n",
    "# # Load the music DataFrame\n",
    "# music_df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data_w_topics_w_features.xlsx', engine='openpyxl')\n",
    "# music_df = music_df[['Path', 'Sample Rate (Hz)']]\n",
    "# sampled_music_df = music_df.sample(n=100, random_state=42)\n",
    "# destination_directory = './selected_music'\n",
    "# os.makedirs(destination_directory, exist_ok=True)\n",
    "# new_music_paths = []\n",
    "#\n",
    "# for path in sampled_music_df['Path']:\n",
    "#     filename = os.path.basename(path)\n",
    "#     destination_path = os.path.join(destination_directory, filename)\n",
    "#     shutil.copy(path, destination_path)\n",
    "#     new_music_paths.append(destination_path)\n",
    "#\n",
    "# sampled_music_df['Path'] = new_music_paths\n",
    "# sampled_music_df.to_pickle('./sampled_music_metadata.pkl')"
   ],
   "id": "c2fea9d844a71b65",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.387649Z",
     "start_time": "2024-10-14T16:00:20.374862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_df = pd.read_pickle('./sampled_gunshot_metadata.pkl')\n",
    "gunshot_df = gunshot_df[['filename', 'gunshot_location_in_seconds', 'num_gunshots']]\n",
    "gunshot_df.head()"
   ],
   "id": "248141f128afd6c",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.392899Z",
     "start_time": "2024-10-14T16:00:20.388300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_df = pd.read_pickle('./sampled_music_metadata.pkl')\n",
    "music_df = music_df[['Path', 'Sample Rate (Hz)']]\n",
    "music_df.head()"
   ],
   "id": "ef62985a0a1d1027",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>At this point we have two dataframes with 100-100 audio files, one contains the gunshots and the other contains the musical pieces</b>",
   "id": "bc3b36b2dabc91ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.397383Z",
     "start_time": "2024-10-14T16:00:20.393885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_train_df, music_valid_df = train_test_split(music_df, test_size=0.2, random_state=42)\n",
    "gunshot_train_df, gunshot_valid_df = train_test_split(gunshot_df, test_size=0.2, random_state=42)"
   ],
   "id": "85913fb23cc8e10d",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.400175Z",
     "start_time": "2024-10-14T16:00:20.397961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"SHAPES:\")\n",
    "print(f\"music_train_df: {music_train_df.shape}, music_valid_df: {music_valid_df.shape}\")\n",
    "print(f\"gunshot_train_df: {gunshot_train_df.shape}, gunshot_valid_df: {gunshot_valid_df.shape}\")"
   ],
   "id": "fd77120151060515",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:20.763552Z",
     "start_time": "2024-10-14T16:00:20.728039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames) \n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "375039e3f516b75b",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:21.295812Z",
     "start_time": "2024-10-14T16:00:21.289661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, music_df, gunshot_df, excerpt_len=5.0, gunshot_placement_sec=2.0, gunshot_prob=1.0, min_db=3, max_db=5, max_non_gunshot_samples=1, mean=None, std=None):\n",
    "        \"\"\"\n",
    "        :param music_df: DataFrame containing paths to music files.\n",
    "        :param gunshot_df: DataFrame containing paths to gunshot files and timing info.\n",
    "        :param excerpt_len: Length of the music segment in seconds.\n",
    "        :param gunshot_placement_sec: Time in seconds where to place the gunshot in the music.\n",
    "        :param gunshot_prob: Probability of adding a gunshot to the segment.\n",
    "        :param min_db: Minimum gain (in dB) to apply to the gunshot.\n",
    "        :param max_db: Maximum gain (in dB) to apply to the gunshot.\n",
    "        :param max_non_gunshot_samples: Max number of non-gunshot samples to extract when no gunshots are present.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.music_paths = music_df['Path'].tolist()\n",
    "        self.gunshot_paths = gunshot_df['filename'].tolist()\n",
    "        self.gunshot_truth = gunshot_df['gunshot_location_in_seconds'].tolist()\n",
    "        self.excerpt_len = excerpt_len\n",
    "        self.gunshot_placement_sec = gunshot_placement_sec\n",
    "        self.gunshot_prob = gunshot_prob\n",
    "        self.min_db = min_db\n",
    "        self.max_db = max_db\n",
    "        self.max_non_gunshot_samples = max_non_gunshot_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn_music = self.music_paths[idx]\n",
    "        add_gunshot = (np.random.rand() < self.gunshot_prob)\n",
    "\n",
    "        if add_gunshot:\n",
    "            gunshot_idx = np.random.randint(0, len(self.gunshot_paths) - 1)\n",
    "            fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "            gunshot_times = self.gunshot_truth[gunshot_idx][0]\n",
    "            \n",
    "            music_segment, sr = utils.combine_music_and_gunshot(\n",
    "                music_file=fn_music,\n",
    "                gunshot_file=fn_gunshot,\n",
    "                gunshot_time=gunshot_times,\n",
    "                gunshot_volume_increase_dB=self.max_db,\n",
    "                gunshot_placement_sec=self.gunshot_placement_sec,\n",
    "                excerpt_len_sec=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 1\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label, gunshot_placement_sec)\n",
    "        else:\n",
    "            music_segment, sr = utils.extract_music_segment(\n",
    "                music_file=fn_music,\n",
    "                excerpt_len=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 0\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label)\n",
    "\n",
    "        if not spectrograms or not labels:\n",
    "            raise ValueError(\"Spectrograms or labels are empty after preprocessing\")\n",
    "\n",
    "        return spectrograms[0], labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.music_paths)"
   ],
   "id": "18971f1c1625f911",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>When we use the GunshotDataset which contains preprocessing the audio, preprocessing the gunshot sound, below I will cut out codes from the utility functions just to show what kind of data we have during the intermediate steps.</b>",
   "id": "5504eaac422630f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:27.187749Z",
     "start_time": "2024-10-14T16:00:22.105851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_waveform, sr = torchaudio.load(music_df.iloc[0]['Path'])\n",
    "if sr != utils.SAMPLING_RATE:\n",
    "    print(f\"Resampling music from {sr} Hz to {utils.SAMPLING_RATE} Hz. \\n\")\n",
    "    music_waveform = torchaudio.transforms.Resample(sr, utils.SAMPLING_RATE)(music_waveform)\n",
    "\n",
    "excerpt_len_sec = 5\n",
    "excerpt_len_samples = int(excerpt_len_sec * utils.SAMPLING_RATE)\n",
    "total_music_samples = music_waveform.size(1)\n",
    "max_start_sample = max(0, total_music_samples - excerpt_len_samples)\n",
    "start_pos_music = random.randint(0, max_start_sample)\n",
    "music_segment = music_waveform[:, start_pos_music:start_pos_music + excerpt_len_samples]\n",
    "utils.play_audio(music_segment, sr)"
   ],
   "id": "6eb9e38d7f298e52",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:38.321338Z",
     "start_time": "2024-10-14T16:00:37.757075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_filename = gunshot_df.iloc[1]['filename']\n",
    "gunshot_time = gunshot_df.iloc[0]['gunshot_location_in_seconds']\n",
    "pre_gunshot_time = 0.5\n",
    "\n",
    "# First we play the nomral gunshot file\n",
    "gunshot_waveform, sr_gunshot = torchaudio.load(gunshot_df.iloc[0]['filename'])\n",
    "\n",
    "if sr_gunshot != utils.SAMPLING_RATE:\n",
    "    print(f\"Resampling gunshot from {sr_gunshot} Hz to {utils.SAMPLING_RATE} Hz.\\n\")\n",
    "    gunshot_waveform = torchaudio.transforms.Resample(sr_gunshot, utils.SAMPLING_RATE)(gunshot_waveform)\n",
    "\n",
    "# Here we just set the gunshot audio so it won't start too later than 0.5 so we can just take it, overlay on the music audio and then we know that it if we take\n",
    "# frame size which is over than 0.5 seconds the gunshot will be there somewhere\n",
    "gunshot_start_sample = int((gunshot_time[0] - pre_gunshot_time) * utils.SAMPLING_RATE)\n",
    "gunshot_segment = gunshot_waveform[:, gunshot_start_sample:]\n",
    "\n",
    "utils.play_audio(gunshot_segment, sr)"
   ],
   "id": "e2f3a5e21dad5ac4",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:38.797606Z",
     "start_time": "2024-10-14T16:00:38.794874Z"
    }
   },
   "cell_type": "code",
   "source": "assert utils.SAMPLING_RATE == sr_gunshot, f\"Expected sample rate: {utils.SAMPLING_RATE}, but got: {sr_gunshot}\"",
   "id": "273dc35a1b4c5e01",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:45.588759Z",
     "start_time": "2024-10-14T16:00:39.659563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_placement_sec = 2\n",
    "gunshot_placement_sample = int(gunshot_placement_sec * utils.SAMPLING_RATE)\n",
    "combined_segment = music_segment.clone()\n",
    "combined_segment[:, gunshot_placement_sample:gunshot_placement_sample + gunshot_segment.size(1)] += gunshot_segment\n",
    "\n",
    "# Vertical line at the point where the gunshot fires\n",
    "utils.plot_waveform(combined_segment, utils.SAMPLING_RATE, vertical_lines=[2])\n",
    "\n",
    "utils.play_audio(combined_segment, utils.SAMPLING_RATE)"
   ],
   "id": "5c5cec107037b54b",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Now we show you steps during processing this new audio we just computed above</b>",
   "id": "ac8e1e44a53ed2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:47.161769Z",
     "start_time": "2024-10-14T16:00:47.159445Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Currently we have a 5 second audio with shapes: {combined_segment.shape}\")",
   "id": "a627834d86cc1c21",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:49.225203Z",
     "start_time": "2024-10-14T16:00:48.082095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "segment = utils.select_gunshot_segment(combined_segment, utils.SAMPLING_RATE, 1.5)\n",
    "utils.play_audio(segment, utils.SAMPLING_RATE)"
   ],
   "id": "c13c4c07da0a960",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:54.442747Z",
     "start_time": "2024-10-14T16:00:53.503900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mel_specgram = utils.calculate_melbands(segment[0], utils.SAMPLING_RATE)\n",
    "print(mel_specgram.shape)"
   ],
   "id": "9d1d50c1f5a3b8da",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:00:58.542553Z",
     "start_time": "2024-10-14T16:00:58.538777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = GunshotDataset(music_train_df, gunshot_train_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=0.5)\n",
    "valid_dataset = GunshotDataset(music_valid_df, gunshot_valid_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=0.5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "bfd4750fea8bf572",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:01:24.873556Z",
     "start_time": "2024-10-14T16:01:01.933556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean, std = utils.compute_mean_std(train_loader)\n",
    "mean = mean.to(device)\n",
    "std = std.to(device)"
   ],
   "id": "6e0c05f63a21d839",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:06:06.665772Z",
     "start_time": "2024-10-14T16:01:46.240547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2\n",
    "lr = 3e-4\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = th.nn.BCELoss()\n",
    "\n",
    "best_threshold, best_score = utils.train_model(\n",
    "    model, optimizer, criterion, train_loader, valid_loader,\n",
    "    epochs=10, mean=mean, std=std, patience=3\n",
    ")\n",
    "\n",
    "print(f\"Training completed. Best ROC AUC: {best_score:.4f}, Optimal Threshold: {best_threshold:.4f}\")"
   ],
   "id": "ef962832158050cd",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:32:13.267191Z",
     "start_time": "2024-10-14T16:32:13.258298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def manual_evaluate_test(model, feature, threshold, frame_size=utils.NUM_FRAMES, sampling_rate=utils.SAMPLING_RATE, hop_length=utils.HOP_LENGTH, mean=None, std=None, step_size=None, filter_time_sec=1):\n",
    "    \"\"\"\n",
    "    Manually evaluate the model on an audio feature, returning time positions where gunshots are detected.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model.\n",
    "        feature: The feature (e.g., spectrogram) to evaluate.\n",
    "        threshold: The prediction threshold for gunshots.\n",
    "        frame_size: Number of frames to use in each evaluation.\n",
    "        sampling_rate: Audio sampling rate.\n",
    "        hop_length: Hop length in samples for each frame.\n",
    "        mean: Mean for normalization.\n",
    "        std: Standard deviation for normalization.\n",
    "        step_size: Step size for moving through frames (default: frame_size // 2).\n",
    "        filter_time_sec: Time (in seconds) to filter out close consecutive predictions.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (minutes, seconds, output) where gunshots are detected along with the model's output.\n",
    "    \"\"\"\n",
    "    if mean is None or std is None:\n",
    "        raise ValueError(\"Mean and std must be provided for normalization.\")\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    feature = feature.to(device)\n",
    "    feature = (feature - mean) / std\n",
    "\n",
    "    num_frames = feature.shape[2]\n",
    "\n",
    "    if step_size is None:\n",
    "        step_size = 1\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for j in range(0, num_frames - frame_size + 1, step_size):\n",
    "            total_iterations += 1\n",
    "            start = j\n",
    "            end = j + frame_size\n",
    "\n",
    "            input_frame = feature[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().item()\n",
    "            predictions.append((output, start))\n",
    "    \n",
    "        print(\"Number of predictions\", len(predictions))\n",
    "        \n",
    "        res = []\n",
    "        for output, start in predictions:\n",
    "            if output >= threshold:\n",
    "                time_in_seconds = start * hop_length / sampling_rate\n",
    "                minutes = int(time_in_seconds // 60)\n",
    "                seconds = time_in_seconds % 60\n",
    "                res.append((minutes, seconds, time_in_seconds, output))\n",
    "                \n",
    "        print(\"Number of results after comapring against the threshold:\", len(res))\n",
    "        \n",
    "    filtered_res = []\n",
    "    last_detection_time = -float('inf')\n",
    "\n",
    "    for minutes, seconds, time_in_seconds, output in res:\n",
    "        if time_in_seconds - last_detection_time >= filter_time_sec:\n",
    "            filtered_res.append((minutes, seconds, output))\n",
    "            last_detection_time = time_in_seconds\n",
    "\n",
    "    return filtered_res"
   ],
   "id": "ea86cce6c341bad9",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:32:29.868235Z",
     "start_time": "2024-10-14T16:32:14.310197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['/Users/borosabel/Documents/Uni/Thesis/PopMIR/M.I.A. - Paper Planes.mp3'])\n",
    "\n",
    "print(f\"Got back spectogram in shape: {spectrograms[0].shape} and sample rate: {sample_rates}\")\n",
    "\n",
    "predictions = manual_evaluate_test(model, spectrograms[0], threshold=best_threshold, mean=mean, std=std, step_size=1,\n",
    "                                   filter_time_sec=1.5)\n",
    "\n",
    "if(len(predictions) > 0):\n",
    "    print(f\"Current treshold is {best_threshold} \\n\")\n",
    "    \n",
    "    for minutes, seconds, output in predictions:\n",
    "        print(f\"Detected gunshot at {minutes}m {seconds:.2f}s with model output: {output:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions\")"
   ],
   "id": "d52be314e2a0f275",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>This is for manual checking</b>",
   "id": "2b634f052a76b536"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:38:25.867508Z",
     "start_time": "2024-10-14T16:38:23.869169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_and_predict(model, audio_path, start_time_sec, mean, std, threshold=best_threshold):\n",
    "\n",
    "    # Extract the waveform and the audio sample\n",
    "    waveform, sample, sample_rate = utils.extract_sample_at_time(audio_path, start_time_sec)\n",
    "\n",
    "    print(f\"Playing the audio sample from {start_time_sec:.2f} seconds.\")\n",
    "    play(sample)\n",
    "\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    model = model.to(device)\n",
    "    waveform = waveform.to(device)\n",
    "\n",
    "    mel_spectrogram = utils.calculate_melbands(waveform[0], sample_rate)\n",
    "    mel_spectrogram = (mel_spectrogram - mean) / std\n",
    "\n",
    "    # Reshape and feed to model\n",
    "    with th.no_grad():\n",
    "        input_tensor = mel_spectrogram.unsqueeze(0).float()\n",
    "        output = model(input_tensor).squeeze().item()\n",
    "\n",
    "    if output >= threshold:\n",
    "        prediction = \"Gunshot\"\n",
    "    else:\n",
    "        prediction = \"No Gunshot\"\n",
    "\n",
    "    print(f\"Model Prediction: {prediction} with output: {output}\")\n",
    "    return prediction\n",
    "\n",
    "audio_path = './M.I.A. - Paper Planes.mp3'\n",
    "# audio_path = '''./2Pac - Hit 'Em Up (Dirty) (Music Video) HD.mp3'''\n",
    "# audio_path = './50 Cent - Many Men (Wish Death) (Dirty Version).mp3'\n",
    "\n",
    "prediction = process_and_predict(model, audio_path, start_time_sec=44.4, mean=mean, std=std)"
   ],
   "id": "f6829671136a676d",
   "execution_count": 76,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "27636f58225dd367",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
