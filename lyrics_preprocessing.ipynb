{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:40.197022Z",
     "start_time": "2024-10-22T18:38:39.666292Z"
    }
   },
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "data = '/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/test.json'"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:40.372789Z",
     "start_time": "2024-10-22T18:38:40.198196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data.xlsx', engine='openpyxl')\n",
    "df.head()"
   ],
   "id": "678b38e814fb785c",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.851436Z",
     "start_time": "2024-10-22T18:38:40.373467Z"
    }
   },
   "cell_type": "code",
   "source": "df[['Tokens', 'Processed_Lyrics']] = df['Lyrics'].apply(lambda x: pd.Series(utils.cleanup(x)))",
   "id": "f07f9589568220a6",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.916773Z",
     "start_time": "2024-10-22T18:38:55.853522Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_df = utils.filter_tokens_by_document_frequency(df, column_name='Tokens', min_doc_frequency=0.03, max_doc_frequency=0.85)",
   "id": "2d38bbd5711284b6",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.926622Z",
     "start_time": "2024-10-22T18:38:55.917548Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "581a6536a3905dfa",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.960467Z",
     "start_time": "2024-10-22T18:38:55.927418Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_pickle('preprocessed_df.pkl')",
   "id": "debbb2855c8bff69",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.993932Z",
     "start_time": "2024-10-22T18:38:55.961424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_unique_tokens(tokens_list, output_file_path):\n",
    "    # Flatten the list of tokens (if you have multiple documents)\n",
    "    all_tokens = [token for tokens in tokens_list for token in tokens]\n",
    "\n",
    "    # Get unique tokens\n",
    "    unique_tokens = sorted(set(all_tokens))  # Sorted for easier review\n",
    "\n",
    "    # Write unique tokens to a file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        for token in unique_tokens:\n",
    "            file.write(f\"{token}\\n\")\n",
    "\n",
    "list_of_unique_tokens = list(df['Tokens'])\n",
    "save_unique_tokens(list_of_unique_tokens, \"unique_tokens.txt\")"
   ],
   "id": "7f0749662e142c31",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:38:55.998304Z",
     "start_time": "2024-10-22T18:38:55.995187Z"
    }
   },
   "cell_type": "code",
   "source": "len(list_of_unique_tokens)",
   "id": "8d1be56a77efb04e",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Statistics</b>",
   "id": "5e38271e7dc9be24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:31:28.687109Z",
     "start_time": "2024-10-22T18:31:28.328556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming df is your dataframe that contains the 'Tokens' column with lists of strings (tokens)\n",
    "# Example:\n",
    "# df = pd.read_csv('your_lyrics_data.csv')\n",
    "\n",
    "# Step 1: Flatten all the tokens from the 'Tokens' column into a single list\n",
    "all_tokens = [token for tokens_list in df['Tokens'] for token in tokens_list]\n",
    "\n",
    "# Step 2: Count the frequency of each token using Counter\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "# Step 3: Convert the counts to a DataFrame\n",
    "token_counts_df = pd.DataFrame(token_counts.items(), columns=['Word', 'Count'])\n",
    "\n",
    "# Step 4: Sort the words by frequency in descending order and get the top N words\n",
    "top_n = 20  # You can change this to however many words you want to see\n",
    "token_counts_df = token_counts_df.sort_values(by='Count', ascending=False).head(top_n)\n",
    "\n",
    "# Step 5: Plot the most used words and their counts using Seaborn\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns_barplot = sns.barplot(x='Count', y='Word', data=token_counts_df, palette='crest')  # Using Seaborn's palette\n",
    "\n",
    "# Step 6: Add frequency numbers on top of each bar\n",
    "for index, value in enumerate(token_counts_df['Count']):\n",
    "    plt.text(value + 1, index, str(value), color='black', va='center', fontsize=10)  # `+1` for slight space from bar\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.title(f'Top {top_n} Most Used Words in Lyrics')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Plots/word-frequency.png')\n",
    "plt.show()"
   ],
   "id": "1747af572f537b1c",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T18:31:15.609023Z",
     "start_time": "2024-10-22T18:31:14.380264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Combine all tokens into single text\n",
    "all_text = [' '.join(tokens) for tokens in df['Tokens']]\n",
    "\n",
    "# Use CountVectorizer to get bigrams and trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "X = vectorizer.fit_transform(all_text)\n",
    "\n",
    "# Get the top n-grams\n",
    "ngram_counts = X.sum(axis=0).A1\n",
    "ngram_names = vectorizer.get_feature_names_out()\n",
    "ngram_df = pd.DataFrame({'ngram': ngram_names, 'count': ngram_counts})\n",
    "ngram_df = ngram_df.sort_values(by='count', ascending=False).head(20)\n",
    "\n",
    "# Plot the top n-grams\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='count', y='ngram', data=ngram_df, palette='viridis')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('N-Grams')\n",
    "plt.savefig('./Plots/n-grams-frequency.png')\n",
    "plt.title('Top 20 Most Frequent Bigrams/Trigrams in Lyrics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "35efa2b2566b2085",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "56b715981e9fe9a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
