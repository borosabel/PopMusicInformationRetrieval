{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T14:51:23.789836Z",
     "start_time": "2024-10-13T14:51:23.335046Z"
    }
   },
   "source": [
    "import string\n",
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.sparse import dok_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "\n",
    "# Octis is the library which can use different implemented topic modelling techniques\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.models.LDA import LDA\n",
    "from octis.models.CTM import CTM\n",
    "from octis.models.ETM import ETM\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.models.NMF import NMF\n",
    "\n",
    "importlib.reload(utils)\n",
    "data = './preprocessed_df.pkl'"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_pickle(data)\n",
    "df[['Artist', 'Song', 'Tokens', 'Lyrics', 'Coast']].head()"
   ],
   "id": "93f27912d1cc82c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the corpus required by OCTIS to build up the dataset\n",
    "with open('corpus.tsv', 'w', encoding='utf-8') as file:\n",
    "    for lyrics in df['Lyrics']:\n",
    "        if pd.notna(lyrics):\n",
    "            file.write(lyrics + '\\n')"
   ],
   "id": "197d2eab0e57aef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Flatten all tokens to create a single list of words\n",
    "vocab = set(chain.from_iterable(df['Tokens'].tolist()))\n",
    "\n",
    "# Save as vocabulary.json\n",
    "with open(\"./vocabulary.json\", 'w') as f:\n",
    "    json.dump(list(vocab), f)"
   ],
   "id": "b66e5c9fe5e4a722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the document-term matrix\n",
    "num_docs = len(df)\n",
    "num_terms = len(vocab)\n",
    "doc_term_matrix = dok_matrix((num_docs, num_terms), dtype=np.int32)\n",
    "\n",
    "# Build the matrix\n",
    "token_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "for doc_idx, tokens in enumerate(df['Tokens']):\n",
    "    for token in tokens:\n",
    "        if token in token_to_index:\n",
    "            word_idx = token_to_index[token]\n",
    "            doc_term_matrix[doc_idx, word_idx] += 1\n",
    "\n",
    "# Convert the matrix to a sparse format JSON\n",
    "sparse_matrix = []\n",
    "for (doc_idx, word_idx), freq in doc_term_matrix.items():\n",
    "    sparse_matrix.append([doc_idx, word_idx, int(freq)])\n",
    "\n",
    "# Save as doc_term_matrix.json\n",
    "with open(\"./doc_term_matrix.json\", 'w') as f:\n",
    "    json.dump(sparse_matrix, f)"
   ],
   "id": "5fa354b7af283132",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize preprocessing\n",
    "preprocessor = Preprocessing(\n",
    "    vocabulary=None,\n",
    "    max_features=None,\n",
    "    remove_punctuation=True,\n",
    "    punctuation=string.punctuation,\n",
    "    lemmatize=True,\n",
    "    min_chars=2,\n",
    "    min_words_docs=0,\n",
    "    save_original_indexes=True,\n",
    "    min_df=0.05,\n",
    "    max_df=0.8,\n",
    "    split=True\n",
    ")\n",
    "\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=\"./corpus.tsv\")"
   ],
   "id": "51b8dacd377937e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:39:27.046309Z",
     "start_time": "2024-10-13T14:39:22.652694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "\n",
    "# Initialize the coherence and diversity metrics\n",
    "coherence_cv = Coherence(topk=10, measure='c_v')\n",
    "coherence_umass = Coherence(topk=10, measure='u_mass')\n",
    "topic_diversity = TopicDiversity(topk=10)"
   ],
   "id": "e32ab34c87baa12c",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:54:05.559596Z",
     "start_time": "2024-10-13T14:54:05.550135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    'LDA': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'iterations': [500, 1000],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'CTM': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [5, 10],\n",
    "    },\n",
    "    'ETM': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [50, 100],\n",
    "    },\n",
    "    'NeuralLDA': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [50, 100],\n",
    "        'lr': [2e-3, 1e-3],\n",
    "    },\n",
    "    'NMF': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "def evaluate_coherence(model_output):\n",
    "    # Initialize the coherence metric\n",
    "    coherence_cv = Coherence(topk=10, measure='c_v')\n",
    "\n",
    "    # Calculate and return coherence score\n",
    "    coherence_score = coherence_cv.score(model_output)\n",
    "    return coherence_score\n",
    "\n",
    "def parameter_search(model_name, dataset, param_grid):\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_score = -float('inf')\n",
    "    best_params = None\n",
    "    best_model_output = None\n",
    "\n",
    "    # Use tqdm to track progress in parameter search\n",
    "    for params in tqdm(param_combinations, desc=f\"Searching {model_name} Params\"):\n",
    "        # Create parameter dict\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "\n",
    "        # Initialize and train the model based on model name and params\n",
    "        if model_name == 'LDA':\n",
    "            model = LDA(**param_dict)\n",
    "        elif model_name == 'CTM':\n",
    "            model = CTM(**param_dict)\n",
    "        elif model_name == 'ETM':\n",
    "            model = ETM(**param_dict)\n",
    "        elif model_name == 'NeuralLDA':\n",
    "            model = NeuralLDA(**param_dict)\n",
    "        elif model_name == 'NMF':\n",
    "            model = NMF(**param_dict)\n",
    "\n",
    "        # Train the model\n",
    "        model_output = model.train_model(dataset)\n",
    "\n",
    "        # Evaluate the model (e.g., using coherence score)\n",
    "        score = evaluate_coherence(model_output)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = param_dict\n",
    "            best_model_output = model_output\n",
    "\n",
    "    return best_model_output, best_params, best_score"
   ],
   "id": "cc12e975684d3e24",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:56:38.873498Z",
     "start_time": "2024-10-13T14:54:06.426308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_models = {}\n",
    "\n",
    "# Perform hyperparameter search for each model with progress bars\n",
    "for model_name, param_grid in tqdm(param_grids.items(), desc=\"Overall Model Parameter Search\"):\n",
    "    best_output, best_params, best_score = parameter_search(model_name, dataset, param_grid)\n",
    "    best_models[model_name] = {'output': best_output, 'params': best_params, 'score': best_score}\n",
    "    print(f\"Best {model_name} Params: {best_params} with Score: {best_score}\")"
   ],
   "id": "1f6c5676c3834fef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Model Parameter Search:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Searching LDA Params:   0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "Searching LDA Params:  12%|█▎        | 1/8 [00:07<00:53,  7.59s/it]\u001B[A\n",
      "Searching LDA Params:  25%|██▌       | 2/8 [00:16<00:48,  8.10s/it]\u001B[A\n",
      "Searching LDA Params:  38%|███▊      | 3/8 [00:22<00:36,  7.32s/it]\u001B[A\n",
      "Searching LDA Params:  50%|█████     | 4/8 [00:29<00:29,  7.41s/it]\u001B[A\n",
      "Searching LDA Params:  62%|██████▎   | 5/8 [00:35<00:20,  6.74s/it]\u001B[A\n",
      "Searching LDA Params:  75%|███████▌  | 6/8 [00:41<00:13,  6.60s/it]\u001B[A\n",
      "Searching LDA Params:  88%|████████▊ | 7/8 [00:47<00:06,  6.23s/it]\u001B[A\n",
      "Searching LDA Params: 100%|██████████| 8/8 [00:53<00:00,  6.72s/it]\u001B[A\n",
      "Overall Model Parameter Search:  20%|██        | 1/5 [00:53<03:34, 53.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LDA Params: {'num_topics': 2, 'iterations': 500, 'random_state': 42} with Score: 0.6017872659552621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching CTM Params:   0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "Searching CTM Params:  12%|█▎        | 1/8 [00:01<00:11,  1.70s/it]\u001B[A\n",
      "Searching CTM Params:  25%|██▌       | 2/8 [00:03<00:10,  1.68s/it]\u001B[A\n",
      "Searching CTM Params:  38%|███▊      | 3/8 [00:05<00:08,  1.72s/it]\u001B[A\n",
      "Searching CTM Params:  50%|█████     | 4/8 [00:07<00:07,  1.85s/it]\u001B[A\n",
      "Searching CTM Params:  62%|██████▎   | 5/8 [00:09<00:05,  1.85s/it]\u001B[A\n",
      "Searching CTM Params:  75%|███████▌  | 6/8 [00:10<00:03,  1.89s/it]\u001B[A\n",
      "Searching CTM Params:  88%|████████▊ | 7/8 [00:12<00:01,  1.93s/it]\u001B[A\n",
      "Searching CTM Params: 100%|██████████| 8/8 [00:14<00:00,  1.87s/it]\u001B[A\n",
      "Overall Model Parameter Search:  40%|████      | 2/5 [01:08<01:32, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CTM Params: {'num_topics': 3, 'num_epochs': 5} with Score: 0.6173094858246226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:   0%|          | 0/8 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=2, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=2, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=2, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 1111.18 .. NELBO: 1111.38\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.07 .. Rec_loss: 277.77 .. NELBO: 277.84\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1153.020996).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 1064.37 .. NELBO: 1064.53\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.55 .. NELBO: 272.55\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1153.020996 --> 1130.761597).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.46 .. Rec_loss: 1054.44 .. NELBO: 1054.9\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 271.04 .. NELBO: 271.21\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1130.761597 --> 1124.830811).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 1051.89 .. NELBO: 1052.09\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.15 .. NELBO: 271.15\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.830811 --> 1124.744263).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1051.04 .. NELBO: 1051.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.91 .. NELBO: 270.91\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.744263 --> 1124.055420).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1050.41 .. NELBO: 1050.43\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.81 .. NELBO: 270.81\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.055420 --> 1123.601318).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.22 .. NELBO: 1050.23\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.77 .. NELBO: 270.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.601318 --> 1123.278076).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.24 .. NELBO: 1050.24\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.14 .. NELBO: 1050.15\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.13 .. NELBO: 1050.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 1050.02 .. NELBO: 1050.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 270.73 .. NELBO: 270.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.278076 --> 1123.174561).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 1049.74 .. NELBO: 1049.87\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 270.6 .. NELBO: 270.64\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.174561 --> 1122.709839).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 1049.29 .. NELBO: 1049.61\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 270.33 .. NELBO: 270.44\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.709839 --> 1121.919556).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 0.68 .. Rec_loss: 1048.13 .. NELBO: 1048.81\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 269.97 .. NELBO: 270.14\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1121.919556 --> 1120.583496).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 0.94 .. Rec_loss: 1046.41 .. NELBO: 1047.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.23 .. Rec_loss: 269.39 .. NELBO: 269.62\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1120.583496 --> 1118.093384).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 1.33 .. Rec_loss: 1044.46 .. NELBO: 1045.79\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 268.86 .. NELBO: 269.19\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1118.093384 --> 1115.997437).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 1042.95 .. NELBO: 1044.48\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.34 .. Rec_loss: 268.71 .. NELBO: 269.05\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.997437 --> 1115.291260).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 1042.26 .. NELBO: 1043.78\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.46 .. Rec_loss: 268.67 .. NELBO: 269.13\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 1.79 .. Rec_loss: 1041.66 .. NELBO: 1043.45\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.36 .. Rec_loss: 268.53 .. NELBO: 268.89\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.291260 --> 1114.223267).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 1041.14 .. NELBO: 1042.82\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 268.55 .. NELBO: 268.97\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 1041.36 .. NELBO: 1043.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 268.52 .. NELBO: 268.84\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.223267 --> 1113.988281).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 1.73 .. Rec_loss: 1041.32 .. NELBO: 1043.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 268.51 .. NELBO: 268.98\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 1.85 .. Rec_loss: 1041.01 .. NELBO: 1042.86\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 268.64 .. NELBO: 268.96\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 1.42 .. Rec_loss: 1041.65 .. NELBO: 1043.07\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.54 .. NELBO: 268.91\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 1.79 .. Rec_loss: 1040.76 .. NELBO: 1042.55\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 268.39 .. NELBO: 268.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.988281 --> 1113.595947).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 1.51 .. Rec_loss: 1040.87 .. NELBO: 1042.38\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 268.5 .. NELBO: 268.85\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 1.57 .. Rec_loss: 1040.67 .. NELBO: 1042.24\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 268.35 .. NELBO: 268.7\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.595947 --> 1113.134277).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 1040.52 .. NELBO: 1042.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 268.32 .. NELBO: 268.7\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 1.74 .. Rec_loss: 1040.18 .. NELBO: 1041.92\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.31 .. NELBO: 268.72\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 1.82 .. Rec_loss: 1040.13 .. NELBO: 1041.95\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.31 .. NELBO: 268.7\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 1040.27 .. NELBO: 1041.9\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.31 .. NELBO: 268.72\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 1.75 .. Rec_loss: 1039.98 .. NELBO: 1041.73\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.32 .. NELBO: 268.69\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  12%|█▎        | 1/8 [00:04<00:29,  4.22s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=2, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=2, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=2, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1111.96 .. NELBO: 1111.97\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 278.08 .. NELBO: 278.08\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1154.131348).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1064.79 .. NELBO: 1064.8\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.78 .. NELBO: 272.78\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1154.131348 --> 1131.745972).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 1055.17 .. NELBO: 1055.3\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 271.07 .. NELBO: 271.08\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.745972 --> 1124.213623).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1051.85 .. NELBO: 1051.94\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 271.16 .. NELBO: 271.25\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 1050.5 .. NELBO: 1050.87\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 270.61 .. NELBO: 270.72\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.213623 --> 1123.178955).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 1049.21 .. NELBO: 1049.77\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 270.34 .. NELBO: 270.49\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.178955 --> 1122.127808).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 1048.26 .. NELBO: 1049.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 269.98 .. NELBO: 270.16\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.127808 --> 1120.478882).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.93 .. Rec_loss: 1047.13 .. NELBO: 1048.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.3 .. Rec_loss: 269.71 .. NELBO: 270.01\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1120.478882 --> 1119.573120).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 1045.87 .. NELBO: 1047.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.27 .. Rec_loss: 269.42 .. NELBO: 269.69\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1119.573120 --> 1118.000000).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 1.3 .. Rec_loss: 1044.59 .. NELBO: 1045.89\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.97 .. NELBO: 269.36\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1118.000000 --> 1116.441772).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 1.35 .. Rec_loss: 1043.45 .. NELBO: 1044.8\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 268.87 .. NELBO: 269.2\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1116.441772 --> 1115.773682).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 1042.66 .. NELBO: 1044.29\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.36 .. Rec_loss: 268.74 .. NELBO: 269.1\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.773682 --> 1115.386353).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 1.61 .. Rec_loss: 1042.08 .. NELBO: 1043.69\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 268.61 .. NELBO: 269.09\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 1.54 .. Rec_loss: 1041.79 .. NELBO: 1043.33\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.57 .. NELBO: 268.97\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.386353 --> 1114.862061).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 1.76 .. Rec_loss: 1041.29 .. NELBO: 1043.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 268.52 .. NELBO: 268.9\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.862061 --> 1114.510132).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 1040.9 .. NELBO: 1042.55\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.52 .. Rec_loss: 268.48 .. NELBO: 269.0\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 1040.88 .. NELBO: 1042.59\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.46 .. Rec_loss: 268.46 .. NELBO: 268.92\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.510132 --> 1114.184937).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 1.81 .. Rec_loss: 1040.72 .. NELBO: 1042.53\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 268.65 .. NELBO: 269.24\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 1041.03 .. NELBO: 1042.65\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.46 .. NELBO: 268.87\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.184937 --> 1114.073364).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 1.75 .. Rec_loss: 1040.62 .. NELBO: 1042.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.44 .. NELBO: 268.84\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.073364 --> 1114.055176).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 1.8 .. Rec_loss: 1040.19 .. NELBO: 1041.99\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.52 .. NELBO: 268.89\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 1040.29 .. NELBO: 1042.0\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.33 .. NELBO: 268.73\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.055176 --> 1113.493164).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 1039.87 .. NELBO: 1041.58\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.46 .. Rec_loss: 268.28 .. NELBO: 268.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.493164 --> 1113.373779).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 1039.92 .. NELBO: 1041.64\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.43 .. Rec_loss: 268.3 .. NELBO: 268.73\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.373779 --> 1113.368408).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 1.87 .. Rec_loss: 1039.57 .. NELBO: 1041.44\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.43 .. Rec_loss: 268.3 .. NELBO: 268.73\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 1.8 .. Rec_loss: 1039.62 .. NELBO: 1041.42\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.3 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 1.82 .. Rec_loss: 1039.63 .. NELBO: 1041.45\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.35 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 1.87 .. Rec_loss: 1039.62 .. NELBO: 1041.49\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.3 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 1.82 .. Rec_loss: 1039.58 .. NELBO: 1041.4\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.43 .. Rec_loss: 268.31 .. NELBO: 268.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.368408 --> 1113.348877).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 1.84 .. Rec_loss: 1039.55 .. NELBO: 1041.39\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 268.27 .. NELBO: 268.69\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.348877 --> 1113.146240).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 1.84 .. Rec_loss: 1039.63 .. NELBO: 1041.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.5 .. Rec_loss: 268.25 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 1.82 .. Rec_loss: 1039.52 .. NELBO: 1041.34\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.43 .. Rec_loss: 268.31 .. NELBO: 268.74\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 1.78 .. Rec_loss: 1039.83 .. NELBO: 1041.61\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.51 .. Rec_loss: 268.24 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 2.03 .. Rec_loss: 1039.34 .. NELBO: 1041.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.3 .. NELBO: 268.67\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.146240 --> 1113.093018).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 1.78 .. Rec_loss: 1039.68 .. NELBO: 1041.46\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 268.25 .. NELBO: 268.73\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 1.8 .. Rec_loss: 1039.61 .. NELBO: 1041.41\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.23 .. NELBO: 268.68\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.093018 --> 1113.055542).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 1.95 .. Rec_loss: 1039.45 .. NELBO: 1041.4\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 268.23 .. NELBO: 268.71\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 1039.64 .. NELBO: 1041.34\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 268.25 .. NELBO: 268.67\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.055542 --> 1113.031250).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 1.98 .. Rec_loss: 1039.34 .. NELBO: 1041.32\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.3 .. NELBO: 268.7\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 1.8 .. Rec_loss: 1039.63 .. NELBO: 1041.43\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.26 .. NELBO: 268.71\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 1.82 .. Rec_loss: 1039.52 .. NELBO: 1041.34\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 268.24 .. NELBO: 268.66\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.031250 --> 1113.018188).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 1.96 .. Rec_loss: 1039.31 .. NELBO: 1041.27\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 268.24 .. NELBO: 268.71\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 1.77 .. Rec_loss: 1039.49 .. NELBO: 1041.26\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.49 .. Rec_loss: 268.26 .. NELBO: 268.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 1.76 .. Rec_loss: 1039.42 .. NELBO: 1041.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.24 .. NELBO: 268.69\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 1.85 .. Rec_loss: 1039.46 .. NELBO: 1041.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 268.24 .. NELBO: 268.72\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 1.88 .. Rec_loss: 1039.4 .. NELBO: 1041.28\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.26 .. NELBO: 268.67\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  25%|██▌       | 2/8 [00:10<00:31,  5.31s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=3, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=3, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=3, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1113.3 .. NELBO: 1113.39\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 278.55 .. NELBO: 278.63\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1156.348145).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 1065.7 .. NELBO: 1065.81\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.73 .. NELBO: 272.73\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1156.348145 --> 1131.641846).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 1055.18 .. NELBO: 1055.57\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 270.99 .. NELBO: 271.14\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.641846 --> 1124.429321).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 1051.89 .. NELBO: 1052.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.2 .. NELBO: 271.2\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 1051.2 .. NELBO: 1051.23\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 270.91 .. NELBO: 270.93\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.429321 --> 1124.085449).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 1050.44 .. NELBO: 1050.49\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.8 .. NELBO: 270.8\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.085449 --> 1123.556396).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.25 .. NELBO: 1050.26\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.77 .. NELBO: 270.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.556396 --> 1123.279785).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.19 .. NELBO: 1050.19\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.16 .. NELBO: 1050.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.11 .. NELBO: 1050.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.16 .. NELBO: 1050.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.16 .. NELBO: 1050.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  38%|███▊      | 3/8 [00:12<00:20,  4.09s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=3, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=3, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=3, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 1113.2 .. NELBO: 1113.24\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 278.55 .. NELBO: 278.61\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1156.285400).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1065.58 .. NELBO: 1065.67\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 272.71 .. NELBO: 272.73\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1156.285400 --> 1131.671997).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.36 .. Rec_loss: 1055.14 .. NELBO: 1055.5\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 271.02 .. NELBO: 271.11\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.671997 --> 1124.271851).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 1052.11 .. NELBO: 1052.24\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.2 .. NELBO: 271.2\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1051.13 .. NELBO: 1051.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 270.78 .. NELBO: 270.83\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.271851 --> 1123.696167).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 1049.97 .. NELBO: 1050.3\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 270.56 .. NELBO: 270.67\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.696167 --> 1122.928833).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.43 .. Rec_loss: 1049.29 .. NELBO: 1049.72\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 270.32 .. NELBO: 270.44\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.928833 --> 1121.803955).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 1048.51 .. NELBO: 1049.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.19 .. Rec_loss: 270.04 .. NELBO: 270.23\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1121.803955 --> 1120.889648).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.81 .. Rec_loss: 1047.63 .. NELBO: 1048.44\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.26 .. Rec_loss: 269.69 .. NELBO: 269.95\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1120.889648 --> 1119.707886).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 1046.14 .. NELBO: 1047.32\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 269.18 .. NELBO: 269.51\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1119.707886 --> 1117.784790).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 1.34 .. Rec_loss: 1044.42 .. NELBO: 1045.76\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.93 .. NELBO: 269.32\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1117.784790 --> 1116.848022).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 1043.12 .. NELBO: 1044.72\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.69 .. NELBO: 269.09\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1116.848022 --> 1115.940674).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 1.61 .. Rec_loss: 1041.87 .. NELBO: 1043.48\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.67 .. NELBO: 269.12\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 1041.2 .. NELBO: 1042.87\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.57 .. NELBO: 268.98\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.940674 --> 1115.399414).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 1.76 .. Rec_loss: 1040.87 .. NELBO: 1042.63\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.49 .. Rec_loss: 268.73 .. NELBO: 269.22\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 1.74 .. Rec_loss: 1041.09 .. NELBO: 1042.83\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.38 .. NELBO: 268.83\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.399414 --> 1114.341919).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 1.95 .. Rec_loss: 1040.81 .. NELBO: 1042.76\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.49 .. Rec_loss: 268.48 .. NELBO: 268.97\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 1041.0 .. NELBO: 1042.72\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.4 .. NELBO: 268.85\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 1.88 .. Rec_loss: 1040.4 .. NELBO: 1042.28\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.44 .. Rec_loss: 268.35 .. NELBO: 268.79\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.341919 --> 1114.092651).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 1.77 .. Rec_loss: 1039.83 .. NELBO: 1041.6\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.5 .. Rec_loss: 268.21 .. NELBO: 268.71\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.092651 --> 1113.719971).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 1.99 .. Rec_loss: 1039.47 .. NELBO: 1041.46\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.54 .. Rec_loss: 268.15 .. NELBO: 268.69\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.719971 --> 1113.605347).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 1.95 .. Rec_loss: 1039.41 .. NELBO: 1041.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.51 .. Rec_loss: 268.12 .. NELBO: 268.63\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.605347 --> 1113.260010).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 2.14 .. Rec_loss: 1038.97 .. NELBO: 1041.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 268.05 .. NELBO: 268.61\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.260010 --> 1113.163574).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 2.1 .. Rec_loss: 1038.68 .. NELBO: 1040.78\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.52 .. Rec_loss: 267.97 .. NELBO: 268.49\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.163574 --> 1112.681152).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 2.21 .. Rec_loss: 1038.47 .. NELBO: 1040.68\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 267.89 .. NELBO: 268.47\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1112.681152 --> 1112.557739).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 2.27 .. Rec_loss: 1038.01 .. NELBO: 1040.28\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 267.74 .. NELBO: 268.35\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1112.557739 --> 1112.117920).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 2.52 .. Rec_loss: 1037.6 .. NELBO: 1040.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 267.66 .. NELBO: 268.29\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1112.117920 --> 1111.863770).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 2.39 .. Rec_loss: 1037.3 .. NELBO: 1039.69\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 267.55 .. NELBO: 268.18\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.863770 --> 1111.468872).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 2.49 .. Rec_loss: 1036.8 .. NELBO: 1039.29\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.53 .. Rec_loss: 267.59 .. NELBO: 268.12\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.468872 --> 1111.190796).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 2.59 .. Rec_loss: 1036.52 .. NELBO: 1039.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.64 .. Rec_loss: 267.48 .. NELBO: 268.12\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.190796 --> 1111.016724).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 2.53 .. Rec_loss: 1036.24 .. NELBO: 1038.77\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 267.25 .. NELBO: 267.88\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.016724 --> 1109.737671).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 2.58 .. Rec_loss: 1035.84 .. NELBO: 1038.42\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.67 .. Rec_loss: 267.27 .. NELBO: 267.94\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 2.67 .. Rec_loss: 1035.84 .. NELBO: 1038.51\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 267.23 .. NELBO: 267.89\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 2.7 .. Rec_loss: 1035.57 .. NELBO: 1038.27\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.68 .. Rec_loss: 267.1 .. NELBO: 267.78\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1109.737671 --> 1109.319580).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 2.82 .. Rec_loss: 1035.21 .. NELBO: 1038.03\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 267.19 .. NELBO: 267.93\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 2.84 .. Rec_loss: 1035.13 .. NELBO: 1037.97\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 267.1 .. NELBO: 267.73\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1109.319580 --> 1109.149902).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 2.62 .. Rec_loss: 1035.11 .. NELBO: 1037.73\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 267.02 .. NELBO: 267.71\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1109.149902 --> 1108.867554).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 2.77 .. Rec_loss: 1034.74 .. NELBO: 1037.51\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.67 .. Rec_loss: 266.99 .. NELBO: 267.66\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.867554 --> 1108.653198).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 2.87 .. Rec_loss: 1034.72 .. NELBO: 1037.59\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.7 .. Rec_loss: 266.96 .. NELBO: 267.66\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.653198 --> 1108.647217).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 2.82 .. Rec_loss: 1034.56 .. NELBO: 1037.38\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.68 .. Rec_loss: 267.0 .. NELBO: 267.68\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 2.63 .. Rec_loss: 1034.68 .. NELBO: 1037.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 266.96 .. NELBO: 267.65\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.647217 --> 1108.552368).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 2.95 .. Rec_loss: 1034.41 .. NELBO: 1037.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 266.94 .. NELBO: 267.63\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.552368 --> 1108.449585).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 2.75 .. Rec_loss: 1034.65 .. NELBO: 1037.4\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.68 .. Rec_loss: 266.96 .. NELBO: 267.64\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 2.81 .. Rec_loss: 1034.37 .. NELBO: 1037.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.67 .. Rec_loss: 266.91 .. NELBO: 267.58\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.449585 --> 1108.230591).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 2.87 .. Rec_loss: 1034.32 .. NELBO: 1037.19\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 266.9 .. NELBO: 267.63\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 2.89 .. Rec_loss: 1034.33 .. NELBO: 1037.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 266.87 .. NELBO: 267.6\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->47 .. LR: 0.005 .. KL_theta: 3.04 .. Rec_loss: 1034.17 .. NELBO: 1037.21\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.75 .. Rec_loss: 266.85 .. NELBO: 267.6\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->48 .. LR: 0.005 .. KL_theta: 2.91 .. Rec_loss: 1034.21 .. NELBO: 1037.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 266.85 .. NELBO: 267.54\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.230591 --> 1107.994019).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->49 .. LR: 0.005 .. KL_theta: 2.88 .. Rec_loss: 1034.22 .. NELBO: 1037.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.72 .. Rec_loss: 266.9 .. NELBO: 267.62\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->50 .. LR: 0.005 .. KL_theta: 2.95 .. Rec_loss: 1034.08 .. NELBO: 1037.03\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 266.89 .. NELBO: 267.63\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->51 .. LR: 0.005 .. KL_theta: 2.84 .. Rec_loss: 1034.18 .. NELBO: 1037.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 266.87 .. NELBO: 267.53\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.994019 --> 1107.882202).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->52 .. LR: 0.005 .. KL_theta: 2.93 .. Rec_loss: 1034.25 .. NELBO: 1037.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.76 .. Rec_loss: 266.86 .. NELBO: 267.62\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->53 .. LR: 0.005 .. KL_theta: 3.04 .. Rec_loss: 1034.0 .. NELBO: 1037.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 266.83 .. NELBO: 267.57\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->54 .. LR: 0.005 .. KL_theta: 2.98 .. Rec_loss: 1034.12 .. NELBO: 1037.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.76 .. Rec_loss: 266.9 .. NELBO: 267.66\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->55 .. LR: 0.005 .. KL_theta: 3.09 .. Rec_loss: 1034.04 .. NELBO: 1037.13\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.71 .. Rec_loss: 266.92 .. NELBO: 267.63\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->56 .. LR: 0.005 .. KL_theta: 2.92 .. Rec_loss: 1034.25 .. NELBO: 1037.17\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.8 .. Rec_loss: 266.89 .. NELBO: 267.69\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  50%|█████     | 4/8 [00:20<00:21,  5.38s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=4, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=4, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=4, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 1113.76 .. NELBO: 1113.9\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 278.77 .. NELBO: 278.87\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1157.360352).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 1065.96 .. NELBO: 1066.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.65 .. NELBO: 272.65\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1157.360352 --> 1131.359497).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 1054.9 .. NELBO: 1055.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.07 .. Rec_loss: 271.04 .. NELBO: 271.11\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.359497 --> 1124.312256).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 1052.04 .. NELBO: 1052.15\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.21 .. NELBO: 271.21\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 1051.39 .. NELBO: 1051.42\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 270.89 .. NELBO: 270.91\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.312256 --> 1124.028198).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 1050.57 .. NELBO: 1050.65\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 270.8 .. NELBO: 270.81\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.028198 --> 1123.561279).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 1050.28 .. NELBO: 1050.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 270.76 .. NELBO: 270.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.561279 --> 1123.275757).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1050.18 .. NELBO: 1050.2\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.8 .. NELBO: 270.8\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.19 .. NELBO: 1050.2\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.18 .. NELBO: 1050.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.13 .. NELBO: 1050.13\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.14 .. NELBO: 1050.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  62%|██████▎   | 5/8 [00:22<00:12,  4.31s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=4, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=4, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=4, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1114.02 .. NELBO: 1114.03\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 278.91 .. NELBO: 278.92\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1157.556396).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 1066.26 .. NELBO: 1066.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.8 .. NELBO: 272.8\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1157.556396 --> 1131.945190).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1055.8 .. NELBO: 1055.89\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 271.09 .. NELBO: 271.1\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.945190 --> 1124.253906).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1052.08 .. NELBO: 1052.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.34 .. NELBO: 271.34\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1051.25 .. NELBO: 1051.26\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.99 .. NELBO: 270.99\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.59 .. NELBO: 1050.6\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.8 .. NELBO: 270.8\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.253906 --> 1123.596558).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.29 .. NELBO: 1050.29\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.77 .. NELBO: 270.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.596558 --> 1123.292847).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.18 .. NELBO: 1050.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.8 .. NELBO: 270.8\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.19 .. NELBO: 1050.19\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.14 .. NELBO: 1050.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.17 .. NELBO: 1050.17\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 1050.12 .. NELBO: 1050.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  75%|███████▌  | 6/8 [00:25<00:07,  3.65s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=5, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1114.78 .. NELBO: 1114.8\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 279.27 .. NELBO: 279.3\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1159.177856).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 1066.9 .. NELBO: 1066.96\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 272.73 .. NELBO: 272.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1159.177856 --> 1131.820312).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 1055.6 .. NELBO: 1055.93\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 271.05 .. NELBO: 271.11\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.820312 --> 1124.294067).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 1051.87 .. NELBO: 1051.96\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 271.22 .. NELBO: 271.25\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.27 .. Rec_loss: 1051.04 .. NELBO: 1051.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 270.84 .. NELBO: 270.88\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.294067 --> 1123.906982).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 1050.42 .. NELBO: 1050.52\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 270.66 .. NELBO: 270.72\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.906982 --> 1123.225098).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 1049.64 .. NELBO: 1050.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 270.48 .. NELBO: 270.6\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.225098 --> 1122.530762).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 1049.34 .. NELBO: 1049.72\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 270.41 .. NELBO: 270.54\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.530762 --> 1122.235840).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.67 .. Rec_loss: 1048.68 .. NELBO: 1049.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 270.16 .. NELBO: 270.33\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.235840 --> 1121.351074).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.89 .. Rec_loss: 1048.03 .. NELBO: 1048.92\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.31 .. Rec_loss: 269.85 .. NELBO: 270.16\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1121.351074 --> 1120.535522).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 1.11 .. Rec_loss: 1046.82 .. NELBO: 1047.93\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 269.47 .. NELBO: 269.79\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1120.535522 --> 1118.742188).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 1.58 .. Rec_loss: 1045.03 .. NELBO: 1046.61\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.84 .. NELBO: 269.24\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1118.742188 --> 1116.291016).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 1043.22 .. NELBO: 1044.9\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.51 .. Rec_loss: 268.51 .. NELBO: 269.02\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1116.291016 --> 1115.220093).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 1.85 .. Rec_loss: 1041.83 .. NELBO: 1043.68\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.57 .. Rec_loss: 268.38 .. NELBO: 268.95\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.220093 --> 1114.984985).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 2.03 .. Rec_loss: 1040.95 .. NELBO: 1042.98\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.53 .. Rec_loss: 268.25 .. NELBO: 268.78\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.984985 --> 1114.229248).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 2.05 .. Rec_loss: 1040.09 .. NELBO: 1042.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.54 .. Rec_loss: 268.18 .. NELBO: 268.72\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.229248 --> 1113.901245).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 2.17 .. Rec_loss: 1039.69 .. NELBO: 1041.86\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 268.3 .. NELBO: 268.93\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 2.17 .. Rec_loss: 1039.35 .. NELBO: 1041.52\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 268.1 .. NELBO: 268.76\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 2.2 .. Rec_loss: 1039.17 .. NELBO: 1041.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.53 .. Rec_loss: 267.81 .. NELBO: 268.34\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1113.901245 --> 1112.099731).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 2.41 .. Rec_loss: 1038.95 .. NELBO: 1041.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 267.97 .. NELBO: 268.55\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 2.26 .. Rec_loss: 1038.72 .. NELBO: 1040.98\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.64 .. Rec_loss: 267.79 .. NELBO: 268.43\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 2.49 .. Rec_loss: 1037.98 .. NELBO: 1040.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 267.57 .. NELBO: 268.22\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1112.099731 --> 1111.510620).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 2.52 .. Rec_loss: 1037.18 .. NELBO: 1039.7\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 267.59 .. NELBO: 268.17\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.510620 --> 1111.116699).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 2.6 .. Rec_loss: 1036.97 .. NELBO: 1039.57\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.64 .. Rec_loss: 267.39 .. NELBO: 268.03\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1111.116699 --> 1110.466064).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 2.66 .. Rec_loss: 1036.65 .. NELBO: 1039.31\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.57 .. Rec_loss: 267.37 .. NELBO: 267.94\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1110.466064 --> 1110.074463).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 2.84 .. Rec_loss: 1036.43 .. NELBO: 1039.27\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 267.27 .. NELBO: 267.92\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1110.074463 --> 1109.958618).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 2.61 .. Rec_loss: 1036.44 .. NELBO: 1039.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.71 .. Rec_loss: 267.3 .. NELBO: 268.01\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 2.73 .. Rec_loss: 1035.99 .. NELBO: 1038.72\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 267.24 .. NELBO: 267.98\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 2.76 .. Rec_loss: 1035.67 .. NELBO: 1038.43\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.62 .. Rec_loss: 267.09 .. NELBO: 267.71\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1109.958618 --> 1109.023804).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 2.8 .. Rec_loss: 1035.46 .. NELBO: 1038.26\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.72 .. Rec_loss: 266.98 .. NELBO: 267.7\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1109.023804 --> 1108.884888).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 3.05 .. Rec_loss: 1034.97 .. NELBO: 1038.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.75 .. Rec_loss: 267.0 .. NELBO: 267.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 2.93 .. Rec_loss: 1035.09 .. NELBO: 1038.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.77 .. Rec_loss: 266.98 .. NELBO: 267.75\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 2.84 .. Rec_loss: 1034.99 .. NELBO: 1037.83\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 266.98 .. NELBO: 267.63\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.884888 --> 1108.450317).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 3.0 .. Rec_loss: 1035.15 .. NELBO: 1038.15\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 266.89 .. NELBO: 267.62\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.450317 --> 1108.371948).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 3.13 .. Rec_loss: 1034.87 .. NELBO: 1038.0\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 266.92 .. NELBO: 267.58\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.371948 --> 1108.244751).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 3.03 .. Rec_loss: 1034.92 .. NELBO: 1037.95\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.82 .. Rec_loss: 266.94 .. NELBO: 267.76\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 2.97 .. Rec_loss: 1034.83 .. NELBO: 1037.8\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 266.95 .. NELBO: 267.68\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 2.86 .. Rec_loss: 1034.76 .. NELBO: 1037.62\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 266.83 .. NELBO: 267.52\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1108.244751 --> 1107.785522).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 2.97 .. Rec_loss: 1034.68 .. NELBO: 1037.65\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.72 .. Rec_loss: 266.81 .. NELBO: 267.53\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.785522 --> 1107.782471).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 3.16 .. Rec_loss: 1034.52 .. NELBO: 1037.68\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.8 .. Rec_loss: 266.78 .. NELBO: 267.58\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 3.17 .. Rec_loss: 1034.39 .. NELBO: 1037.56\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 266.81 .. NELBO: 267.54\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 3.15 .. Rec_loss: 1034.44 .. NELBO: 1037.59\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.79 .. Rec_loss: 266.77 .. NELBO: 267.56\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 2.98 .. Rec_loss: 1034.32 .. NELBO: 1037.3\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.76 .. Rec_loss: 266.82 .. NELBO: 267.58\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 3.21 .. Rec_loss: 1034.2 .. NELBO: 1037.41\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 266.77 .. NELBO: 267.55\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.782471 --> 1107.634521).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 3.1 .. Rec_loss: 1034.2 .. NELBO: 1037.3\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 266.78 .. NELBO: 267.56\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 3.16 .. Rec_loss: 1033.96 .. NELBO: 1037.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 266.74 .. NELBO: 267.52\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.634521 --> 1107.557007).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->47 .. LR: 0.005 .. KL_theta: 3.29 .. Rec_loss: 1034.01 .. NELBO: 1037.3\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.79 .. Rec_loss: 266.75 .. NELBO: 267.54\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.557007 --> 1107.523438).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->48 .. LR: 0.005 .. KL_theta: 3.17 .. Rec_loss: 1033.82 .. NELBO: 1036.99\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.79 .. Rec_loss: 266.79 .. NELBO: 267.58\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->49 .. LR: 0.005 .. KL_theta: 3.27 .. Rec_loss: 1033.72 .. NELBO: 1036.99\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 266.75 .. NELBO: 267.53\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.523438 --> 1107.419800).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->50 .. LR: 0.005 .. KL_theta: 3.17 .. Rec_loss: 1033.8 .. NELBO: 1036.97\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 266.72 .. NELBO: 267.5\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1107.419800 --> 1107.266846).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params:  88%|████████▊ | 7/8 [00:30<00:04,  4.32s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=720, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=5, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=720, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1114.75 .. NELBO: 1114.76\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 279.33 .. NELBO: 279.34\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (inf --> 1159.333252).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 1066.94 .. NELBO: 1067.0\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 272.74 .. NELBO: 272.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1159.333252 --> 1131.804810).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.27 .. Rec_loss: 1055.58 .. NELBO: 1055.85\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 271.08 .. NELBO: 271.12\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1131.804810 --> 1124.306274).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 1051.96 .. NELBO: 1052.01\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 271.3 .. NELBO: 271.3\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1051.32 .. NELBO: 1051.34\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 270.94 .. NELBO: 270.96\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.306274 --> 1124.259521).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 1050.62 .. NELBO: 1050.66\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 270.8 .. NELBO: 270.81\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1124.259521 --> 1123.582764).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 1050.33 .. NELBO: 1050.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.77 .. NELBO: 270.77\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.582764 --> 1123.286987).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.19 .. NELBO: 1050.2\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.8 .. NELBO: 270.8\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.16 .. NELBO: 1050.17\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.79 .. NELBO: 270.79\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.13 .. NELBO: 1050.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.78 .. NELBO: 270.78\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 1050.07 .. NELBO: 1050.08\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 270.76 .. NELBO: 270.76\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 1050.0 .. NELBO: 1050.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 270.72 .. NELBO: 270.74\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.286987 --> 1123.178833).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 1049.83 .. NELBO: 1049.94\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.07 .. Rec_loss: 270.64 .. NELBO: 270.71\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.178833 --> 1123.044800).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 1049.56 .. NELBO: 1049.74\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 270.5 .. NELBO: 270.61\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1123.044800 --> 1122.611450).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 1049.29 .. NELBO: 1049.64\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 270.35 .. NELBO: 270.45\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1122.611450 --> 1121.882202).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 0.5 .. Rec_loss: 1048.62 .. NELBO: 1049.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 270.04 .. NELBO: 270.19\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1121.882202 --> 1120.749634).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 0.87 .. Rec_loss: 1047.24 .. NELBO: 1048.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 269.68 .. NELBO: 269.84\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1120.749634 --> 1119.170654).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 1.27 .. Rec_loss: 1045.84 .. NELBO: 1047.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 269.47 .. NELBO: 269.62\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1119.170654 --> 1118.314209).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 1045.04 .. NELBO: 1046.56\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.25 .. Rec_loss: 269.01 .. NELBO: 269.26\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1118.314209 --> 1116.634644).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 1.44 .. Rec_loss: 1043.69 .. NELBO: 1045.13\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.9 .. NELBO: 269.29\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1116.634644 --> 1116.540039).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 1.44 .. Rec_loss: 1043.1 .. NELBO: 1044.54\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.36 .. Rec_loss: 268.71 .. NELBO: 269.07\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1116.540039 --> 1115.592773).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 1042.5 .. NELBO: 1044.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 268.62 .. NELBO: 268.94\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1115.592773 --> 1114.935059).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 1042.23 .. NELBO: 1043.88\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.36 .. Rec_loss: 268.57 .. NELBO: 268.93\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.935059 --> 1114.842041).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 1.86 .. Rec_loss: 1041.83 .. NELBO: 1043.69\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.34 .. Rec_loss: 268.52 .. NELBO: 268.86\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.842041 --> 1114.496216).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 1.77 .. Rec_loss: 1041.84 .. NELBO: 1043.61\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.51 .. NELBO: 268.9\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 1041.63 .. NELBO: 1043.35\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 268.5 .. NELBO: 268.85\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.496216 --> 1114.459229).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 1.75 .. Rec_loss: 1041.61 .. NELBO: 1043.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.51 .. NELBO: 268.9\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 1041.46 .. NELBO: 1043.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 268.52 .. NELBO: 268.92\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 1.76 .. Rec_loss: 1041.56 .. NELBO: 1043.32\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 268.47 .. NELBO: 268.85\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.459229 --> 1114.312988).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 1.78 .. Rec_loss: 1041.45 .. NELBO: 1043.23\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 268.47 .. NELBO: 268.82\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.312988 --> 1114.130005).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 1.81 .. Rec_loss: 1041.35 .. NELBO: 1043.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.45 .. NELBO: 268.82\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 1.78 .. Rec_loss: 1041.14 .. NELBO: 1042.92\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.42 .. Rec_loss: 268.48 .. NELBO: 268.9\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 1.86 .. Rec_loss: 1041.5 .. NELBO: 1043.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.45 .. Rec_loss: 268.49 .. NELBO: 268.94\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 1.99 .. Rec_loss: 1041.18 .. NELBO: 1043.17\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 268.43 .. NELBO: 268.82\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.130005 --> 1114.121094).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 1.96 .. Rec_loss: 1041.04 .. NELBO: 1043.0\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 268.41 .. NELBO: 268.78\n",
      "****************************************************************************************************\n",
      "Validation loss decreased (1114.121094 --> 1113.938721).  Saving model ...\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 1.75 .. Rec_loss: 1041.26 .. NELBO: 1043.01\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.44 .. NELBO: 268.85\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 1 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 1.87 .. Rec_loss: 1041.1 .. NELBO: 1042.97\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.35 .. Rec_loss: 268.46 .. NELBO: 268.81\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 2 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 1.97 .. Rec_loss: 1040.79 .. NELBO: 1042.76\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.31 .. Rec_loss: 268.49 .. NELBO: 268.8\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 3 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 1041.38 .. NELBO: 1043.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 268.46 .. NELBO: 268.87\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 4 out of 5\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 1041.34 .. NELBO: 1043.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VALIDATION .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 268.52 .. NELBO: 268.99\n",
      "****************************************************************************************************\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching ETM Params: 100%|██████████| 8/8 [00:35<00:00,  4.41s/it]\u001B[A\n",
      "Overall Model Parameter Search:  60%|██████    | 3/5 [01:43<01:05, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ETM Params: {'num_topics': 5, 'num_epochs': 50} with Score: 0.639376252501009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:   0%|          | 0/16 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1306.3124754837866\tTime: 0:00:00.031102\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.355449695122\tTime: 0:00:00.002602\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1308.0964712996863\tTime: 0:00:00.030453\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1151.0301829268292\tTime: 0:00:00.004017\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1299.848538833682\tTime: 0:00:00.035441\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1148.5410299161585\tTime: 0:00:00.002554\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1242.8418295632846\tTime: 0:00:00.027743\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1147.4167063643292\tTime: 0:00:00.002639\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1218.9853638206066\tTime: 0:00:00.029398\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1143.5890196265243\tTime: 0:00:00.002293\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1259.0131978948746\tTime: 0:00:00.035583\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1138.3736852134145\tTime: 0:00:00.003564\n",
      "Epoch: [7/50]\tSamples: [6692/47800]\tTrain Loss: 1227.0224813676778\tTime: 0:00:00.045150\n",
      "Epoch: [7/50]\tSamples: [205/10250]\tValidation Loss: 1136.0874857088415\tTime: 0:00:00.004476\n",
      "Epoch: [8/50]\tSamples: [7648/47800]\tTrain Loss: 1225.8183512029289\tTime: 0:00:00.038751\n",
      "Epoch: [8/50]\tSamples: [205/10250]\tValidation Loss: 1136.3311975990853\tTime: 0:00:00.005263\n",
      "Epoch: [9/50]\tSamples: [8604/47800]\tTrain Loss: 1232.2821816161088\tTime: 0:00:00.034755\n",
      "Epoch: [9/50]\tSamples: [205/10250]\tValidation Loss: 1136.5065310594512\tTime: 0:00:00.003541\n",
      "Epoch: [10/50]\tSamples: [9560/47800]\tTrain Loss: 1256.597901412134\tTime: 0:00:00.029114\n",
      "Epoch: [10/50]\tSamples: [205/10250]\tValidation Loss: 1136.7216368140244\tTime: 0:00:00.002452\n",
      "Epoch: [11/50]\tSamples: [10516/47800]\tTrain Loss: 1257.541456916841\tTime: 0:00:00.027573\n",
      "Epoch: [11/50]\tSamples: [205/10250]\tValidation Loss: 1140.6554211128048\tTime: 0:00:00.002295\n",
      "Epoch: [12/50]\tSamples: [11472/47800]\tTrain Loss: 1277.059852248954\tTime: 0:00:00.028305\n",
      "Epoch: [12/50]\tSamples: [205/10250]\tValidation Loss: 1139.6280297256098\tTime: 0:00:00.002307\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:   6%|▋         | 1/16 [00:02<00:31,  2.13s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1313.5469322044978\tTime: 0:00:00.033491\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.2649437881098\tTime: 0:00:00.003875\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1299.7031495162134\tTime: 0:00:00.029481\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1151.361513910061\tTime: 0:00:00.002913\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1298.8786692599372\tTime: 0:00:00.023132\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1148.8041730182927\tTime: 0:00:00.002213\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1279.2679458682007\tTime: 0:00:00.027659\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1145.9502334222561\tTime: 0:00:00.003559\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1263.526714500523\tTime: 0:00:00.025383\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1143.9386766387195\tTime: 0:00:00.002245\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1256.084875130753\tTime: 0:00:00.027085\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1143.8152724847562\tTime: 0:00:00.003229\n",
      "Epoch: [7/50]\tSamples: [6692/47800]\tTrain Loss: 1279.0922463389122\tTime: 0:00:00.025862\n",
      "Epoch: [7/50]\tSamples: [205/10250]\tValidation Loss: 1143.9425304878048\tTime: 0:00:00.003375\n",
      "Epoch: [8/50]\tSamples: [7648/47800]\tTrain Loss: 1253.0667086166318\tTime: 0:00:00.027049\n",
      "Epoch: [8/50]\tSamples: [205/10250]\tValidation Loss: 1146.1367949695123\tTime: 0:00:00.002841\n",
      "Epoch: [9/50]\tSamples: [8604/47800]\tTrain Loss: 1266.8709793410042\tTime: 0:00:00.028406\n",
      "Epoch: [9/50]\tSamples: [205/10250]\tValidation Loss: 1144.235975609756\tTime: 0:00:00.006799\n",
      "Epoch: [10/50]\tSamples: [9560/47800]\tTrain Loss: 1244.5802579105648\tTime: 0:00:00.030783\n",
      "Epoch: [10/50]\tSamples: [205/10250]\tValidation Loss: 1142.6670779344513\tTime: 0:00:00.003755\n",
      "Epoch: [11/50]\tSamples: [10516/47800]\tTrain Loss: 1261.6615863624477\tTime: 0:00:00.027090\n",
      "Epoch: [11/50]\tSamples: [205/10250]\tValidation Loss: 1141.7257002667684\tTime: 0:00:00.003971\n",
      "Epoch: [12/50]\tSamples: [11472/47800]\tTrain Loss: 1266.257183250523\tTime: 0:00:00.039128\n",
      "Epoch: [12/50]\tSamples: [205/10250]\tValidation Loss: 1140.7793492759147\tTime: 0:00:00.002460\n",
      "Epoch: [13/50]\tSamples: [12428/47800]\tTrain Loss: 1258.7639006929917\tTime: 0:00:00.026873\n",
      "Epoch: [13/50]\tSamples: [205/10250]\tValidation Loss: 1141.6571884527439\tTime: 0:00:00.002262\n",
      "Epoch: [14/50]\tSamples: [13384/47800]\tTrain Loss: 1272.8688382583682\tTime: 0:00:00.029627\n",
      "Epoch: [14/50]\tSamples: [205/10250]\tValidation Loss: 1142.119559832317\tTime: 0:00:00.002641\n",
      "Epoch: [15/50]\tSamples: [14340/47800]\tTrain Loss: 1241.4637977248954\tTime: 0:00:00.035077\n",
      "Epoch: [15/50]\tSamples: [205/10250]\tValidation Loss: 1141.3049447408537\tTime: 0:00:00.002801\n",
      "Epoch: [16/50]\tSamples: [15296/47800]\tTrain Loss: 1226.7914242285565\tTime: 0:00:00.038003\n",
      "Epoch: [16/50]\tSamples: [205/10250]\tValidation Loss: 1142.876981707317\tTime: 0:00:00.002378\n",
      "Epoch: [17/50]\tSamples: [16252/47800]\tTrain Loss: 1255.1001487316946\tTime: 0:00:00.031573\n",
      "Epoch: [17/50]\tSamples: [205/10250]\tValidation Loss: 1143.1835985137195\tTime: 0:00:00.002545\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  12%|█▎        | 2/16 [00:04<00:29,  2.08s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1316.3228049816946\tTime: 0:00:00.036850\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1157.9471370045733\tTime: 0:00:00.003166\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1295.2522391474895\tTime: 0:00:00.044960\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1155.2202076981707\tTime: 0:00:00.003556\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1263.5988902327406\tTime: 0:00:00.027017\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1149.2368997713415\tTime: 0:00:00.002867\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1268.0293785957113\tTime: 0:00:00.026457\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1144.3816930259147\tTime: 0:00:00.002993\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1255.5929654811716\tTime: 0:00:00.026317\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1143.270274390244\tTime: 0:00:00.003889\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1275.387290794979\tTime: 0:00:00.026605\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1141.2904963795731\tTime: 0:00:00.002353\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1239.6942664748954\tTime: 0:00:00.028088\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1141.5085032393292\tTime: 0:00:00.002739\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1270.4456802432007\tTime: 0:00:00.030991\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1139.6992568597561\tTime: 0:00:00.002989\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1219.17867416318\tTime: 0:00:00.028310\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1140.7858184070121\tTime: 0:00:00.003282\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1246.9555929654812\tTime: 0:00:00.034491\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1141.7575171493902\tTime: 0:00:00.005425\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1282.471839042887\tTime: 0:00:00.033482\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1142.211680640244\tTime: 0:00:00.002834\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1237.4535499476988\tTime: 0:00:00.027764\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1142.0768006859755\tTime: 0:00:00.002419\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1278.6130606040795\tTime: 0:00:00.027911\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1142.1544397865853\tTime: 0:00:00.002514\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  19%|█▉        | 3/16 [00:06<00:29,  2.28s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1330.0997483002093\tTime: 0:00:00.028081\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1151.9510480182928\tTime: 0:00:00.004087\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1287.77886375523\tTime: 0:00:00.026642\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1150.9565548780488\tTime: 0:00:00.002353\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1284.7082488885983\tTime: 0:00:00.027672\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1147.824776105183\tTime: 0:00:00.002369\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1301.4014938546024\tTime: 0:00:00.026162\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1145.2487709603658\tTime: 0:00:00.002611\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1267.4022865455022\tTime: 0:00:00.029305\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1143.6507621951218\tTime: 0:00:00.002274\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1314.437181289226\tTime: 0:00:00.026240\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1143.2657488567072\tTime: 0:00:00.003131\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1252.968504837866\tTime: 0:00:00.028458\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1144.3113948170733\tTime: 0:00:00.002268\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1283.664634544979\tTime: 0:00:00.035637\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1145.8975514481708\tTime: 0:00:00.003784\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1275.548582962866\tTime: 0:00:00.029931\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1146.7947932545733\tTime: 0:00:00.003093\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1238.3953811453976\tTime: 0:00:00.034340\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1144.146484375\tTime: 0:00:00.002490\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1236.4408668933054\tTime: 0:00:00.029989\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1143.9048494664635\tTime: 0:00:00.006172\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  25%|██▌       | 4/16 [00:08<00:25,  2.16s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1213.783325706067\tTime: 0:00:00.032014\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.8027677210366\tTime: 0:00:00.003394\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1199.4566308185147\tTime: 0:00:00.028023\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1153.7237328506098\tTime: 0:00:00.003637\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1205.0922463389122\tTime: 0:00:00.030235\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1155.8576838795732\tTime: 0:00:00.002915\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1210.2283603556486\tTime: 0:00:00.026746\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1157.968221227134\tTime: 0:00:00.003736\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1194.4533946783472\tTime: 0:00:00.028759\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1156.2775247713414\tTime: 0:00:00.002533\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1211.6824905203976\tTime: 0:00:00.029109\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1154.9484232088414\tTime: 0:00:00.002512\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  31%|███▏      | 5/16 [00:10<00:22,  2.03s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1215.5511408211298\tTime: 0:00:00.032062\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.567830602134\tTime: 0:00:00.003454\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1226.7707570606694\tTime: 0:00:00.030504\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1152.7583031631098\tTime: 0:00:00.002344\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1231.1626405596235\tTime: 0:00:00.028771\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1155.2747141768293\tTime: 0:00:00.002729\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1186.3028978164225\tTime: 0:00:00.028011\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1155.8814977134145\tTime: 0:00:00.002852\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1201.580650169979\tTime: 0:00:00.028497\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1156.8998285060975\tTime: 0:00:00.003018\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1196.8239490716528\tTime: 0:00:00.025936\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1156.102882050305\tTime: 0:00:00.003077\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  38%|███▊      | 6/16 [00:12<00:19,  1.97s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1209.451049293933\tTime: 0:00:00.027245\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.3001810213414\tTime: 0:00:00.003059\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1214.8429001046024\tTime: 0:00:00.027376\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1153.2921589176829\tTime: 0:00:00.002412\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1196.8736597803347\tTime: 0:00:00.026345\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1157.9451410060976\tTime: 0:00:00.002358\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1190.3820279811716\tTime: 0:00:00.027126\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1157.5220179115854\tTime: 0:00:00.002711\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1204.5756406903765\tTime: 0:00:00.026586\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1155.458350800305\tTime: 0:00:00.002833\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1212.5296973064853\tTime: 0:00:00.025484\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1154.674013910061\tTime: 0:00:00.002311\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  44%|████▍     | 7/16 [00:14<00:18,  2.00s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1217.6855877353557\tTime: 0:00:00.038017\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.2216653963415\tTime: 0:00:00.002880\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1219.3607887683054\tTime: 0:00:00.028300\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1152.3012480945122\tTime: 0:00:00.002664\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1203.4967965481171\tTime: 0:00:00.025146\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1153.0567549542684\tTime: 0:00:00.003069\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1206.5789994116108\tTime: 0:00:00.029827\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1153.9561261432927\tTime: 0:00:00.003187\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1212.5322143043934\tTime: 0:00:00.026505\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1151.312052210366\tTime: 0:00:00.002858\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1193.2700297463389\tTime: 0:00:00.024632\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1150.834012957317\tTime: 0:00:00.002715\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1194.1606138859834\tTime: 0:00:00.033047\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1149.360556402439\tTime: 0:00:00.002294\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1189.0366108786611\tTime: 0:00:00.043349\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1149.7291539634145\tTime: 0:00:00.004296\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1214.966674293933\tTime: 0:00:00.046442\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1147.2469035823171\tTime: 0:00:00.003573\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1205.9968047201883\tTime: 0:00:00.044412\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1146.5299066310977\tTime: 0:00:00.006311\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1191.752525169979\tTime: 0:00:00.041764\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1147.8595703125\tTime: 0:00:00.004488\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1191.660540337343\tTime: 0:00:00.029594\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1144.9189024390244\tTime: 0:00:00.002697\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1196.1707717703976\tTime: 0:00:00.031454\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1142.1905154344513\tTime: 0:00:00.003680\n",
      "Epoch: [14/100]\tSamples: [13384/95600]\tTrain Loss: 1167.2604929393306\tTime: 0:00:00.035929\n",
      "Epoch: [14/100]\tSamples: [205/20500]\tValidation Loss: 1139.4750619283536\tTime: 0:00:00.005444\n",
      "Epoch: [15/100]\tSamples: [14340/95600]\tTrain Loss: 1178.39402458159\tTime: 0:00:00.033372\n",
      "Epoch: [15/100]\tSamples: [205/20500]\tValidation Loss: 1136.7370093368902\tTime: 0:00:00.003256\n",
      "Epoch: [16/100]\tSamples: [15296/95600]\tTrain Loss: 1177.0909633237447\tTime: 0:00:00.030929\n",
      "Epoch: [16/100]\tSamples: [205/20500]\tValidation Loss: 1132.9372332317073\tTime: 0:00:00.003798\n",
      "Epoch: [17/100]\tSamples: [16252/95600]\tTrain Loss: 1167.6022080936193\tTime: 0:00:00.027151\n",
      "Epoch: [17/100]\tSamples: [205/20500]\tValidation Loss: 1135.5688833841464\tTime: 0:00:00.003267\n",
      "Epoch: [18/100]\tSamples: [17208/95600]\tTrain Loss: 1185.7851644220711\tTime: 0:00:00.026611\n",
      "Epoch: [18/100]\tSamples: [205/20500]\tValidation Loss: 1130.3299352134147\tTime: 0:00:00.002514\n",
      "Epoch: [19/100]\tSamples: [18164/95600]\tTrain Loss: 1155.2674637160042\tTime: 0:00:00.029877\n",
      "Epoch: [19/100]\tSamples: [205/20500]\tValidation Loss: 1127.3641196646342\tTime: 0:00:00.002873\n",
      "Epoch: [20/100]\tSamples: [19120/95600]\tTrain Loss: 1181.086182662134\tTime: 0:00:00.030403\n",
      "Epoch: [20/100]\tSamples: [205/20500]\tValidation Loss: 1124.8542825838415\tTime: 0:00:00.003610\n",
      "Epoch: [21/100]\tSamples: [20076/95600]\tTrain Loss: 1177.528160957113\tTime: 0:00:00.033765\n",
      "Epoch: [21/100]\tSamples: [205/20500]\tValidation Loss: 1123.0366330030488\tTime: 0:00:00.003834\n",
      "Epoch: [22/100]\tSamples: [21032/95600]\tTrain Loss: 1173.3639554458682\tTime: 0:00:00.032032\n",
      "Epoch: [22/100]\tSamples: [205/20500]\tValidation Loss: 1127.074971417683\tTime: 0:00:00.003753\n",
      "Epoch: [23/100]\tSamples: [21988/95600]\tTrain Loss: 1143.289503791841\tTime: 0:00:00.030632\n",
      "Epoch: [23/100]\tSamples: [205/20500]\tValidation Loss: 1122.3823313643293\tTime: 0:00:00.002510\n",
      "Epoch: [24/100]\tSamples: [22944/95600]\tTrain Loss: 1151.9057269874477\tTime: 0:00:00.030648\n",
      "Epoch: [24/100]\tSamples: [205/20500]\tValidation Loss: 1121.1653582317074\tTime: 0:00:00.002758\n",
      "Epoch: [25/100]\tSamples: [23900/95600]\tTrain Loss: 1155.1420632845188\tTime: 0:00:00.030476\n",
      "Epoch: [25/100]\tSamples: [205/20500]\tValidation Loss: 1119.4989900914634\tTime: 0:00:00.004117\n",
      "Epoch: [26/100]\tSamples: [24856/95600]\tTrain Loss: 1140.1781920109834\tTime: 0:00:00.041112\n",
      "Epoch: [26/100]\tSamples: [205/20500]\tValidation Loss: 1118.657421875\tTime: 0:00:00.004846\n",
      "Epoch: [27/100]\tSamples: [25812/95600]\tTrain Loss: 1157.403986336297\tTime: 0:00:00.037713\n",
      "Epoch: [27/100]\tSamples: [205/20500]\tValidation Loss: 1121.483212652439\tTime: 0:00:00.003029\n",
      "Epoch: [28/100]\tSamples: [26768/95600]\tTrain Loss: 1156.8393452536611\tTime: 0:00:00.033983\n",
      "Epoch: [28/100]\tSamples: [205/20500]\tValidation Loss: 1122.1604706554879\tTime: 0:00:00.002519\n",
      "Epoch: [29/100]\tSamples: [27724/95600]\tTrain Loss: 1180.7606318645398\tTime: 0:00:00.034300\n",
      "Epoch: [29/100]\tSamples: [205/20500]\tValidation Loss: 1120.8342559070122\tTime: 0:00:00.003144\n",
      "Epoch: [30/100]\tSamples: [28680/95600]\tTrain Loss: 1168.6179434165795\tTime: 0:00:00.031452\n",
      "Epoch: [30/100]\tSamples: [205/20500]\tValidation Loss: 1124.6036394817072\tTime: 0:00:00.003631\n",
      "Epoch: [31/100]\tSamples: [29636/95600]\tTrain Loss: 1159.2418074986924\tTime: 0:00:00.033339\n",
      "Epoch: [31/100]\tSamples: [205/20500]\tValidation Loss: 1121.420703125\tTime: 0:00:00.003791\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  50%|█████     | 8/16 [00:17<00:17,  2.24s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1193.3189559361924\tTime: 0:00:00.031533\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.4163205030488\tTime: 0:00:00.004556\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1184.4515396182007\tTime: 0:00:00.026602\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1153.515086699695\tTime: 0:00:00.005252\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1167.511334662657\tTime: 0:00:00.027295\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1154.8846131859757\tTime: 0:00:00.002721\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1181.1899189330543\tTime: 0:00:00.031810\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1153.5417540015244\tTime: 0:00:00.002627\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1167.22164291318\tTime: 0:00:00.030593\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1146.6237280868902\tTime: 0:00:00.004032\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1159.5073221757323\tTime: 0:00:00.028439\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1140.4436356707317\tTime: 0:00:00.002347\n",
      "Epoch: [7/50]\tSamples: [6692/47800]\tTrain Loss: 1165.430815245816\tTime: 0:00:00.033389\n",
      "Epoch: [7/50]\tSamples: [205/10250]\tValidation Loss: 1138.0046017530487\tTime: 0:00:00.002989\n",
      "Epoch: [8/50]\tSamples: [7648/47800]\tTrain Loss: 1151.2196570998954\tTime: 0:00:00.030795\n",
      "Epoch: [8/50]\tSamples: [205/10250]\tValidation Loss: 1132.920369664634\tTime: 0:00:00.003400\n",
      "Epoch: [9/50]\tSamples: [8604/47800]\tTrain Loss: 1144.8789144220711\tTime: 0:00:00.028590\n",
      "Epoch: [9/50]\tSamples: [205/10250]\tValidation Loss: 1129.7610041920732\tTime: 0:00:00.003034\n",
      "Epoch: [10/50]\tSamples: [9560/47800]\tTrain Loss: 1143.115618462343\tTime: 0:00:00.028133\n",
      "Epoch: [10/50]\tSamples: [205/10250]\tValidation Loss: 1128.9823361280487\tTime: 0:00:00.002782\n",
      "Epoch: [11/50]\tSamples: [10516/47800]\tTrain Loss: 1135.6355297136506\tTime: 0:00:00.035331\n",
      "Epoch: [11/50]\tSamples: [205/10250]\tValidation Loss: 1126.2415253429879\tTime: 0:00:00.003506\n",
      "Epoch: [12/50]\tSamples: [11472/47800]\tTrain Loss: 1136.1245015036611\tTime: 0:00:00.032156\n",
      "Epoch: [12/50]\tSamples: [205/10250]\tValidation Loss: 1125.7148675685976\tTime: 0:00:00.002668\n",
      "Epoch: [13/50]\tSamples: [12428/47800]\tTrain Loss: 1130.444429916318\tTime: 0:00:00.032144\n",
      "Epoch: [13/50]\tSamples: [205/10250]\tValidation Loss: 1121.9590605945123\tTime: 0:00:00.002499\n",
      "Epoch: [14/50]\tSamples: [13384/47800]\tTrain Loss: 1139.7714271705022\tTime: 0:00:00.037093\n",
      "Epoch: [14/50]\tSamples: [205/10250]\tValidation Loss: 1124.257021722561\tTime: 0:00:00.003877\n",
      "Epoch: [15/50]\tSamples: [14340/47800]\tTrain Loss: 1128.9464565899582\tTime: 0:00:00.036113\n",
      "Epoch: [15/50]\tSamples: [205/10250]\tValidation Loss: 1119.6590224847562\tTime: 0:00:00.003026\n",
      "Epoch: [16/50]\tSamples: [15296/47800]\tTrain Loss: 1142.3694470776675\tTime: 0:00:00.033107\n",
      "Epoch: [16/50]\tSamples: [205/10250]\tValidation Loss: 1119.1419159679879\tTime: 0:00:00.004053\n",
      "Epoch: [17/50]\tSamples: [16252/47800]\tTrain Loss: 1125.3572747777196\tTime: 0:00:00.036668\n",
      "Epoch: [17/50]\tSamples: [205/10250]\tValidation Loss: 1114.8835699314025\tTime: 0:00:00.003619\n",
      "Epoch: [18/50]\tSamples: [17208/47800]\tTrain Loss: 1129.2868560407949\tTime: 0:00:00.026440\n",
      "Epoch: [18/50]\tSamples: [205/10250]\tValidation Loss: 1113.7308355564023\tTime: 0:00:00.002431\n",
      "Epoch: [19/50]\tSamples: [18164/47800]\tTrain Loss: 1126.7277678804917\tTime: 0:00:00.030159\n",
      "Epoch: [19/50]\tSamples: [205/10250]\tValidation Loss: 1112.9443740472561\tTime: 0:00:00.004706\n",
      "Epoch: [20/50]\tSamples: [19120/47800]\tTrain Loss: 1126.6725941422594\tTime: 0:00:00.031204\n",
      "Epoch: [20/50]\tSamples: [205/10250]\tValidation Loss: 1114.2576648246952\tTime: 0:00:00.002845\n",
      "Epoch: [21/50]\tSamples: [20076/47800]\tTrain Loss: 1125.1972084205022\tTime: 0:00:00.031124\n",
      "Epoch: [21/50]\tSamples: [205/10250]\tValidation Loss: 1110.334727515244\tTime: 0:00:00.003188\n",
      "Epoch: [22/50]\tSamples: [21032/47800]\tTrain Loss: 1125.437920861663\tTime: 0:00:00.031335\n",
      "Epoch: [22/50]\tSamples: [205/10250]\tValidation Loss: 1110.4300352515245\tTime: 0:00:00.002776\n",
      "Epoch: [23/50]\tSamples: [21988/47800]\tTrain Loss: 1119.79437843227\tTime: 0:00:00.028444\n",
      "Epoch: [23/50]\tSamples: [205/10250]\tValidation Loss: 1113.6559355945121\tTime: 0:00:00.002367\n",
      "Epoch: [24/50]\tSamples: [22944/47800]\tTrain Loss: 1127.3569846691946\tTime: 0:00:00.026414\n",
      "Epoch: [24/50]\tSamples: [205/10250]\tValidation Loss: 1113.346270007622\tTime: 0:00:00.002434\n",
      "Epoch: [25/50]\tSamples: [23900/47800]\tTrain Loss: 1119.691667756276\tTime: 0:00:00.026556\n",
      "Epoch: [25/50]\tSamples: [205/10250]\tValidation Loss: 1113.3609565548782\tTime: 0:00:00.002907\n",
      "Epoch: [26/50]\tSamples: [24856/47800]\tTrain Loss: 1127.1744655465482\tTime: 0:00:00.026350\n",
      "Epoch: [26/50]\tSamples: [205/10250]\tValidation Loss: 1114.1521627286586\tTime: 0:00:00.003400\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  56%|█████▋    | 9/16 [00:19<00:16,  2.35s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1191.6721773666318\tTime: 0:00:00.035478\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.2186785442073\tTime: 0:00:00.003952\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1196.5241157819037\tTime: 0:00:00.027747\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1152.3397389481706\tTime: 0:00:00.002592\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1178.770601791318\tTime: 0:00:00.025125\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1153.5943025914635\tTime: 0:00:00.002552\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1173.7351799490064\tTime: 0:00:00.026812\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1154.8837938262195\tTime: 0:00:00.003099\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1183.686372254184\tTime: 0:00:00.027574\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1152.6774199695121\tTime: 0:00:00.002906\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1166.60648208682\tTime: 0:00:00.025170\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1152.856650152439\tTime: 0:00:00.002239\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  62%|██████▎   | 10/16 [00:21<00:13,  2.30s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1192.7949382191423\tTime: 0:00:00.036555\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.0147103658537\tTime: 0:00:00.003385\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1174.0873594403765\tTime: 0:00:00.032159\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1152.0216558689024\tTime: 0:00:00.002783\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1174.9910107217572\tTime: 0:00:00.031550\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1150.7003429878048\tTime: 0:00:00.003707\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1162.311372254184\tTime: 0:00:00.034425\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1146.658565167683\tTime: 0:00:00.003223\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1170.3130883891213\tTime: 0:00:00.030329\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1143.323466082317\tTime: 0:00:00.004665\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1159.567975287657\tTime: 0:00:00.037272\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1141.6889719893293\tTime: 0:00:00.004230\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1156.0617236532428\tTime: 0:00:00.032844\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1140.6061070884145\tTime: 0:00:00.004787\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1146.338773208682\tTime: 0:00:00.044234\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1138.3766387195121\tTime: 0:00:00.004484\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1144.9217932792887\tTime: 0:00:00.039308\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1136.5708555640244\tTime: 0:00:00.003581\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1156.1540190245817\tTime: 0:00:00.036003\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1132.6167016006098\tTime: 0:00:00.003275\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1149.2239882975941\tTime: 0:00:00.032306\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1131.526376714939\tTime: 0:00:00.004696\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1152.6545256929917\tTime: 0:00:00.031087\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1127.9142244664633\tTime: 0:00:00.002935\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1144.4078149516213\tTime: 0:00:00.039912\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1124.8954173018292\tTime: 0:00:00.003732\n",
      "Epoch: [14/100]\tSamples: [13384/95600]\tTrain Loss: 1139.4089712996863\tTime: 0:00:00.034860\n",
      "Epoch: [14/100]\tSamples: [205/20500]\tValidation Loss: 1121.1615758384146\tTime: 0:00:00.003182\n",
      "Epoch: [15/100]\tSamples: [14340/95600]\tTrain Loss: 1141.4436821718095\tTime: 0:00:00.033563\n",
      "Epoch: [15/100]\tSamples: [205/20500]\tValidation Loss: 1120.3510432545731\tTime: 0:00:00.003489\n",
      "Epoch: [16/100]\tSamples: [15296/95600]\tTrain Loss: 1137.3813210970188\tTime: 0:00:00.031913\n",
      "Epoch: [16/100]\tSamples: [205/20500]\tValidation Loss: 1117.987333269817\tTime: 0:00:00.003287\n",
      "Epoch: [17/100]\tSamples: [16252/95600]\tTrain Loss: 1137.809852248954\tTime: 0:00:00.032167\n",
      "Epoch: [17/100]\tSamples: [205/20500]\tValidation Loss: 1114.8453887195121\tTime: 0:00:00.003760\n",
      "Epoch: [18/100]\tSamples: [17208/95600]\tTrain Loss: 1146.154419456067\tTime: 0:00:00.042269\n",
      "Epoch: [18/100]\tSamples: [205/20500]\tValidation Loss: 1118.446503429878\tTime: 0:00:00.003937\n",
      "Epoch: [19/100]\tSamples: [18164/95600]\tTrain Loss: 1132.4422765755753\tTime: 0:00:00.051481\n",
      "Epoch: [19/100]\tSamples: [205/20500]\tValidation Loss: 1118.9256145198171\tTime: 0:00:00.008588\n",
      "Epoch: [20/100]\tSamples: [19120/95600]\tTrain Loss: 1129.810828811454\tTime: 0:00:00.040780\n",
      "Epoch: [20/100]\tSamples: [205/20500]\tValidation Loss: 1116.4530392530487\tTime: 0:00:00.003377\n",
      "Epoch: [21/100]\tSamples: [20076/95600]\tTrain Loss: 1127.1511261114017\tTime: 0:00:00.028237\n",
      "Epoch: [21/100]\tSamples: [205/20500]\tValidation Loss: 1114.9069169207316\tTime: 0:00:00.002861\n",
      "Epoch: [22/100]\tSamples: [21032/95600]\tTrain Loss: 1128.4675078451883\tTime: 0:00:00.026730\n",
      "Epoch: [22/100]\tSamples: [205/20500]\tValidation Loss: 1114.4131002286585\tTime: 0:00:00.002803\n",
      "Epoch: [23/100]\tSamples: [21988/95600]\tTrain Loss: 1131.8966519024582\tTime: 0:00:00.029195\n",
      "Epoch: [23/100]\tSamples: [205/20500]\tValidation Loss: 1117.574042492378\tTime: 0:00:00.003729\n",
      "Epoch: [24/100]\tSamples: [22944/95600]\tTrain Loss: 1124.9663964435147\tTime: 0:00:00.034412\n",
      "Epoch: [24/100]\tSamples: [205/20500]\tValidation Loss: 1116.6502191310976\tTime: 0:00:00.002883\n",
      "Epoch: [25/100]\tSamples: [23900/95600]\tTrain Loss: 1120.342021606956\tTime: 0:00:00.035962\n",
      "Epoch: [25/100]\tSamples: [205/20500]\tValidation Loss: 1117.626738757622\tTime: 0:00:00.002508\n",
      "Epoch: [26/100]\tSamples: [24856/95600]\tTrain Loss: 1127.4894743723848\tTime: 0:00:00.033024\n",
      "Epoch: [26/100]\tSamples: [205/20500]\tValidation Loss: 1117.262071265244\tTime: 0:00:00.003231\n",
      "Epoch: [27/100]\tSamples: [25812/95600]\tTrain Loss: 1117.18995979341\tTime: 0:00:00.031189\n",
      "Epoch: [27/100]\tSamples: [205/20500]\tValidation Loss: 1115.7211270960365\tTime: 0:00:00.003213\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  69%|██████▉   | 11/16 [00:24<00:12,  2.49s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1193.455650169979\tTime: 0:00:00.047914\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.5327124618902\tTime: 0:00:00.002869\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1189.3061911610878\tTime: 0:00:00.029881\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1152.9272675304878\tTime: 0:00:00.003523\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1190.3814722803347\tTime: 0:00:00.030491\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1153.184922827744\tTime: 0:00:00.002513\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1181.8481138859834\tTime: 0:00:00.028982\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1153.5223561356706\tTime: 0:00:00.002582\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1175.340726333682\tTime: 0:00:00.027055\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1151.7985137195121\tTime: 0:00:00.002409\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1174.6892120489017\tTime: 0:00:00.030499\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1150.2744569359756\tTime: 0:00:00.003506\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1177.3063260002616\tTime: 0:00:00.028094\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1149.1155201981708\tTime: 0:00:00.003317\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1167.3365258891213\tTime: 0:00:00.035045\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1149.232012195122\tTime: 0:00:00.003104\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1161.2012617677824\tTime: 0:00:00.033523\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1148.4087461890244\tTime: 0:00:00.005004\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1158.4269008237447\tTime: 0:00:00.030585\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1148.0168730945122\tTime: 0:00:00.003798\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1166.0606040794978\tTime: 0:00:00.040071\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1146.994764672256\tTime: 0:00:00.003464\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1171.8696636375523\tTime: 0:00:00.033497\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1146.7592797256098\tTime: 0:00:00.004056\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1162.0325493593095\tTime: 0:00:00.039712\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1145.9152867759146\tTime: 0:00:00.004586\n",
      "Epoch: [14/100]\tSamples: [13384/95600]\tTrain Loss: 1158.8439706459205\tTime: 0:00:00.040482\n",
      "Epoch: [14/100]\tSamples: [205/20500]\tValidation Loss: 1147.002391387195\tTime: 0:00:00.003817\n",
      "Epoch: [15/100]\tSamples: [14340/95600]\tTrain Loss: 1154.0889938546024\tTime: 0:00:00.034177\n",
      "Epoch: [15/100]\tSamples: [205/20500]\tValidation Loss: 1146.344188262195\tTime: 0:00:00.003248\n",
      "Epoch: [16/100]\tSamples: [15296/95600]\tTrain Loss: 1156.5123561715482\tTime: 0:00:00.031831\n",
      "Epoch: [16/100]\tSamples: [205/20500]\tValidation Loss: 1143.6051495807926\tTime: 0:00:00.003005\n",
      "Epoch: [17/100]\tSamples: [16252/95600]\tTrain Loss: 1163.0193146901152\tTime: 0:00:00.029935\n",
      "Epoch: [17/100]\tSamples: [205/20500]\tValidation Loss: 1142.8924542682928\tTime: 0:00:00.003194\n",
      "Epoch: [18/100]\tSamples: [17208/95600]\tTrain Loss: 1151.0276706328452\tTime: 0:00:00.032673\n",
      "Epoch: [18/100]\tSamples: [205/20500]\tValidation Loss: 1144.4179020579268\tTime: 0:00:00.002418\n",
      "Epoch: [19/100]\tSamples: [18164/95600]\tTrain Loss: 1160.4629151412134\tTime: 0:00:00.032248\n",
      "Epoch: [19/100]\tSamples: [205/20500]\tValidation Loss: 1141.6961556783538\tTime: 0:00:00.004929\n",
      "Epoch: [20/100]\tSamples: [19120/95600]\tTrain Loss: 1148.213952994247\tTime: 0:00:00.034484\n",
      "Epoch: [20/100]\tSamples: [205/20500]\tValidation Loss: 1140.9827076981708\tTime: 0:00:00.005087\n",
      "Epoch: [21/100]\tSamples: [20076/95600]\tTrain Loss: 1155.3962637290795\tTime: 0:00:00.035261\n",
      "Epoch: [21/100]\tSamples: [205/20500]\tValidation Loss: 1138.758669969512\tTime: 0:00:00.002458\n",
      "Epoch: [22/100]\tSamples: [21032/95600]\tTrain Loss: 1153.8493233525105\tTime: 0:00:00.033418\n",
      "Epoch: [22/100]\tSamples: [205/20500]\tValidation Loss: 1139.5513814786586\tTime: 0:00:00.003881\n",
      "Epoch: [23/100]\tSamples: [21988/95600]\tTrain Loss: 1150.1720220972804\tTime: 0:00:00.027150\n",
      "Epoch: [23/100]\tSamples: [205/20500]\tValidation Loss: 1138.0282869664634\tTime: 0:00:00.002786\n",
      "Epoch: [24/100]\tSamples: [22944/95600]\tTrain Loss: 1158.0711542233264\tTime: 0:00:00.028440\n",
      "Epoch: [24/100]\tSamples: [205/20500]\tValidation Loss: 1140.788614710366\tTime: 0:00:00.002721\n",
      "Epoch: [25/100]\tSamples: [23900/95600]\tTrain Loss: 1156.3894727379707\tTime: 0:00:00.032813\n",
      "Epoch: [25/100]\tSamples: [205/20500]\tValidation Loss: 1135.096317644817\tTime: 0:00:00.005063\n",
      "Epoch: [26/100]\tSamples: [24856/95600]\tTrain Loss: 1145.518816193776\tTime: 0:00:00.036074\n",
      "Epoch: [26/100]\tSamples: [205/20500]\tValidation Loss: 1136.7356135670732\tTime: 0:00:00.003619\n",
      "Epoch: [27/100]\tSamples: [25812/95600]\tTrain Loss: 1151.7064183446653\tTime: 0:00:00.038661\n",
      "Epoch: [27/100]\tSamples: [205/20500]\tValidation Loss: 1137.8957888719513\tTime: 0:00:00.003404\n",
      "Epoch: [28/100]\tSamples: [26768/95600]\tTrain Loss: 1144.7507967769352\tTime: 0:00:00.038333\n",
      "Epoch: [28/100]\tSamples: [205/20500]\tValidation Loss: 1132.1220560213415\tTime: 0:00:00.004488\n",
      "Epoch: [29/100]\tSamples: [27724/95600]\tTrain Loss: 1144.3479831328452\tTime: 0:00:00.037022\n",
      "Epoch: [29/100]\tSamples: [205/20500]\tValidation Loss: 1131.3275914634146\tTime: 0:00:00.003705\n",
      "Epoch: [30/100]\tSamples: [28680/95600]\tTrain Loss: 1135.8813170109834\tTime: 0:00:00.036208\n",
      "Epoch: [30/100]\tSamples: [205/20500]\tValidation Loss: 1131.7427591463415\tTime: 0:00:00.003873\n",
      "Epoch: [31/100]\tSamples: [29636/95600]\tTrain Loss: 1147.5920175209205\tTime: 0:00:00.037009\n",
      "Epoch: [31/100]\tSamples: [205/20500]\tValidation Loss: 1131.0373761432927\tTime: 0:00:00.003852\n",
      "Epoch: [32/100]\tSamples: [30592/95600]\tTrain Loss: 1140.69480583159\tTime: 0:00:00.036672\n",
      "Epoch: [32/100]\tSamples: [205/20500]\tValidation Loss: 1125.390301067073\tTime: 0:00:00.003146\n",
      "Epoch: [33/100]\tSamples: [31548/95600]\tTrain Loss: 1143.2168377353557\tTime: 0:00:00.037084\n",
      "Epoch: [33/100]\tSamples: [205/20500]\tValidation Loss: 1123.1978610899391\tTime: 0:00:00.003648\n",
      "Epoch: [34/100]\tSamples: [32504/95600]\tTrain Loss: 1135.2197469926778\tTime: 0:00:00.028279\n",
      "Epoch: [34/100]\tSamples: [205/20500]\tValidation Loss: 1119.7130573551829\tTime: 0:00:00.003301\n",
      "Epoch: [35/100]\tSamples: [33460/95600]\tTrain Loss: 1143.4557850091528\tTime: 0:00:00.029550\n",
      "Epoch: [35/100]\tSamples: [205/20500]\tValidation Loss: 1121.7483565167684\tTime: 0:00:00.003139\n",
      "Epoch: [36/100]\tSamples: [34416/95600]\tTrain Loss: 1134.986552856956\tTime: 0:00:00.035602\n",
      "Epoch: [36/100]\tSamples: [205/20500]\tValidation Loss: 1121.8533155487805\tTime: 0:00:00.003998\n",
      "Epoch: [37/100]\tSamples: [35372/95600]\tTrain Loss: 1125.7757501961298\tTime: 0:00:00.034575\n",
      "Epoch: [37/100]\tSamples: [205/20500]\tValidation Loss: 1118.1166634908536\tTime: 0:00:00.003759\n",
      "Epoch: [38/100]\tSamples: [36328/95600]\tTrain Loss: 1121.114821685408\tTime: 0:00:00.045442\n",
      "Epoch: [38/100]\tSamples: [205/20500]\tValidation Loss: 1114.570322027439\tTime: 0:00:00.003625\n",
      "Epoch: [39/100]\tSamples: [37284/95600]\tTrain Loss: 1136.5733688546024\tTime: 0:00:00.036578\n",
      "Epoch: [39/100]\tSamples: [205/20500]\tValidation Loss: 1115.551171875\tTime: 0:00:00.003986\n",
      "Epoch: [40/100]\tSamples: [38240/95600]\tTrain Loss: 1120.9673770920501\tTime: 0:00:00.034410\n",
      "Epoch: [40/100]\tSamples: [205/20500]\tValidation Loss: 1115.3646246189023\tTime: 0:00:00.002836\n",
      "Epoch: [41/100]\tSamples: [39196/95600]\tTrain Loss: 1130.0681101268306\tTime: 0:00:00.036813\n",
      "Epoch: [41/100]\tSamples: [205/20500]\tValidation Loss: 1113.7002810594513\tTime: 0:00:00.004000\n",
      "Epoch: [42/100]\tSamples: [40152/95600]\tTrain Loss: 1123.5250923444037\tTime: 0:00:00.037712\n",
      "Epoch: [42/100]\tSamples: [205/20500]\tValidation Loss: 1113.1676686356707\tTime: 0:00:00.003524\n",
      "Epoch: [43/100]\tSamples: [41108/95600]\tTrain Loss: 1123.428175666841\tTime: 0:00:00.039988\n",
      "Epoch: [43/100]\tSamples: [205/20500]\tValidation Loss: 1115.0808022103658\tTime: 0:00:00.004048\n",
      "Epoch: [44/100]\tSamples: [42064/95600]\tTrain Loss: 1128.154100745293\tTime: 0:00:00.037764\n",
      "Epoch: [44/100]\tSamples: [205/20500]\tValidation Loss: 1115.760408727134\tTime: 0:00:00.003177\n",
      "Epoch: [45/100]\tSamples: [43020/95600]\tTrain Loss: 1121.489670502092\tTime: 0:00:00.030976\n",
      "Epoch: [45/100]\tSamples: [205/20500]\tValidation Loss: 1114.1957269435975\tTime: 0:00:00.003193\n",
      "Epoch: [46/100]\tSamples: [43976/95600]\tTrain Loss: 1118.4099764644352\tTime: 0:00:00.027907\n",
      "Epoch: [46/100]\tSamples: [205/20500]\tValidation Loss: 1117.1304020579269\tTime: 0:00:00.004745\n",
      "Epoch: [47/100]\tSamples: [44932/95600]\tTrain Loss: 1115.5678731367677\tTime: 0:00:00.032652\n",
      "Epoch: [47/100]\tSamples: [205/20500]\tValidation Loss: 1111.8883050685977\tTime: 0:00:00.002843\n",
      "Epoch: [48/100]\tSamples: [45888/95600]\tTrain Loss: 1114.4217973653242\tTime: 0:00:00.031089\n",
      "Epoch: [48/100]\tSamples: [205/20500]\tValidation Loss: 1113.6822313262196\tTime: 0:00:00.003918\n",
      "Epoch: [49/100]\tSamples: [46844/95600]\tTrain Loss: 1131.3067182596758\tTime: 0:00:00.031917\n",
      "Epoch: [49/100]\tSamples: [205/20500]\tValidation Loss: 1113.805030487805\tTime: 0:00:00.003794\n",
      "Epoch: [50/100]\tSamples: [47800/95600]\tTrain Loss: 1131.2180390298117\tTime: 0:00:00.034243\n",
      "Epoch: [50/100]\tSamples: [205/20500]\tValidation Loss: 1113.516630144817\tTime: 0:00:00.003198\n",
      "Epoch: [51/100]\tSamples: [48756/95600]\tTrain Loss: 1122.6487071783472\tTime: 0:00:00.031027\n",
      "Epoch: [51/100]\tSamples: [205/20500]\tValidation Loss: 1112.9462509527439\tTime: 0:00:00.002342\n",
      "Epoch: [52/100]\tSamples: [49712/95600]\tTrain Loss: 1116.366868789226\tTime: 0:00:00.032600\n",
      "Epoch: [52/100]\tSamples: [205/20500]\tValidation Loss: 1114.4372237042683\tTime: 0:00:00.003962\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  75%|███████▌  | 12/16 [00:28<00:11,  2.91s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1181.519719207636\tTime: 0:00:00.031503\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1153.0141149009146\tTime: 0:00:00.003005\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1183.769972541841\tTime: 0:00:00.030524\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1154.2534632240854\tTime: 0:00:00.003786\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1164.0793548967051\tTime: 0:00:00.040652\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1155.7674256859757\tTime: 0:00:00.009230\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1167.0504870554394\tTime: 0:00:00.033498\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1154.836794969512\tTime: 0:00:00.002834\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1155.7491337604602\tTime: 0:00:00.027757\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1151.8128715701218\tTime: 0:00:00.004063\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1158.3637960904812\tTime: 0:00:00.035497\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1151.6368807164633\tTime: 0:00:00.002960\n",
      "Epoch: [7/50]\tSamples: [6692/47800]\tTrain Loss: 1152.194074431224\tTime: 0:00:00.033310\n",
      "Epoch: [7/50]\tSamples: [205/10250]\tValidation Loss: 1149.7604611280487\tTime: 0:00:00.003617\n",
      "Epoch: [8/50]\tSamples: [7648/47800]\tTrain Loss: 1150.2742955674687\tTime: 0:00:00.024548\n",
      "Epoch: [8/50]\tSamples: [205/10250]\tValidation Loss: 1149.0937928734756\tTime: 0:00:00.003657\n",
      "Epoch: [9/50]\tSamples: [8604/47800]\tTrain Loss: 1151.6059182139122\tTime: 0:00:00.025178\n",
      "Epoch: [9/50]\tSamples: [205/10250]\tValidation Loss: 1146.2728182164635\tTime: 0:00:00.003502\n",
      "Epoch: [10/50]\tSamples: [9560/47800]\tTrain Loss: 1151.90437042364\tTime: 0:00:00.035257\n",
      "Epoch: [10/50]\tSamples: [205/10250]\tValidation Loss: 1145.8707221798782\tTime: 0:00:00.004517\n",
      "Epoch: [11/50]\tSamples: [10516/47800]\tTrain Loss: 1150.1086517717051\tTime: 0:00:00.032059\n",
      "Epoch: [11/50]\tSamples: [205/10250]\tValidation Loss: 1144.7544778963415\tTime: 0:00:00.004351\n",
      "Epoch: [12/50]\tSamples: [11472/47800]\tTrain Loss: 1145.8637715742677\tTime: 0:00:00.026696\n",
      "Epoch: [12/50]\tSamples: [205/10250]\tValidation Loss: 1144.7540015243903\tTime: 0:00:00.003582\n",
      "Epoch: [13/50]\tSamples: [12428/47800]\tTrain Loss: 1148.4889064134413\tTime: 0:00:00.027843\n",
      "Epoch: [13/50]\tSamples: [205/10250]\tValidation Loss: 1142.1314977134145\tTime: 0:00:00.002582\n",
      "Epoch: [14/50]\tSamples: [13384/47800]\tTrain Loss: 1150.0924669848325\tTime: 0:00:00.031415\n",
      "Epoch: [14/50]\tSamples: [205/10250]\tValidation Loss: 1141.782841082317\tTime: 0:00:00.003853\n",
      "Epoch: [15/50]\tSamples: [14340/47800]\tTrain Loss: 1143.3595874738494\tTime: 0:00:00.039079\n",
      "Epoch: [15/50]\tSamples: [205/10250]\tValidation Loss: 1140.5366377667683\tTime: 0:00:00.003860\n",
      "Epoch: [16/50]\tSamples: [15296/47800]\tTrain Loss: 1150.684974830021\tTime: 0:00:00.030405\n",
      "Epoch: [16/50]\tSamples: [205/10250]\tValidation Loss: 1141.2743521341463\tTime: 0:00:00.002695\n",
      "Epoch: [17/50]\tSamples: [16252/47800]\tTrain Loss: 1137.2700583485878\tTime: 0:00:00.031715\n",
      "Epoch: [17/50]\tSamples: [205/10250]\tValidation Loss: 1138.7042111280489\tTime: 0:00:00.002578\n",
      "Epoch: [18/50]\tSamples: [17208/47800]\tTrain Loss: 1141.5976399058577\tTime: 0:00:00.025915\n",
      "Epoch: [18/50]\tSamples: [205/10250]\tValidation Loss: 1137.4652010289635\tTime: 0:00:00.002546\n",
      "Epoch: [19/50]\tSamples: [18164/47800]\tTrain Loss: 1139.1823189069037\tTime: 0:00:00.028636\n",
      "Epoch: [19/50]\tSamples: [205/10250]\tValidation Loss: 1135.3735375381098\tTime: 0:00:00.002509\n",
      "Epoch: [20/50]\tSamples: [19120/47800]\tTrain Loss: 1131.3429001046024\tTime: 0:00:00.029437\n",
      "Epoch: [20/50]\tSamples: [205/10250]\tValidation Loss: 1132.4139386432928\tTime: 0:00:00.003240\n",
      "Epoch: [21/50]\tSamples: [20076/47800]\tTrain Loss: 1130.570913147228\tTime: 0:00:00.030390\n",
      "Epoch: [21/50]\tSamples: [205/10250]\tValidation Loss: 1129.1534108231708\tTime: 0:00:00.003137\n",
      "Epoch: [22/50]\tSamples: [21032/47800]\tTrain Loss: 1136.254461950837\tTime: 0:00:00.030888\n",
      "Epoch: [22/50]\tSamples: [205/10250]\tValidation Loss: 1126.333770007622\tTime: 0:00:00.003165\n",
      "Epoch: [23/50]\tSamples: [21988/47800]\tTrain Loss: 1126.5306289225941\tTime: 0:00:00.028595\n",
      "Epoch: [23/50]\tSamples: [205/10250]\tValidation Loss: 1124.409979992378\tTime: 0:00:00.003573\n",
      "Epoch: [24/50]\tSamples: [22944/47800]\tTrain Loss: 1120.5514636179394\tTime: 0:00:00.027801\n",
      "Epoch: [24/50]\tSamples: [205/10250]\tValidation Loss: 1121.6192501905489\tTime: 0:00:00.002311\n",
      "Epoch: [25/50]\tSamples: [23900/47800]\tTrain Loss: 1123.3915770462866\tTime: 0:00:00.024879\n",
      "Epoch: [25/50]\tSamples: [205/10250]\tValidation Loss: 1116.1858755716464\tTime: 0:00:00.004194\n",
      "Epoch: [26/50]\tSamples: [24856/47800]\tTrain Loss: 1122.2539389382846\tTime: 0:00:00.031414\n",
      "Epoch: [26/50]\tSamples: [205/10250]\tValidation Loss: 1117.684012957317\tTime: 0:00:00.002868\n",
      "Epoch: [27/50]\tSamples: [25812/47800]\tTrain Loss: 1116.4674342965482\tTime: 0:00:00.028393\n",
      "Epoch: [27/50]\tSamples: [205/10250]\tValidation Loss: 1118.8965081935976\tTime: 0:00:00.002976\n",
      "Epoch: [28/50]\tSamples: [26768/47800]\tTrain Loss: 1120.9450714239017\tTime: 0:00:00.030255\n",
      "Epoch: [28/50]\tSamples: [205/10250]\tValidation Loss: 1118.0825504954269\tTime: 0:00:00.002999\n",
      "Epoch: [29/50]\tSamples: [27724/47800]\tTrain Loss: 1118.902605256276\tTime: 0:00:00.031710\n",
      "Epoch: [29/50]\tSamples: [205/10250]\tValidation Loss: 1117.2788633765244\tTime: 0:00:00.003088\n",
      "Epoch: [30/50]\tSamples: [28680/47800]\tTrain Loss: 1115.1110012421548\tTime: 0:00:00.029909\n",
      "Epoch: [30/50]\tSamples: [205/10250]\tValidation Loss: 1115.6538300304878\tTime: 0:00:00.002460\n",
      "Epoch: [31/50]\tSamples: [29636/47800]\tTrain Loss: 1119.0684124934623\tTime: 0:00:00.026283\n",
      "Epoch: [31/50]\tSamples: [205/10250]\tValidation Loss: 1114.6788443216462\tTime: 0:00:00.002653\n",
      "Epoch: [32/50]\tSamples: [30592/47800]\tTrain Loss: 1119.8366362120817\tTime: 0:00:00.035350\n",
      "Epoch: [32/50]\tSamples: [205/10250]\tValidation Loss: 1114.764677019817\tTime: 0:00:00.003529\n",
      "Epoch: [33/50]\tSamples: [31548/47800]\tTrain Loss: 1113.9757943253137\tTime: 0:00:00.040431\n",
      "Epoch: [33/50]\tSamples: [205/10250]\tValidation Loss: 1116.4537966844512\tTime: 0:00:00.004275\n",
      "Epoch: [34/50]\tSamples: [32504/47800]\tTrain Loss: 1112.0636073156381\tTime: 0:00:00.031044\n",
      "Epoch: [34/50]\tSamples: [205/10250]\tValidation Loss: 1113.459394054878\tTime: 0:00:00.003131\n",
      "Epoch: [35/50]\tSamples: [33460/47800]\tTrain Loss: 1113.6073524123954\tTime: 0:00:00.028579\n",
      "Epoch: [35/50]\tSamples: [205/10250]\tValidation Loss: 1115.6641720655489\tTime: 0:00:00.003771\n",
      "Epoch: [36/50]\tSamples: [34416/47800]\tTrain Loss: 1110.7351023143306\tTime: 0:00:00.025528\n",
      "Epoch: [36/50]\tSamples: [205/10250]\tValidation Loss: 1112.2583174542683\tTime: 0:00:00.002690\n",
      "Epoch: [37/50]\tSamples: [35372/47800]\tTrain Loss: 1116.5211166317993\tTime: 0:00:00.024975\n",
      "Epoch: [37/50]\tSamples: [205/10250]\tValidation Loss: 1112.6760718368903\tTime: 0:00:00.002753\n",
      "Epoch: [38/50]\tSamples: [36328/47800]\tTrain Loss: 1113.1372703648012\tTime: 0:00:00.029334\n",
      "Epoch: [38/50]\tSamples: [205/10250]\tValidation Loss: 1110.0860613567072\tTime: 0:00:00.004059\n",
      "Epoch: [39/50]\tSamples: [37284/47800]\tTrain Loss: 1109.9532884414225\tTime: 0:00:00.027933\n",
      "Epoch: [39/50]\tSamples: [205/10250]\tValidation Loss: 1111.4697694359756\tTime: 0:00:00.003841\n",
      "Epoch: [40/50]\tSamples: [38240/47800]\tTrain Loss: 1113.083673836297\tTime: 0:00:00.035190\n",
      "Epoch: [40/50]\tSamples: [205/10250]\tValidation Loss: 1110.3610899390244\tTime: 0:00:00.002855\n",
      "Epoch: [41/50]\tSamples: [39196/47800]\tTrain Loss: 1122.5372523862447\tTime: 0:00:00.032959\n",
      "Epoch: [41/50]\tSamples: [205/10250]\tValidation Loss: 1109.6293635670731\tTime: 0:00:00.002605\n",
      "Epoch: [42/50]\tSamples: [40152/47800]\tTrain Loss: 1108.673264252092\tTime: 0:00:00.033090\n",
      "Epoch: [42/50]\tSamples: [205/10250]\tValidation Loss: 1110.5770007621952\tTime: 0:00:00.002752\n",
      "Epoch: [43/50]\tSamples: [41108/47800]\tTrain Loss: 1108.0970351725941\tTime: 0:00:00.027781\n",
      "Epoch: [43/50]\tSamples: [205/10250]\tValidation Loss: 1108.5104658917683\tTime: 0:00:00.002327\n",
      "Epoch: [44/50]\tSamples: [42064/47800]\tTrain Loss: 1113.1246649450836\tTime: 0:00:00.028093\n",
      "Epoch: [44/50]\tSamples: [205/10250]\tValidation Loss: 1109.0508765243903\tTime: 0:00:00.002349\n",
      "Epoch: [45/50]\tSamples: [43020/47800]\tTrain Loss: 1114.7270446521966\tTime: 0:00:00.031013\n",
      "Epoch: [45/50]\tSamples: [205/10250]\tValidation Loss: 1109.1696122332316\tTime: 0:00:00.002891\n",
      "Epoch: [46/50]\tSamples: [43976/47800]\tTrain Loss: 1112.8732021443514\tTime: 0:00:00.028149\n",
      "Epoch: [46/50]\tSamples: [205/10250]\tValidation Loss: 1108.691525342988\tTime: 0:00:00.004611\n",
      "Epoch: [47/50]\tSamples: [44932/47800]\tTrain Loss: 1108.433659126569\tTime: 0:00:00.034178\n",
      "Epoch: [47/50]\tSamples: [205/10250]\tValidation Loss: 1109.8900724085365\tTime: 0:00:00.003504\n",
      "Epoch: [48/50]\tSamples: [45888/47800]\tTrain Loss: 1112.486082962866\tTime: 0:00:00.028742\n",
      "Epoch: [48/50]\tSamples: [205/10250]\tValidation Loss: 1109.6307545731706\tTime: 0:00:00.002606\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  81%|████████▏ | 13/16 [00:32<00:09,  3.08s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [956/47800]\tTrain Loss: 1191.6138287787658\tTime: 0:00:00.029720\n",
      "Epoch: [1/50]\tSamples: [205/10250]\tValidation Loss: 1152.4995665015244\tTime: 0:00:00.003618\n",
      "Epoch: [2/50]\tSamples: [1912/47800]\tTrain Loss: 1177.6419979079499\tTime: 0:00:00.031485\n",
      "Epoch: [2/50]\tSamples: [205/10250]\tValidation Loss: 1154.1273866234756\tTime: 0:00:00.002628\n",
      "Epoch: [3/50]\tSamples: [2868/47800]\tTrain Loss: 1166.5060269024582\tTime: 0:00:00.028919\n",
      "Epoch: [3/50]\tSamples: [205/10250]\tValidation Loss: 1155.6586270960365\tTime: 0:00:00.003811\n",
      "Epoch: [4/50]\tSamples: [3824/47800]\tTrain Loss: 1163.6949447567993\tTime: 0:00:00.027289\n",
      "Epoch: [4/50]\tSamples: [205/10250]\tValidation Loss: 1155.5199266387194\tTime: 0:00:00.002279\n",
      "Epoch: [5/50]\tSamples: [4780/47800]\tTrain Loss: 1161.1521394482218\tTime: 0:00:00.027997\n",
      "Epoch: [5/50]\tSamples: [205/10250]\tValidation Loss: 1152.0209651295731\tTime: 0:00:00.002659\n",
      "Epoch: [6/50]\tSamples: [5736/47800]\tTrain Loss: 1165.0869263206066\tTime: 0:00:00.032422\n",
      "Epoch: [6/50]\tSamples: [205/10250]\tValidation Loss: 1152.6494950457318\tTime: 0:00:00.003626\n",
      "Epoch: [7/50]\tSamples: [6692/47800]\tTrain Loss: 1160.3745995685147\tTime: 0:00:00.026870\n",
      "Epoch: [7/50]\tSamples: [205/10250]\tValidation Loss: 1150.5972751524391\tTime: 0:00:00.002425\n",
      "Epoch: [8/50]\tSamples: [7648/47800]\tTrain Loss: 1159.579015755753\tTime: 0:00:00.032680\n",
      "Epoch: [8/50]\tSamples: [205/10250]\tValidation Loss: 1151.050595464939\tTime: 0:00:00.003208\n",
      "Epoch: [9/50]\tSamples: [8604/47800]\tTrain Loss: 1155.662370881276\tTime: 0:00:00.028274\n",
      "Epoch: [9/50]\tSamples: [205/10250]\tValidation Loss: 1151.3077839176829\tTime: 0:00:00.003348\n",
      "Epoch: [10/50]\tSamples: [9560/47800]\tTrain Loss: 1150.2987137160042\tTime: 0:00:00.028863\n",
      "Epoch: [10/50]\tSamples: [205/10250]\tValidation Loss: 1149.1716844512196\tTime: 0:00:00.002499\n",
      "Epoch: [11/50]\tSamples: [10516/47800]\tTrain Loss: 1152.45457145659\tTime: 0:00:00.027738\n",
      "Epoch: [11/50]\tSamples: [205/10250]\tValidation Loss: 1149.1666920731707\tTime: 0:00:00.003830\n",
      "Epoch: [12/50]\tSamples: [11472/47800]\tTrain Loss: 1149.2123676124477\tTime: 0:00:00.032474\n",
      "Epoch: [12/50]\tSamples: [205/10250]\tValidation Loss: 1149.0800733612805\tTime: 0:00:00.002912\n",
      "Epoch: [13/50]\tSamples: [12428/47800]\tTrain Loss: 1144.95464500523\tTime: 0:00:00.026721\n",
      "Epoch: [13/50]\tSamples: [205/10250]\tValidation Loss: 1148.124228277439\tTime: 0:00:00.002948\n",
      "Epoch: [14/50]\tSamples: [13384/47800]\tTrain Loss: 1150.9408914095188\tTime: 0:00:00.031217\n",
      "Epoch: [14/50]\tSamples: [205/10250]\tValidation Loss: 1147.1247618140244\tTime: 0:00:00.003712\n",
      "Epoch: [15/50]\tSamples: [14340/47800]\tTrain Loss: 1148.546433708159\tTime: 0:00:00.030388\n",
      "Epoch: [15/50]\tSamples: [205/10250]\tValidation Loss: 1144.1724180640244\tTime: 0:00:00.003680\n",
      "Epoch: [16/50]\tSamples: [15296/47800]\tTrain Loss: 1150.5793916710252\tTime: 0:00:00.034386\n",
      "Epoch: [16/50]\tSamples: [205/10250]\tValidation Loss: 1144.778672827744\tTime: 0:00:00.004148\n",
      "Epoch: [17/50]\tSamples: [16252/47800]\tTrain Loss: 1148.6369230517782\tTime: 0:00:00.031576\n",
      "Epoch: [17/50]\tSamples: [205/10250]\tValidation Loss: 1144.3561928353658\tTime: 0:00:00.002430\n",
      "Epoch: [18/50]\tSamples: [17208/47800]\tTrain Loss: 1149.3842180962342\tTime: 0:00:00.031601\n",
      "Epoch: [18/50]\tSamples: [205/10250]\tValidation Loss: 1140.3663157393294\tTime: 0:00:00.002472\n",
      "Epoch: [19/50]\tSamples: [18164/47800]\tTrain Loss: 1143.12883270136\tTime: 0:00:00.027419\n",
      "Epoch: [19/50]\tSamples: [205/10250]\tValidation Loss: 1142.4354801829268\tTime: 0:00:00.002612\n",
      "Epoch: [20/50]\tSamples: [19120/47800]\tTrain Loss: 1150.2967932792887\tTime: 0:00:00.027346\n",
      "Epoch: [20/50]\tSamples: [205/10250]\tValidation Loss: 1140.2558260289634\tTime: 0:00:00.004744\n",
      "Epoch: [21/50]\tSamples: [20076/47800]\tTrain Loss: 1144.2220024843095\tTime: 0:00:00.032120\n",
      "Epoch: [21/50]\tSamples: [205/10250]\tValidation Loss: 1140.746846417683\tTime: 0:00:00.005053\n",
      "Epoch: [22/50]\tSamples: [21032/47800]\tTrain Loss: 1138.2846904419457\tTime: 0:00:00.035132\n",
      "Epoch: [22/50]\tSamples: [205/10250]\tValidation Loss: 1136.6069216844512\tTime: 0:00:00.003856\n",
      "Epoch: [23/50]\tSamples: [21988/47800]\tTrain Loss: 1136.2311797201883\tTime: 0:00:00.030859\n",
      "Epoch: [23/50]\tSamples: [205/10250]\tValidation Loss: 1135.8146960746951\tTime: 0:00:00.002685\n",
      "Epoch: [24/50]\tSamples: [22944/47800]\tTrain Loss: 1135.182841919456\tTime: 0:00:00.030906\n",
      "Epoch: [24/50]\tSamples: [205/10250]\tValidation Loss: 1129.9983041158537\tTime: 0:00:00.003023\n",
      "Epoch: [25/50]\tSamples: [23900/47800]\tTrain Loss: 1131.1829563284518\tTime: 0:00:00.029339\n",
      "Epoch: [25/50]\tSamples: [205/10250]\tValidation Loss: 1133.308165015244\tTime: 0:00:00.002617\n",
      "Epoch: [26/50]\tSamples: [24856/47800]\tTrain Loss: 1129.968194299163\tTime: 0:00:00.026889\n",
      "Epoch: [26/50]\tSamples: [205/10250]\tValidation Loss: 1130.0745760289635\tTime: 0:00:00.002935\n",
      "Epoch: [27/50]\tSamples: [25812/47800]\tTrain Loss: 1125.2382935081066\tTime: 0:00:00.033872\n",
      "Epoch: [27/50]\tSamples: [205/10250]\tValidation Loss: 1130.0336985518293\tTime: 0:00:00.002575\n",
      "Epoch: [28/50]\tSamples: [26768/47800]\tTrain Loss: 1132.13433250523\tTime: 0:00:00.035893\n",
      "Epoch: [28/50]\tSamples: [205/10250]\tValidation Loss: 1127.7667730564024\tTime: 0:00:00.003379\n",
      "Epoch: [29/50]\tSamples: [27724/47800]\tTrain Loss: 1130.1895593619247\tTime: 0:00:00.033900\n",
      "Epoch: [29/50]\tSamples: [205/10250]\tValidation Loss: 1126.6688024009147\tTime: 0:00:00.003811\n",
      "Epoch: [30/50]\tSamples: [28680/47800]\tTrain Loss: 1129.6782083551254\tTime: 0:00:00.032074\n",
      "Epoch: [30/50]\tSamples: [205/10250]\tValidation Loss: 1127.832469512195\tTime: 0:00:00.003996\n",
      "Epoch: [31/50]\tSamples: [29636/47800]\tTrain Loss: 1119.4487529419457\tTime: 0:00:00.029147\n",
      "Epoch: [31/50]\tSamples: [205/10250]\tValidation Loss: 1124.1172732469513\tTime: 0:00:00.003774\n",
      "Epoch: [32/50]\tSamples: [30592/47800]\tTrain Loss: 1128.0908080543934\tTime: 0:00:00.033318\n",
      "Epoch: [32/50]\tSamples: [205/10250]\tValidation Loss: 1121.8949980945122\tTime: 0:00:00.003578\n",
      "Epoch: [33/50]\tSamples: [31548/47800]\tTrain Loss: 1122.3591543540795\tTime: 0:00:00.032903\n",
      "Epoch: [33/50]\tSamples: [205/10250]\tValidation Loss: 1122.8663729039633\tTime: 0:00:00.002605\n",
      "Epoch: [34/50]\tSamples: [32504/47800]\tTrain Loss: 1120.3115193514645\tTime: 0:00:00.032570\n",
      "Epoch: [34/50]\tSamples: [205/10250]\tValidation Loss: 1124.9065215320122\tTime: 0:00:00.003303\n",
      "Epoch: [35/50]\tSamples: [33460/47800]\tTrain Loss: 1122.4196644547594\tTime: 0:00:00.031546\n",
      "Epoch: [35/50]\tSamples: [205/10250]\tValidation Loss: 1120.3225228658537\tTime: 0:00:00.003328\n",
      "Epoch: [36/50]\tSamples: [34416/47800]\tTrain Loss: 1123.9731792625523\tTime: 0:00:00.024801\n",
      "Epoch: [36/50]\tSamples: [205/10250]\tValidation Loss: 1120.9584508384146\tTime: 0:00:00.002485\n",
      "Epoch: [37/50]\tSamples: [35372/47800]\tTrain Loss: 1112.0399695998954\tTime: 0:00:00.024941\n",
      "Epoch: [37/50]\tSamples: [205/10250]\tValidation Loss: 1120.2019817073171\tTime: 0:00:00.002857\n",
      "Epoch: [38/50]\tSamples: [36328/47800]\tTrain Loss: 1126.1002059361924\tTime: 0:00:00.028318\n",
      "Epoch: [38/50]\tSamples: [205/10250]\tValidation Loss: 1120.7838509908536\tTime: 0:00:00.003082\n",
      "Epoch: [39/50]\tSamples: [37284/47800]\tTrain Loss: 1113.4369769874477\tTime: 0:00:00.031830\n",
      "Epoch: [39/50]\tSamples: [205/10250]\tValidation Loss: 1119.4610518292684\tTime: 0:00:00.003979\n",
      "Epoch: [40/50]\tSamples: [38240/47800]\tTrain Loss: 1117.0956704367154\tTime: 0:00:00.034494\n",
      "Epoch: [40/50]\tSamples: [205/10250]\tValidation Loss: 1118.8264576981708\tTime: 0:00:00.003817\n",
      "Epoch: [41/50]\tSamples: [39196/47800]\tTrain Loss: 1110.8425201032949\tTime: 0:00:00.034162\n",
      "Epoch: [41/50]\tSamples: [205/10250]\tValidation Loss: 1118.3953410823171\tTime: 0:00:00.003153\n",
      "Epoch: [42/50]\tSamples: [40152/47800]\tTrain Loss: 1117.3427530073222\tTime: 0:00:00.031747\n",
      "Epoch: [42/50]\tSamples: [205/10250]\tValidation Loss: 1117.6815310594511\tTime: 0:00:00.002650\n",
      "Epoch: [43/50]\tSamples: [41108/47800]\tTrain Loss: 1118.9427464696653\tTime: 0:00:00.026326\n",
      "Epoch: [43/50]\tSamples: [205/10250]\tValidation Loss: 1119.0090748856708\tTime: 0:00:00.002330\n",
      "Epoch: [44/50]\tSamples: [42064/47800]\tTrain Loss: 1112.1167298640166\tTime: 0:00:00.030226\n",
      "Epoch: [44/50]\tSamples: [205/10250]\tValidation Loss: 1116.6274104420731\tTime: 0:00:00.003653\n",
      "Epoch: [45/50]\tSamples: [43020/47800]\tTrain Loss: 1119.5311355910042\tTime: 0:00:00.032344\n",
      "Epoch: [45/50]\tSamples: [205/10250]\tValidation Loss: 1114.0034108231707\tTime: 0:00:00.003497\n",
      "Epoch: [46/50]\tSamples: [43976/47800]\tTrain Loss: 1112.675245979341\tTime: 0:00:00.034873\n",
      "Epoch: [46/50]\tSamples: [205/10250]\tValidation Loss: 1116.122403772866\tTime: 0:00:00.003350\n",
      "Epoch: [47/50]\tSamples: [44932/47800]\tTrain Loss: 1115.0880254641736\tTime: 0:00:00.033840\n",
      "Epoch: [47/50]\tSamples: [205/10250]\tValidation Loss: 1115.5538490853658\tTime: 0:00:00.003120\n",
      "Epoch: [48/50]\tSamples: [45888/47800]\tTrain Loss: 1113.8299391997907\tTime: 0:00:00.028835\n",
      "Epoch: [48/50]\tSamples: [205/10250]\tValidation Loss: 1114.596346227134\tTime: 0:00:00.003423\n",
      "Epoch: [49/50]\tSamples: [46844/47800]\tTrain Loss: 1121.0972067860878\tTime: 0:00:00.027668\n",
      "Epoch: [49/50]\tSamples: [205/10250]\tValidation Loss: 1114.9737042682927\tTime: 0:00:00.002647\n",
      "Epoch: [50/50]\tSamples: [47800/47800]\tTrain Loss: 1116.7640886506276\tTime: 0:00:00.026554\n",
      "Epoch: [50/50]\tSamples: [205/10250]\tValidation Loss: 1113.588252667683\tTime: 0:00:00.002446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  88%|████████▊ | 14/16 [00:35<00:06,  3.21s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1187.6001977641213\tTime: 0:00:00.033870\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.492978277439\tTime: 0:00:00.004436\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1172.8392308446653\tTime: 0:00:00.024221\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1155.3724561737804\tTime: 0:00:00.002724\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1175.3372777196653\tTime: 0:00:00.025833\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1155.4211937881098\tTime: 0:00:00.003093\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1168.3710692337866\tTime: 0:00:00.024825\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1148.7686070884147\tTime: 0:00:00.002825\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1153.0177497384936\tTime: 0:00:00.029301\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1142.171660632622\tTime: 0:00:00.002624\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1158.1183479341005\tTime: 0:00:00.026895\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1139.1110851753049\tTime: 0:00:00.003364\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1144.888917037134\tTime: 0:00:00.026610\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1135.5489900914633\tTime: 0:00:00.003416\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1156.0508384544978\tTime: 0:00:00.027749\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1131.290253429878\tTime: 0:00:00.002745\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1142.5383351856694\tTime: 0:00:00.037971\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1131.9091129954268\tTime: 0:00:00.002984\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1142.3292200575313\tTime: 0:00:00.026575\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1126.831602515244\tTime: 0:00:00.003009\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1138.089459662657\tTime: 0:00:00.027211\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1125.0198361280488\tTime: 0:00:00.002759\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1144.1828582635983\tTime: 0:00:00.033134\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1123.0186023246952\tTime: 0:00:00.004057\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1130.0546629837866\tTime: 0:00:00.026949\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1119.3930640243902\tTime: 0:00:00.003358\n",
      "Epoch: [14/100]\tSamples: [13384/95600]\tTrain Loss: 1136.3122303216528\tTime: 0:00:00.030756\n",
      "Epoch: [14/100]\tSamples: [205/20500]\tValidation Loss: 1119.020626905488\tTime: 0:00:00.002897\n",
      "Epoch: [15/100]\tSamples: [14340/95600]\tTrain Loss: 1126.3044668540795\tTime: 0:00:00.039253\n",
      "Epoch: [15/100]\tSamples: [205/20500]\tValidation Loss: 1118.0148580411585\tTime: 0:00:00.004251\n",
      "Epoch: [16/100]\tSamples: [15296/95600]\tTrain Loss: 1125.8621943645398\tTime: 0:00:00.032760\n",
      "Epoch: [16/100]\tSamples: [205/20500]\tValidation Loss: 1114.7493616615855\tTime: 0:00:00.003555\n",
      "Epoch: [17/100]\tSamples: [16252/95600]\tTrain Loss: 1125.52879020659\tTime: 0:00:00.033660\n",
      "Epoch: [17/100]\tSamples: [205/20500]\tValidation Loss: 1116.6615472560975\tTime: 0:00:00.003237\n",
      "Epoch: [18/100]\tSamples: [17208/95600]\tTrain Loss: 1129.5461395135983\tTime: 0:00:00.031776\n",
      "Epoch: [18/100]\tSamples: [205/20500]\tValidation Loss: 1115.0537442835366\tTime: 0:00:00.002960\n",
      "Epoch: [19/100]\tSamples: [18164/95600]\tTrain Loss: 1114.8422218226988\tTime: 0:00:00.034676\n",
      "Epoch: [19/100]\tSamples: [205/20500]\tValidation Loss: 1113.7275914634147\tTime: 0:00:00.003341\n",
      "Epoch: [20/100]\tSamples: [19120/95600]\tTrain Loss: 1122.5050503399582\tTime: 0:00:00.040022\n",
      "Epoch: [20/100]\tSamples: [205/20500]\tValidation Loss: 1114.2509241615853\tTime: 0:00:00.002449\n",
      "Epoch: [21/100]\tSamples: [20076/95600]\tTrain Loss: 1113.3160671090482\tTime: 0:00:00.033453\n",
      "Epoch: [21/100]\tSamples: [205/20500]\tValidation Loss: 1113.556288109756\tTime: 0:00:00.004134\n",
      "Epoch: [22/100]\tSamples: [21032/95600]\tTrain Loss: 1119.2727469599895\tTime: 0:00:00.031846\n",
      "Epoch: [22/100]\tSamples: [205/20500]\tValidation Loss: 1112.5891244283537\tTime: 0:00:00.002946\n",
      "Epoch: [23/100]\tSamples: [21988/95600]\tTrain Loss: 1112.4194397228034\tTime: 0:00:00.029050\n",
      "Epoch: [23/100]\tSamples: [205/20500]\tValidation Loss: 1111.3376333841463\tTime: 0:00:00.002471\n",
      "Epoch: [24/100]\tSamples: [22944/95600]\tTrain Loss: 1114.538911316684\tTime: 0:00:00.025829\n",
      "Epoch: [24/100]\tSamples: [205/20500]\tValidation Loss: 1111.156259527439\tTime: 0:00:00.002745\n",
      "Epoch: [25/100]\tSamples: [23900/95600]\tTrain Loss: 1119.0067542167887\tTime: 0:00:00.026570\n",
      "Epoch: [25/100]\tSamples: [205/20500]\tValidation Loss: 1107.832469512195\tTime: 0:00:00.002600\n",
      "Epoch: [26/100]\tSamples: [24856/95600]\tTrain Loss: 1112.9440090546548\tTime: 0:00:00.027033\n",
      "Epoch: [26/100]\tSamples: [205/20500]\tValidation Loss: 1109.2978658536585\tTime: 0:00:00.004450\n",
      "Epoch: [27/100]\tSamples: [25812/95600]\tTrain Loss: 1108.4876193122384\tTime: 0:00:00.030618\n",
      "Epoch: [27/100]\tSamples: [205/20500]\tValidation Loss: 1110.321689214939\tTime: 0:00:00.003740\n",
      "Epoch: [28/100]\tSamples: [26768/95600]\tTrain Loss: 1116.57081916841\tTime: 0:00:00.032727\n",
      "Epoch: [28/100]\tSamples: [205/20500]\tValidation Loss: 1107.3965510670732\tTime: 0:00:00.003563\n",
      "Epoch: [29/100]\tSamples: [27724/95600]\tTrain Loss: 1110.7797871992677\tTime: 0:00:00.032158\n",
      "Epoch: [29/100]\tSamples: [205/20500]\tValidation Loss: 1106.2088176448171\tTime: 0:00:00.002914\n",
      "Epoch: [30/100]\tSamples: [28680/95600]\tTrain Loss: 1117.482667037134\tTime: 0:00:00.030077\n",
      "Epoch: [30/100]\tSamples: [205/20500]\tValidation Loss: 1105.908641387195\tTime: 0:00:00.002977\n",
      "Epoch: [31/100]\tSamples: [29636/95600]\tTrain Loss: 1114.2112807269875\tTime: 0:00:00.029218\n",
      "Epoch: [31/100]\tSamples: [205/20500]\tValidation Loss: 1104.5628763338414\tTime: 0:00:00.002579\n",
      "Epoch: [32/100]\tSamples: [30592/95600]\tTrain Loss: 1115.5719101399059\tTime: 0:00:00.029344\n",
      "Epoch: [32/100]\tSamples: [205/20500]\tValidation Loss: 1105.9280535442074\tTime: 0:00:00.003244\n",
      "Epoch: [33/100]\tSamples: [31548/95600]\tTrain Loss: 1107.3260656380753\tTime: 0:00:00.033444\n",
      "Epoch: [33/100]\tSamples: [205/20500]\tValidation Loss: 1107.6536775914635\tTime: 0:00:00.003086\n",
      "Epoch: [34/100]\tSamples: [32504/95600]\tTrain Loss: 1111.5313603229602\tTime: 0:00:00.033720\n",
      "Epoch: [34/100]\tSamples: [205/20500]\tValidation Loss: 1107.2631955030488\tTime: 0:00:00.004246\n",
      "Epoch: [35/100]\tSamples: [33460/95600]\tTrain Loss: 1109.4904877092051\tTime: 0:00:00.031731\n",
      "Epoch: [35/100]\tSamples: [205/20500]\tValidation Loss: 1107.0061975990855\tTime: 0:00:00.003693\n",
      "Epoch: [36/100]\tSamples: [34416/95600]\tTrain Loss: 1124.2942027327406\tTime: 0:00:00.031657\n",
      "Epoch: [36/100]\tSamples: [205/20500]\tValidation Loss: 1107.281016577744\tTime: 0:00:00.002780\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params:  94%|█████████▍| 15/16 [00:38<00:03,  3.13s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [956/95600]\tTrain Loss: 1179.2978066161088\tTime: 0:00:00.028482\n",
      "Epoch: [1/100]\tSamples: [205/20500]\tValidation Loss: 1152.2553925304878\tTime: 0:00:00.002975\n",
      "Epoch: [2/100]\tSamples: [1912/95600]\tTrain Loss: 1174.1072543475418\tTime: 0:00:00.026631\n",
      "Epoch: [2/100]\tSamples: [205/20500]\tValidation Loss: 1152.8133431783538\tTime: 0:00:00.002697\n",
      "Epoch: [3/100]\tSamples: [2868/95600]\tTrain Loss: 1172.6026739016736\tTime: 0:00:00.025888\n",
      "Epoch: [3/100]\tSamples: [205/20500]\tValidation Loss: 1154.071169969512\tTime: 0:00:00.002614\n",
      "Epoch: [4/100]\tSamples: [3824/95600]\tTrain Loss: 1164.665320998954\tTime: 0:00:00.030206\n",
      "Epoch: [4/100]\tSamples: [205/20500]\tValidation Loss: 1152.7749666539635\tTime: 0:00:00.002397\n",
      "Epoch: [5/100]\tSamples: [4780/95600]\tTrain Loss: 1161.8813496992677\tTime: 0:00:00.024623\n",
      "Epoch: [5/100]\tSamples: [205/20500]\tValidation Loss: 1147.6921303353658\tTime: 0:00:00.002566\n",
      "Epoch: [6/100]\tSamples: [5736/95600]\tTrain Loss: 1167.299776085251\tTime: 0:00:00.026402\n",
      "Epoch: [6/100]\tSamples: [205/20500]\tValidation Loss: 1145.2720274390244\tTime: 0:00:00.002577\n",
      "Epoch: [7/100]\tSamples: [6692/95600]\tTrain Loss: 1170.617375457636\tTime: 0:00:00.025466\n",
      "Epoch: [7/100]\tSamples: [205/20500]\tValidation Loss: 1144.3930306783536\tTime: 0:00:00.003267\n",
      "Epoch: [8/100]\tSamples: [7648/95600]\tTrain Loss: 1156.4553314592051\tTime: 0:00:00.025628\n",
      "Epoch: [8/100]\tSamples: [205/20500]\tValidation Loss: 1143.2294016768292\tTime: 0:00:00.003481\n",
      "Epoch: [9/100]\tSamples: [8604/95600]\tTrain Loss: 1156.908080543933\tTime: 0:00:00.028976\n",
      "Epoch: [9/100]\tSamples: [205/20500]\tValidation Loss: 1141.5510956554879\tTime: 0:00:00.002560\n",
      "Epoch: [10/100]\tSamples: [9560/95600]\tTrain Loss: 1142.2490929001046\tTime: 0:00:00.025705\n",
      "Epoch: [10/100]\tSamples: [205/20500]\tValidation Loss: 1139.3034441692073\tTime: 0:00:00.003570\n",
      "Epoch: [11/100]\tSamples: [10516/95600]\tTrain Loss: 1157.4656160107218\tTime: 0:00:00.022559\n",
      "Epoch: [11/100]\tSamples: [205/20500]\tValidation Loss: 1134.168154535061\tTime: 0:00:00.002249\n",
      "Epoch: [12/100]\tSamples: [11472/95600]\tTrain Loss: 1147.5848833028242\tTime: 0:00:00.030879\n",
      "Epoch: [12/100]\tSamples: [205/20500]\tValidation Loss: 1132.9197694359757\tTime: 0:00:00.003337\n",
      "Epoch: [13/100]\tSamples: [12428/95600]\tTrain Loss: 1137.3413800993724\tTime: 0:00:00.028432\n",
      "Epoch: [13/100]\tSamples: [205/20500]\tValidation Loss: 1129.2776343368903\tTime: 0:00:00.003727\n",
      "Epoch: [14/100]\tSamples: [13384/95600]\tTrain Loss: 1131.3062687957636\tTime: 0:00:00.024616\n",
      "Epoch: [14/100]\tSamples: [205/20500]\tValidation Loss: 1125.067997332317\tTime: 0:00:00.002702\n",
      "Epoch: [15/100]\tSamples: [14340/95600]\tTrain Loss: 1141.3252402588912\tTime: 0:00:00.026618\n",
      "Epoch: [15/100]\tSamples: [205/20500]\tValidation Loss: 1123.4324790396342\tTime: 0:00:00.003764\n",
      "Epoch: [16/100]\tSamples: [15296/95600]\tTrain Loss: 1130.9973440768829\tTime: 0:00:00.036535\n",
      "Epoch: [16/100]\tSamples: [205/20500]\tValidation Loss: 1118.8652724847561\tTime: 0:00:00.003788\n",
      "Epoch: [17/100]\tSamples: [16252/95600]\tTrain Loss: 1131.3140567795501\tTime: 0:00:00.032957\n",
      "Epoch: [17/100]\tSamples: [205/20500]\tValidation Loss: 1116.4637957317073\tTime: 0:00:00.004519\n",
      "Epoch: [18/100]\tSamples: [17208/95600]\tTrain Loss: 1133.9312483655858\tTime: 0:00:00.030589\n",
      "Epoch: [18/100]\tSamples: [205/20500]\tValidation Loss: 1115.6377858231708\tTime: 0:00:00.002726\n",
      "Epoch: [19/100]\tSamples: [18164/95600]\tTrain Loss: 1133.6307122777196\tTime: 0:00:00.024912\n",
      "Epoch: [19/100]\tSamples: [205/20500]\tValidation Loss: 1113.2222513338415\tTime: 0:00:00.004146\n",
      "Epoch: [20/100]\tSamples: [19120/95600]\tTrain Loss: 1126.37004363886\tTime: 0:00:00.033812\n",
      "Epoch: [20/100]\tSamples: [205/20500]\tValidation Loss: 1113.5993807164634\tTime: 0:00:00.003644\n",
      "Epoch: [21/100]\tSamples: [20076/95600]\tTrain Loss: 1128.290088094927\tTime: 0:00:00.030877\n",
      "Epoch: [21/100]\tSamples: [205/20500]\tValidation Loss: 1111.4423780487805\tTime: 0:00:00.003365\n",
      "Epoch: [22/100]\tSamples: [21032/95600]\tTrain Loss: 1116.3381112709205\tTime: 0:00:00.030049\n",
      "Epoch: [22/100]\tSamples: [205/20500]\tValidation Loss: 1108.2942549542684\tTime: 0:00:00.003279\n",
      "Epoch: [23/100]\tSamples: [21988/95600]\tTrain Loss: 1121.4179238036088\tTime: 0:00:00.032740\n",
      "Epoch: [23/100]\tSamples: [205/20500]\tValidation Loss: 1110.9844178734756\tTime: 0:00:00.003241\n",
      "Epoch: [24/100]\tSamples: [22944/95600]\tTrain Loss: 1118.9543426385983\tTime: 0:00:00.028852\n",
      "Epoch: [24/100]\tSamples: [205/20500]\tValidation Loss: 1113.5355802210365\tTime: 0:00:00.002972\n",
      "Epoch: [25/100]\tSamples: [23900/95600]\tTrain Loss: 1126.2153013859834\tTime: 0:00:00.027334\n",
      "Epoch: [25/100]\tSamples: [205/20500]\tValidation Loss: 1110.4899866615854\tTime: 0:00:00.007478\n",
      "Epoch: [26/100]\tSamples: [24856/95600]\tTrain Loss: 1117.6513263271443\tTime: 0:00:00.025382\n",
      "Epoch: [26/100]\tSamples: [205/20500]\tValidation Loss: 1109.1956793064023\tTime: 0:00:00.002879\n",
      "Epoch: [27/100]\tSamples: [25812/95600]\tTrain Loss: 1119.011767782427\tTime: 0:00:00.024408\n",
      "Epoch: [27/100]\tSamples: [205/20500]\tValidation Loss: 1109.325076219512\tTime: 0:00:00.002323\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NeuralLDA Params: 100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\u001B[A\n",
      "Overall Model Parameter Search:  80%|████████  | 4/5 [02:25<00:36, 36.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NeuralLDA Params: {'num_topics': 2, 'num_epochs': 50, 'lr': 0.001} with Score: 0.776061086940576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching NMF Params:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Searching NMF Params:  25%|██▌       | 1/4 [00:01<00:05,  1.75s/it]\u001B[A\n",
      "Searching NMF Params:  50%|█████     | 2/4 [00:03<00:03,  1.71s/it]\u001B[A\n",
      "Searching NMF Params:  75%|███████▌  | 3/4 [00:05<00:01,  1.80s/it]\u001B[A\n",
      "Searching NMF Params: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\u001B[A\n",
      "Overall Model Parameter Search: 100%|██████████| 5/5 [02:32<00:00, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NMF Params: {'num_topics': 2, 'random_state': 42} with Score: 0.6035502327204885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:56:56.016330Z",
     "start_time": "2024-10-13T14:56:56.007705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Summarize results\n",
    "import pandas as pd\n",
    "\n",
    "summary = []\n",
    "for model_name, model_info in best_models.items():\n",
    "    summary.append({\n",
    "        'Model': model_name,\n",
    "        'Best_Params': model_info['params'],\n",
    "        'Best_Score': model_info['score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df)"
   ],
   "id": "8305f9444374804e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Model                                        Best_Params  Best_Score\n",
      "0        LDA  {'num_topics': 2, 'iterations': 500, 'random_s...    0.601787\n",
      "1        CTM                 {'num_topics': 3, 'num_epochs': 5}    0.617309\n",
      "2        ETM                {'num_topics': 5, 'num_epochs': 50}    0.639376\n",
      "3  NeuralLDA   {'num_topics': 2, 'num_epochs': 50, 'lr': 0.001}    0.776061\n",
      "4        NMF              {'num_topics': 2, 'random_state': 42}    0.603550\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:59:53.072946Z",
     "start_time": "2024-10-13T14:59:53.065946Z"
    }
   },
   "cell_type": "code",
   "source": "best_models['LDA']",
   "id": "de60ceeb19d39127",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'topic-word-matrix': array([[0.00185909, 0.00224993, 0.00613317, ..., 0.00109303, 0.00014323,\n",
       "          0.00078758],\n",
       "         [0.00183788, 0.00327841, 0.00513837, ..., 0.00229301, 0.00082292,\n",
       "          0.00063022]], dtype=float32),\n",
       "  'topics': [['nigga',\n",
       "    'make',\n",
       "    'fuck',\n",
       "    'man',\n",
       "    'shit',\n",
       "    'let',\n",
       "    'one',\n",
       "    'want',\n",
       "    'time',\n",
       "    'come'],\n",
       "   ['nigga',\n",
       "    'want',\n",
       "    'say',\n",
       "    'see',\n",
       "    'one',\n",
       "    'make',\n",
       "    'back',\n",
       "    'come',\n",
       "    'shit',\n",
       "    'take']],\n",
       "  'topic-document-matrix': array([[0.99390554, 0.97734255, 0.49285874, ..., 0.6869083 , 0.07091396,\n",
       "          0.02274054],\n",
       "         [0.00609445, 0.02265745, 0.50714129, ..., 0.3130917 , 0.92908597,\n",
       "          0.97725952]]),\n",
       "  'test-topic-document-matrix': array([[0.        , 0.74635935, 0.99336243, 0.10644579, 0.7301811 ,\n",
       "          0.08416618, 0.91168082, 0.35630509, 0.23246025, 0.82655567,\n",
       "          0.98141748, 0.6418463 , 0.48036799, 0.03879594, 0.61559248,\n",
       "          0.79487765, 0.21062225, 0.29875869, 0.97067803, 0.13059388,\n",
       "          0.23503183, 0.49566445, 0.93691349, 0.11277758, 0.03411743,\n",
       "          0.0106312 , 0.        , 0.07223546, 0.60517806, 0.        ,\n",
       "          0.95843893, 0.52005237, 0.65197134, 0.41196641, 0.99249613,\n",
       "          0.99175584, 0.99447352, 0.98535478, 0.4253867 , 0.45379078,\n",
       "          0.02240094, 0.98645651, 0.53980279, 0.98768032, 0.98855466,\n",
       "          0.02236911, 0.27922407, 0.98866308, 0.98365062, 0.        ,\n",
       "          0.01122976, 0.99449599, 0.25712693, 0.55838805, 0.9875977 ,\n",
       "          0.73181993, 0.03308926, 0.56581342, 0.0114394 , 0.97287142,\n",
       "          0.62392622, 0.95429385, 0.97232324, 0.        , 0.98389018,\n",
       "          0.99065626, 0.41770974, 0.15221247, 0.98878598, 0.6353246 ,\n",
       "          0.44394973, 0.99348187, 0.06464209, 0.65352941, 0.9921816 ,\n",
       "          0.0898089 , 0.0171669 , 0.92749792, 0.80537277, 0.29033718,\n",
       "          0.95853376, 0.22837846, 0.84178787, 0.        , 0.98519337,\n",
       "          0.86829472, 0.48129341, 0.34859094, 0.78709006, 0.88768798,\n",
       "          0.4937014 , 0.99244529, 0.99177462, 0.9939639 , 0.98800504,\n",
       "          0.5350343 , 0.02294495, 0.77594656, 0.03521312, 0.96805739,\n",
       "          0.99555957, 0.99097061, 0.        , 0.21364465, 0.01734846,\n",
       "          0.0583994 , 0.73479325, 0.20512186, 0.10337514, 0.70218313,\n",
       "          0.89488542, 0.97628266, 0.33450118, 0.94172978, 0.53267968,\n",
       "          0.48022231, 0.        , 0.40887323, 0.66231805, 0.13882305,\n",
       "          0.99065882, 0.9848606 , 0.41098008, 0.23785917, 0.98347336,\n",
       "          0.44272509, 0.48553529, 0.4891409 , 0.9193275 , 0.        ,\n",
       "          0.76535028, 0.03877476, 0.72377908, 0.27084148, 0.99328464,\n",
       "          0.10260801, 0.83005476, 0.42547426, 0.60962808, 0.48840302,\n",
       "          0.67315185, 0.96391368, 0.36609468, 0.16527252, 0.07341606,\n",
       "          0.70427823, 0.07314361, 0.45920092, 0.11246315, 0.41109341,\n",
       "          0.73826522, 0.7712431 , 0.9948616 , 0.85784233, 0.98670268,\n",
       "          0.68252808, 0.99307364, 0.09685279, 0.02730245, 0.47597876,\n",
       "          0.3775714 , 0.09404229, 0.98271239, 0.20125848, 0.        ,\n",
       "          0.55287468, 0.05378971, 0.11161289, 0.82512301, 0.97319943,\n",
       "          0.47598118, 0.01462248, 0.30718547, 0.9949373 , 0.98148644,\n",
       "          0.98777711, 0.16045883, 0.33972034, 0.96856922, 0.03499629,\n",
       "          0.47111022, 0.97808522, 0.04979732, 0.97895938, 0.42672172,\n",
       "          0.        , 0.66582382, 0.07455814, 0.38513169, 0.76559764,\n",
       "          0.0208392 , 0.99559063, 0.99655265, 0.1206196 , 0.37680238,\n",
       "          0.61610609, 0.20628281, 0.71229511, 0.58239365, 0.18820992,\n",
       "          0.02828289, 0.02426737, 0.98750812, 0.05100671, 0.62270546],\n",
       "         [0.99145108, 0.25364068, 0.        , 0.89355421, 0.26981887,\n",
       "          0.91583383, 0.08831917, 0.64369494, 0.76753974, 0.17344432,\n",
       "          0.0185825 , 0.3581537 , 0.51963204, 0.96120405, 0.38440755,\n",
       "          0.20512235, 0.78937781, 0.70124131, 0.02932198, 0.86940616,\n",
       "          0.76496822, 0.50433558, 0.06308648, 0.88722247, 0.9658826 ,\n",
       "          0.9893688 , 0.99132514, 0.92776453, 0.39482197, 0.99484855,\n",
       "          0.04156106, 0.47994763, 0.34802866, 0.58803356, 0.        ,\n",
       "          0.        , 0.        , 0.01464525, 0.57461327, 0.54620916,\n",
       "          0.97759902, 0.01354351, 0.46019721, 0.01231972, 0.01144535,\n",
       "          0.97763085, 0.7207759 , 0.01133696, 0.01634936, 0.99026227,\n",
       "          0.98877025, 0.        , 0.74287301, 0.44161192, 0.01240228,\n",
       "          0.26818004, 0.96691078, 0.43418658, 0.98856056, 0.0271286 ,\n",
       "          0.37607375, 0.04570617, 0.02767681, 0.99316424, 0.01610982,\n",
       "          0.        , 0.58229023, 0.84778756, 0.01121401, 0.3646754 ,\n",
       "          0.55605024, 0.        , 0.93535787, 0.34647056, 0.        ,\n",
       "          0.91019112, 0.98283309, 0.072502  , 0.19462724, 0.70966285,\n",
       "          0.04146625, 0.77162147, 0.15821211, 0.99604112, 0.01480669,\n",
       "          0.13170525, 0.51870656, 0.65140903, 0.21290992, 0.11231204,\n",
       "          0.5062986 , 0.        , 0.        , 0.        , 0.01199494,\n",
       "          0.46496573, 0.97705501, 0.22405347, 0.96478689, 0.03194262,\n",
       "          0.        , 0.        , 0.99488729, 0.78635538, 0.98265153,\n",
       "          0.94160062, 0.26520678, 0.79487813, 0.8966248 , 0.29781687,\n",
       "          0.10511459, 0.02371736, 0.66549879, 0.05827023, 0.46732032,\n",
       "          0.51977766, 0.99182564, 0.59112674, 0.33768198, 0.86117697,\n",
       "          0.        , 0.01513938, 0.58901995, 0.76214081, 0.01652664,\n",
       "          0.55727488, 0.51446468, 0.51085901, 0.08067252, 0.99201423,\n",
       "          0.23464969, 0.96122527, 0.27622095, 0.72915852, 0.        ,\n",
       "          0.89739197, 0.16994525, 0.57452577, 0.39037195, 0.51159698,\n",
       "          0.32684812, 0.03608632, 0.63390529, 0.83472747, 0.92658395,\n",
       "          0.29572174, 0.9268564 , 0.54079908, 0.88753682, 0.58890659,\n",
       "          0.26173475, 0.2287569 , 0.        , 0.14215767, 0.01329735,\n",
       "          0.31747189, 0.        , 0.90314722, 0.97269756, 0.52402121,\n",
       "          0.6224286 , 0.90595776, 0.01728765, 0.79874152, 0.99020141,\n",
       "          0.44712532, 0.94621032, 0.88838708, 0.17487697, 0.02680059,\n",
       "          0.52401882, 0.98537755, 0.69281453, 0.        , 0.01851353,\n",
       "          0.01222288, 0.8395412 , 0.66027963, 0.03143076, 0.96500367,\n",
       "          0.52888978, 0.0219148 , 0.9502027 , 0.02104062, 0.57327825,\n",
       "          0.99547285, 0.33417624, 0.9254418 , 0.61486834, 0.23440231,\n",
       "          0.97916079, 0.        , 0.        , 0.8793804 , 0.62319756,\n",
       "          0.38389385, 0.79371721, 0.28770491, 0.41760641, 0.81179005,\n",
       "          0.97171718, 0.97573262, 0.01249184, 0.94899327, 0.37729457]])},\n",
       " 'params': {'num_topics': 2, 'iterations': 500, 'random_state': 42},\n",
       " 'score': 0.6017872659552621}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:00:09.616488Z",
     "start_time": "2024-10-13T15:00:09.610658Z"
    }
   },
   "cell_type": "code",
   "source": "best_models['CTM']",
   "id": "e454f82503bd1f99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'topics': [['double',\n",
       "    'somethin',\n",
       "    'hear',\n",
       "    'thing',\n",
       "    'world',\n",
       "    'whatever',\n",
       "    'stress',\n",
       "    'bass',\n",
       "    'ho',\n",
       "    'battle'],\n",
       "   ['take',\n",
       "    'well',\n",
       "    'little',\n",
       "    'as',\n",
       "    'tell',\n",
       "    'guy',\n",
       "    'another',\n",
       "    'brother',\n",
       "    'nothing',\n",
       "    'wit'],\n",
       "   ['clean',\n",
       "    'another',\n",
       "    'huh',\n",
       "    'bass',\n",
       "    'great',\n",
       "    'blue',\n",
       "    'flow',\n",
       "    'makin',\n",
       "    'ghetto',\n",
       "    'cube']],\n",
       "  'topic-document-matrix': array([[0.08450763, 0.317814  , 0.33435184, ..., 0.25211883, 0.08910767,\n",
       "          0.22139151],\n",
       "         [0.33204313, 0.16490646, 0.07378573, ..., 0.12000985, 0.31651188,\n",
       "          0.18019159],\n",
       "         [0.58344924, 0.51727953, 0.59186239, ..., 0.62787131, 0.59438041,\n",
       "          0.59841692]]),\n",
       "  'topic-word-matrix': array([[ 0.0170679 ,  0.03369807, -0.04947468, ..., -0.12947851,\n",
       "          -0.1389453 , -0.06324163],\n",
       "         [-0.02002003, -0.06443809, -0.00666221, ..., -0.022369  ,\n",
       "          -0.01695826,  0.00541135],\n",
       "         [-0.08495021, -0.09038385, -0.08377066, ..., -0.00202768,\n",
       "           0.02173917,  0.00565804]], dtype=float32),\n",
       "  'test-topic-document-matrix': array([[0.08620358, 0.16140791, 0.07197784, 0.74472453, 0.11927863,\n",
       "          0.17537775, 0.1899625 , 0.01517935, 0.32767564, 0.11141529,\n",
       "          0.29075693, 0.10674057, 0.1961793 , 0.29013223, 0.49496592,\n",
       "          0.16296502, 0.12045405, 0.19078707, 0.25349328, 0.04912828,\n",
       "          0.08005626, 0.05571356, 0.18724695, 0.23861605, 0.15929411,\n",
       "          0.58433419, 0.36983301, 0.39471297, 0.30950779, 0.52359447,\n",
       "          0.16541659, 0.18544647, 0.15112011, 0.11299593, 0.0476653 ,\n",
       "          0.41867448, 0.23180015, 0.05671132, 0.07948142, 0.0678311 ,\n",
       "          0.33118929, 0.0843883 , 0.47934693, 0.06704378, 0.61545833,\n",
       "          0.48874377, 0.07056892, 0.28907799, 0.37790743, 0.42536023,\n",
       "          0.36864412, 0.16655363, 0.44086909, 0.0849261 , 0.11077889,\n",
       "          0.06741947, 0.09368674, 0.21969032, 0.27726482, 0.04037591,\n",
       "          0.24241774, 0.09984724, 0.62010337, 0.38084423, 0.23871309,\n",
       "          0.14302737, 0.1013158 , 0.27408459, 0.19113358, 0.26263001,\n",
       "          0.08913755, 0.18608511, 0.12327132, 0.0671661 , 0.16263587,\n",
       "          0.06278277, 0.18375589, 0.33947224, 0.52413831, 0.24234384,\n",
       "          0.08019595, 0.2252379 , 0.03242392, 0.10703857, 0.5814686 ,\n",
       "          0.10178958, 0.15554466, 0.26803495, 0.07475362, 0.17820105,\n",
       "          0.50998338, 0.35836155, 0.18553497, 0.34940908, 0.02906968,\n",
       "          0.40564874, 0.27808997, 0.14707285, 0.2210611 , 0.1902913 ,\n",
       "          0.05822833, 0.06315633, 0.18732522, 0.57668583, 0.31831035,\n",
       "          0.13514662, 0.09693866, 0.37906547, 0.30085569, 0.33636294,\n",
       "          0.04958653, 0.11166531, 0.02273724, 0.21455859, 0.09395565,\n",
       "          0.34374403, 0.03552405, 0.57043341, 0.10815577, 0.2904452 ,\n",
       "          0.5413866 , 0.6883042 , 0.23869444, 0.08804686, 0.07432407,\n",
       "          0.41339   , 0.38891523, 0.11299634, 0.14164297, 0.03226742,\n",
       "          0.02041243, 0.45976946, 0.08738826, 0.22800697, 0.42538024,\n",
       "          0.18616659, 0.33081531, 0.07413483, 0.63786442, 0.1493201 ,\n",
       "          0.20266617, 0.1308743 , 0.38371133, 0.33201616, 0.33229888,\n",
       "          0.04686781, 0.69968681, 0.21277065, 0.28769362, 0.05072017,\n",
       "          0.37017492, 0.04335874, 0.35887722, 0.0935842 , 0.27410516,\n",
       "          0.04861469, 0.33797225, 0.71123318, 0.07412282, 0.10492611,\n",
       "          0.38761998, 0.07682029, 0.57674071, 0.42728936, 0.39677616,\n",
       "          0.14895356, 0.64295874, 0.07343583, 0.0621703 , 0.41617899,\n",
       "          0.16503656, 0.2966591 , 0.30038342, 0.30264938, 0.48016511,\n",
       "          0.04745503, 0.23959148, 0.03430178, 0.48585585, 0.61799405,\n",
       "          0.10998052, 0.15438875, 0.2237233 , 0.40403912, 0.16301088,\n",
       "          0.06529422, 0.29697005, 0.09457334, 0.49202785, 0.23401006,\n",
       "          0.02343065, 0.20259216, 0.02790794, 0.42983645, 0.32188593,\n",
       "          0.07858247, 0.22594191, 0.43744194, 0.57168736, 0.67946112,\n",
       "          0.03917299, 0.13236864, 0.43741411, 0.02220066, 0.10792844],\n",
       "         [0.84350588, 0.47444017, 0.8588675 , 0.00731293, 0.55991326,\n",
       "          0.09582203, 0.65455658, 0.97103468, 0.16354465, 0.77533803,\n",
       "          0.15724992, 0.60427811, 0.04907676, 0.22275953, 0.0562178 ,\n",
       "          0.76385229, 0.33573059, 0.55096644, 0.30931049, 0.25002423,\n",
       "          0.64941524, 0.93782694, 0.6661424 , 0.41769441, 0.29261963,\n",
       "          0.11800279, 0.0769362 , 0.44805749, 0.47769724, 0.15074002,\n",
       "          0.11289863, 0.36221068, 0.70689151, 0.50513253, 0.92421811,\n",
       "          0.3292388 , 0.70220625, 0.91804965, 0.66854384, 0.90274836,\n",
       "          0.35738594, 0.86897522, 0.25447911, 0.73158014, 0.13032578,\n",
       "          0.47095553, 0.86054977, 0.04081295, 0.5190458 , 0.08947953,\n",
       "          0.18011294, 0.49161595, 0.16404777, 0.65775093, 0.80138595,\n",
       "          0.91541654, 0.83442596, 0.25699242, 0.416933  , 0.91222206,\n",
       "          0.37210579, 0.88250067, 0.30464676, 0.06629999, 0.72272626,\n",
       "          0.27713324, 0.56049869, 0.60044351, 0.55805812, 0.22271128,\n",
       "          0.28018833, 0.61807743, 0.78387936, 0.45257797, 0.69121601,\n",
       "          0.46126259, 0.46570697, 0.50296153, 0.01652785, 0.01534289,\n",
       "          0.89491497, 0.53828748, 0.83294578, 0.84400418, 0.13561482,\n",
       "          0.81232697, 0.60372059, 0.37104828, 0.46939806, 0.66961704,\n",
       "          0.20617763, 0.35981293, 0.74154573, 0.54565603, 0.95232537,\n",
       "          0.03185307, 0.17419446, 0.41047297, 0.28058647, 0.38061943,\n",
       "          0.22262397, 0.89193465, 0.4618152 , 0.10567768, 0.04316027,\n",
       "          0.26976358, 0.77588869, 0.23899673, 0.17269189, 0.07720956,\n",
       "          0.93863702, 0.56856366, 0.93087152, 0.73149046, 0.18252743,\n",
       "          0.18237705, 0.95403759, 0.09998234, 0.7399081 , 0.32486609,\n",
       "          0.04388989, 0.01522177, 0.25608647, 0.80860818, 0.4365374 ,\n",
       "          0.40290793, 0.42056886, 0.72224112, 0.73521816, 0.26858201,\n",
       "          0.89515614, 0.15192494, 0.685889  , 0.26802248, 0.27849225,\n",
       "          0.2070433 , 0.05543124, 0.68504048, 0.24929352, 0.15385524,\n",
       "          0.37566782, 0.8001667 , 0.46595997, 0.50078258, 0.15718507,\n",
       "          0.77262307, 0.02209648, 0.23699101, 0.24437179, 0.87679313,\n",
       "          0.11373908, 0.94120373, 0.52239314, 0.57274784, 0.28571208,\n",
       "          0.90932469, 0.36710798, 0.00121286, 0.88854603, 0.66679225,\n",
       "          0.03552434, 0.67500216, 0.09620877, 0.16917786, 0.17052407,\n",
       "          0.52590695, 0.21225316, 0.77355952, 0.83152087, 0.02083073,\n",
       "          0.56505378, 0.45228406, 0.32610891, 0.57888769, 0.01139197,\n",
       "          0.82245884, 0.35640606, 0.95681406, 0.24517421, 0.22342224,\n",
       "          0.22910005, 0.06187713, 0.01746851, 0.14140998, 0.56514006,\n",
       "          0.8897146 , 0.23445539, 0.47524512, 0.09230431, 0.39072049,\n",
       "          0.94065296, 0.6912063 , 0.87987204, 0.18287928, 0.2224515 ,\n",
       "          0.26120928, 0.43382334, 0.50501806, 0.27537459, 0.01839661,\n",
       "          0.91342707, 0.36776943, 0.24418137, 0.89474744, 0.25675862],\n",
       "         [0.07029056, 0.36415192, 0.06915466, 0.24796254, 0.32080811,\n",
       "          0.72880021, 0.15548091, 0.01378598, 0.50877971, 0.11324667,\n",
       "          0.55199314, 0.28898132, 0.75474394, 0.48710825, 0.44881627,\n",
       "          0.07318268, 0.54381537, 0.25824647, 0.43719623, 0.7008475 ,\n",
       "          0.2705285 , 0.00645952, 0.14661064, 0.34368954, 0.54808625,\n",
       "          0.29766303, 0.5532308 , 0.15722955, 0.21279497, 0.32566552,\n",
       "          0.72168477, 0.45234286, 0.14198839, 0.38187154, 0.02811659,\n",
       "          0.25208674, 0.06599359, 0.02523904, 0.25197473, 0.02942055,\n",
       "          0.31142477, 0.0466365 , 0.26617396, 0.20137611, 0.2542159 ,\n",
       "          0.04030069, 0.06888131, 0.67010909, 0.10304678, 0.48516023,\n",
       "          0.45124295, 0.34183041, 0.39508318, 0.25732297, 0.08783514,\n",
       "          0.01716397, 0.07188732, 0.52331724, 0.30580217, 0.04740202,\n",
       "          0.38547647, 0.01765208, 0.07524986, 0.55285578, 0.03856063,\n",
       "          0.5798394 , 0.33818552, 0.12547189, 0.25080829, 0.51465872,\n",
       "          0.63067411, 0.19583744, 0.09284931, 0.48025593, 0.14614813,\n",
       "          0.47595463, 0.35053714, 0.15756624, 0.45933384, 0.74231327,\n",
       "          0.02488909, 0.23647464, 0.13463032, 0.04895725, 0.28291656,\n",
       "          0.08588345, 0.24073475, 0.36091677, 0.45584835, 0.15218189,\n",
       "          0.283839  , 0.28182553, 0.07291929, 0.10493488, 0.01860496,\n",
       "          0.5624982 , 0.54771556, 0.44245418, 0.49835242, 0.42908927,\n",
       "          0.71914771, 0.04490901, 0.35085956, 0.31763648, 0.63852938,\n",
       "          0.59508981, 0.12717268, 0.38193779, 0.52645244, 0.58642749,\n",
       "          0.01177644, 0.31977103, 0.04639121, 0.05395095, 0.72351691,\n",
       "          0.47387893, 0.01043836, 0.32958425, 0.15193613, 0.38468872,\n",
       "          0.41472352, 0.29647403, 0.50521908, 0.10334497, 0.48913851,\n",
       "          0.18370208, 0.19051593, 0.16476255, 0.1231389 , 0.69915058,\n",
       "          0.08443142, 0.38830559, 0.22672272, 0.50397056, 0.29612753,\n",
       "          0.60679009, 0.61375348, 0.2408247 , 0.11284207, 0.69682466,\n",
       "          0.42166603, 0.06895904, 0.15032873, 0.16720126, 0.51051608,\n",
       "          0.18050911, 0.2782167 , 0.55023834, 0.46793457, 0.07248669,\n",
       "          0.51608602, 0.01543756, 0.11872966, 0.33366797, 0.44018274,\n",
       "          0.04206063, 0.29491977, 0.28755399, 0.03733116, 0.22828162,\n",
       "          0.57685568, 0.24817757, 0.32705055, 0.40353277, 0.43269975,\n",
       "          0.32513949, 0.1447881 , 0.15300464, 0.10630884, 0.56299028,\n",
       "          0.26990965, 0.25105686, 0.37350768, 0.11846293, 0.50844292,\n",
       "          0.13008615, 0.40400245, 0.00888416, 0.26896996, 0.1585837 ,\n",
       "          0.66091942, 0.78373413, 0.75880816, 0.4545509 , 0.27184906,\n",
       "          0.0449912 , 0.46857458, 0.43018154, 0.41566784, 0.37526945,\n",
       "          0.03591639, 0.10620154, 0.09222002, 0.38728426, 0.45566258,\n",
       "          0.66020824, 0.34023475, 0.05754   , 0.15293805, 0.3021423 ,\n",
       "          0.04739993, 0.49986192, 0.31840452, 0.08305192, 0.63531293]])},\n",
       " 'params': {'num_topics': 3, 'num_epochs': 5},\n",
       " 'score': 0.6173094858246226}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "52a4951d01d4e1b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
