{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T19:44:11.844721Z",
     "start_time": "2025-01-26T19:44:10.059814Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PopMusicInformationRetrieval import gunshot_utils as utils\n",
    "import importlib\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pydub.playback import play\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PopMusicInformationRetrieval.gunshot_utils' from '/Users/borosabel/Documents/Uni/Thesis/PopMusicInformationRetrieval/gunshot_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:25.316593Z",
     "start_time": "2024-11-02T14:50:25.314368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is how I initially built up the manually labeled gunshot dataset.\n",
    "# folder_path = './test_data_wav/'\n",
    "# gunshot_df = utils.build_dataframe_from_folder(folder_path)"
   ],
   "id": "5fb007a9b199ee3b",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:25.541379Z",
     "start_time": "2024-11-02T14:50:25.532690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading the gunshot dataframe, which could be: \n",
    "\n",
    "# For now I just took the glock gunshots because they are the most clear and representative of how the gunshots usually are\n",
    "# gunshot_df = pd.read_pickle('pkl_data/gunshot_data_glock_only.pkl')\n",
    "# gunshot_df = gunshot_df[['filename', 'gunshot_location_in_seconds', 'num_gunshots']]\n",
    "\n",
    "# Only the manually labeled gunshot samples.\n",
    "gunshot_df = pd.read_pickle('pkl_data/real_music_gunshot_samples.pkl')\n",
    "gunshot_df = gunshot_df[['filename', 'gunshot_location_in_seconds', 'num_gunshots']]\n",
    "\n",
    "gunshot_df"
   ],
   "id": "a5f6cb01c546dfd4",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:56:54.669237Z",
     "start_time": "2024-11-02T14:56:54.656840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading the music dataframe, which could be: \n",
    "# - the dataframe where we store the musical onsets, exactly in a setup like how we have the gunshot locations.\n",
    "\n",
    "music_df = pd.read_pickle('./pkl_data/music_with_onsets_df_100.pkl')\n",
    "music_df.head()"
   ],
   "id": "5660b33d7d5bc92b",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:26.335150Z",
     "start_time": "2024-11-02T14:50:26.330068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_train_df, music_valid_df = train_test_split(music_df, test_size=0.2, random_state=42)\n",
    "gunshot_train_df, gunshot_valid_df = train_test_split(gunshot_df, test_size=0.2, random_state=42)"
   ],
   "id": "7e999d9884537c21",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:26.697286Z",
     "start_time": "2024-11-02T14:50:26.693738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"SHAPES:\")\n",
    "print(f\"music_train_df: {music_train_df.shape}, music_valid_df: {music_valid_df.shape}\")\n",
    "print(f\"gunshot_train_df: {gunshot_train_df.shape}, gunshot_valid_df: {gunshot_valid_df.shape}\")"
   ],
   "id": "e142f2f0c32f054a",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:27.094801Z",
     "start_time": "2024-11-02T14:50:27.076724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames)\n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x))) \n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "100aed0d7d53aa1",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:27.873115Z",
     "start_time": "2024-11-02T14:50:27.857559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, music_df, gunshot_df, music_metadata, gunshot_prob=0.5, num_samples=1000, real_music_gunshot=False):\n",
    "        super().__init__()\n",
    "        self.music_paths = music_df['file_path'].tolist()\n",
    "        self.music_onsets = music_df['onsets_in_seconds'].tolist()\n",
    "        self.gunshot_paths = gunshot_df['filename'].tolist()\n",
    "        self.gunshot_truth = gunshot_df['gunshot_location_in_seconds'].tolist()\n",
    "        self.music_metadata = music_metadata\n",
    "        self.gunshot_prob = gunshot_prob\n",
    "        self.num_samples = num_samples # I created this parameter to be able to generate as many samples as we want, because for every song we have multiple onsets and for one gunshot we have multiple shots too.\n",
    "        # This parameter is only because I also downloaded songs where I know that gunshot exists and in case I return a gunshot sample I don't want to combine an already good gunshot from a music with a music again.\n",
    "        self.real_music_gunshot = real_music_gunshot \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrograms = []\n",
    "        labels = []\n",
    "\n",
    "        # Randomly pick a music sample\n",
    "        music_idx = np.random.randint(0, len(self.music_paths))\n",
    "        fn_music = self.music_paths[music_idx]\n",
    "        onset_times = self.music_onsets[music_idx]\n",
    "        fn_music_metadata = self.music_metadata[fn_music]\n",
    "\n",
    "        # Decide whether to add a gunshot or not\n",
    "        add_gunshot = (np.random.rand() < self.gunshot_prob)\n",
    "\n",
    "        if add_gunshot:\n",
    "            # This is the scenario when the validation set consists only gunshots from real music.\n",
    "            if self.real_music_gunshot:\n",
    "                gunshot_idx = np.random.randint(0, len(self.gunshot_paths))\n",
    "                fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "                gunshot_times = self.gunshot_truth[gunshot_idx]\n",
    "                if len(gunshot_times) > 0:\n",
    "                    gunshot_time = gunshot_times[np.random.randint(0, len(gunshot_times))]\n",
    "                    gunshot_waveform, sr_gunshot = torchaudio.load(fn_gunshot)\n",
    "                    gunshot_segment = utils.select_gunshot_segment(gunshot_waveform, sr_gunshot, gunshot_time)\n",
    "                    gunshot_only_spectrograms, gunshot_only_labels = utils.preprocess_audio_train(gunshot_segment, label=1)\n",
    "                    if gunshot_only_spectrograms and gunshot_only_labels:\n",
    "                        spectrograms.extend(gunshot_only_spectrograms)\n",
    "                        labels.extend(gunshot_only_labels)\n",
    "\n",
    "            # This is the normal scenario when we have to combine music and gunshot\n",
    "            else:\n",
    "                gunshot_idx = np.random.randint(0, len(self.gunshot_paths))\n",
    "                fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "                gunshot_times = self.gunshot_truth[gunshot_idx][0]\n",
    "                music_waveform = utils.select_random_segment(file_path=fn_music, metadata=fn_music_metadata)\n",
    "                segment, sr = utils.combine_music_and_gunshot(music_waveform, fn_gunshot, gunshot_times, gunshot_volume_increase_dB=0)\n",
    "                combined_spectrograms, combined_labels = utils.preprocess_audio_train(segment, label=1)\n",
    "\n",
    "                if combined_spectrograms and combined_labels:\n",
    "                    spectrograms.extend(combined_spectrograms)\n",
    "                    labels.extend(combined_labels)\n",
    "\n",
    "        else:\n",
    "            music_waveform = utils.select_valid_onset_segment(file_path=fn_music, metadata=fn_music_metadata, onset_times=onset_times)\n",
    "            music_spectrograms, music_labels = utils.preprocess_audio_train(music_waveform, label=0)\n",
    "\n",
    "            if music_spectrograms and music_labels:\n",
    "                spectrograms.extend(music_spectrograms)\n",
    "                labels.extend(music_labels)\n",
    "\n",
    "        if not spectrograms or not labels:\n",
    "            raise ValueError(\"Spectrograms or labels are empty after preprocessing\")\n",
    "\n",
    "        return spectrograms[0], labels[0]\n",
    "\n",
    "    def get_random_music_with_gunshot(self):\n",
    "        \"\"\"\n",
    "        Function to return a random waveform that contains both music and gunshot.\n",
    "        \"\"\"\n",
    "        spectrograms = []\n",
    "\n",
    "        if self.real_music_gunshot:\n",
    "            gunshot_idx = np.random.randint(0, len(self.gunshot_paths))\n",
    "            fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "            gunshot_times = self.gunshot_truth[gunshot_idx]\n",
    "            if len(gunshot_times) > 0:\n",
    "                gunshot_time = gunshot_times[np.random.randint(0, len(gunshot_times))]\n",
    "                gunshot_waveform, sr_gunshot = torchaudio.load(fn_gunshot)\n",
    "                segment = utils.select_gunshot_segment(gunshot_waveform, sr_gunshot, gunshot_time)\n",
    "                gunshot_only_spectrograms, gunshot_only_labels = utils.preprocess_audio_train(segment, label=1)\n",
    "                if gunshot_only_spectrograms and gunshot_only_labels:\n",
    "                    spectrograms.extend(gunshot_only_spectrograms)\n",
    "\n",
    "        else:\n",
    "            music_idx = np.random.randint(0, len(self.music_paths))\n",
    "            fn_music = self.music_paths[music_idx]\n",
    "            onset_times = self.music_onsets[music_idx]\n",
    "            fn_music_metadata = self.music_metadata[fn_music]\n",
    "            # Select a random music segment\n",
    "            music_waveform = utils.select_valid_onset_segment(file_path=fn_music, metadata=fn_music_metadata, onset_times=onset_times)\n",
    "            # Randomly select a gunshot index\n",
    "            gunshot_idx = np.random.randint(0, len(self.gunshot_paths))\n",
    "            fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "            gunshot_times = self.gunshot_truth[gunshot_idx][0]\n",
    "            segment, sr = utils.combine_music_and_gunshot(music_waveform, fn_gunshot, gunshot_times)\n",
    "            combined_spectrograms, combined_labels = utils.preprocess_audio_train(segment, label=1)\n",
    "\n",
    "            if combined_spectrograms and combined_labels:\n",
    "                spectrograms.extend(combined_spectrograms)\n",
    "\n",
    "\n",
    "        return segment, spectrograms[0]\n",
    "\n",
    "    def get_random_music_onset(self):\n",
    "        music_idx = np.random.randint(0, len(self.music_paths))\n",
    "        fn_music = self.music_paths[music_idx]\n",
    "        onset_times = self.music_onsets[music_idx]\n",
    "        fn_music_metadata = self.music_metadata[fn_music]\n",
    "        music_waveform = utils.select_valid_onset_segment(file_path=fn_music, metadata=fn_music_metadata, onset_times=onset_times)\n",
    "        music_spectrograms, music_labels = utils.preprocess_audio_train(music_waveform, label=0)\n",
    "        return music_waveform, music_spectrograms[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples  # Define the length of the dataset to be the number of samples you desire"
   ],
   "id": "eaf2138fcfe8fed1",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:13.917970Z",
     "start_time": "2024-11-02T14:51:13.888066Z"
    }
   },
   "cell_type": "code",
   "source": "music_metadata = utils.create_metadata_map('./Data/music')",
   "id": "dd99b18c97075cc",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:22.349945Z",
     "start_time": "2024-11-02T14:51:22.341273Z"
    }
   },
   "cell_type": "code",
   "source": "music_metadata",
   "id": "7962a5a03e7672f5",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Data Loader</b>",
   "id": "c0a813759c4ba4db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:50:30.267702Z",
     "start_time": "2024-11-02T14:50:30.265814Z"
    }
   },
   "cell_type": "code",
   "source": "# I've made several changes in the dataloader: ",
   "id": "d310dd6cf88d22cc",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:27.395512Z",
     "start_time": "2024-11-02T14:51:27.391935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = GunshotDataset(music_train_df, gunshot_train_df, music_metadata, gunshot_prob=0.5, num_samples=800, real_music_gunshot=True) # This means that with 50% probability it will generate gunshot samples. In total 800 samples.\n",
    "valid_dataset = GunshotDataset(music_valid_df, gunshot_valid_df, music_metadata, gunshot_prob=0.5, num_samples=320, real_music_gunshot=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "e5b8ca90178c8623",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:27.785153Z",
     "start_time": "2024-11-02T14:51:27.782268Z"
    }
   },
   "cell_type": "code",
   "source": "# We can retrive also only gunshot parts and only musical onset parts for testing purposes like this: ",
   "id": "8038b4e61d302cfd",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Gunshot</b>",
   "id": "231a6a22492afa6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:29.907324Z",
     "start_time": "2024-11-02T14:51:28.440737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "waveform, spectogram = train_dataset.get_random_music_with_gunshot() # retriving\n",
    "utils.play_audio(waveform) # Listening to the excerpt\n",
    "utils.plot_waveform(waveform) # Plotting the waveform"
   ],
   "id": "4676d6f965cf128a",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:30.263732Z",
     "start_time": "2024-11-02T14:51:29.909577Z"
    }
   },
   "cell_type": "code",
   "source": "utils.plot_spectrogram_channels(spectogram) # Plotting the spectogram channels",
   "id": "5d3857daa17eb6bf",
   "execution_count": 64,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Music only</b>",
   "id": "1a00ab9bc28b47f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:35.374594Z",
     "start_time": "2024-11-02T14:51:34.010930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "waveform, spectogram = train_dataset.get_random_music_onset() # retrieving\n",
    "utils.play_audio(waveform) # Listening to the excerpt\n",
    "utils.plot_waveform(waveform) # Plotting the waveform"
   ],
   "id": "f1fdc8836c2c2eb",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:35.637433Z",
     "start_time": "2024-11-02T14:51:35.376842Z"
    }
   },
   "cell_type": "code",
   "source": "utils.plot_spectrogram_channels(spectogram) # Plotting the spectograms channels",
   "id": "eaeb8e17f90cfaf4",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>We can compare them like this</b>",
   "id": "d3f65296b3ad23c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:37.099877Z",
     "start_time": "2024-11-02T14:51:36.360845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "waveform_onset, spectogram_onset = train_dataset.get_random_music_onset() # retrieving\n",
    "waveform_gunshot, spectogram_gun = train_dataset.get_random_music_with_gunshot() # retriving\n",
    "utils.plot_spectrogram_channels_two_rows(spectogram_onset, spectogram_gun)"
   ],
   "id": "575d3a1ebe2b341e",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:38.449071Z",
     "start_time": "2024-11-02T14:51:37.306003Z"
    }
   },
   "cell_type": "code",
   "source": "utils.play_audio(waveform_onset)",
   "id": "cfc77de09fb60ef9",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:51:39.572203Z",
     "start_time": "2024-11-02T14:51:38.451237Z"
    }
   },
   "cell_type": "code",
   "source": "utils.play_audio(waveform_gunshot)",
   "id": "5a5e5a4a7a8491d6",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:52:03.273435Z",
     "start_time": "2024-11-02T14:51:40.251468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "use_cuda = th.cuda.is_available()\n",
    "mean, std = utils.compute_mean_std(train_loader)\n",
    "mean = mean.to(device)\n",
    "std = std.to(device)"
   ],
   "id": "43af2ff7cf3e06fe",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:55:28.632530Z",
     "start_time": "2024-11-02T14:52:03.275039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "lr = 3e-4\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = th.nn.BCELoss()\n",
    "\n",
    "best_threshold, best_score = utils.train_model(\n",
    "    model, optimizer, criterion, train_loader, valid_loader, num_epochs=epochs, mean=mean, std=std, patience=3\n",
    ")"
   ],
   "id": "d206953440c4c769",
   "execution_count": 73,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:58:07.047235Z",
     "start_time": "2024-11-02T14:58:06.083031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrograms, sample_rates = utils.preprocess_audio(['./50 Cent - Many Men (Wish Death) (Dirty Version).mp3'])\n",
    "print(f\"Got back spectogram in shape: {spectrograms[0].shape} and sample rate: {sample_rates}\")"
   ],
   "id": "df2809978ceacf07",
   "execution_count": 77,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T14:58:27.310403Z",
     "start_time": "2024-11-02T14:58:07.887077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = utils.manual_evaluate_test(model, spectrograms[0], threshold=best_threshold, mean=mean, std=std, step_size=1, filter_time_sec=1)\n",
    "\n",
    "if(len(predictions) > 0):\n",
    "    print(f\"Current treshold is {best_threshold} \\n\")\n",
    "\n",
    "    for minutes, seconds, output in predictions:\n",
    "        print(f\"Detected gunshot at {minutes}m {seconds:.2f}s with model output: {output:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions\")"
   ],
   "id": "f7940f91f72f5b9",
   "execution_count": 78,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:01:01.764452Z",
     "start_time": "2024-11-02T15:01:01.760510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For this song above we should have gunshots at around: \n",
    "# -0:12\n",
    "# -0:47\n",
    "# -2:04 \n",
    "# instead of these we have a bunch of predictions"
   ],
   "id": "e902eecf4c8baa5b",
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a446dd52ed7616ab",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
