{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:29:24.256736Z",
     "start_time": "2025-05-07T20:29:21.697922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import importlib\n",
    "import utility_functions_topic_modeling as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "id": "2b729ddcc6d3d23",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:30:18.754559Z",
     "start_time": "2025-05-07T20:30:18.751004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_topics_list = [2, 3, 4]\n",
    "ctm_epochs_list = [5, 10, 20]\n",
    "ctm_learning_rates = [2e-3, 5e-3, 1e-2]\n",
    "ctm_batch_sizes = [64, 128]\n",
    "\n",
    "# Create all combinations of parameters\n",
    "ctm_param_grid = list(itertools.product(num_topics_list, ctm_epochs_list, ctm_learning_rates, ctm_batch_sizes))"
   ],
   "id": "c3a9d942823e1e50",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:30:51.377696Z",
     "start_time": "2025-05-07T20:30:51.137953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your dataframe\n",
    "df = pd.read_pickle('../Data/pkl_data/preprocessed_df.pkl')\n",
    "\n",
    "if isinstance(df['Tokens'].iloc[0], str):\n",
    "    import ast\n",
    "    df['Tokens'] = df['Tokens'].apply(ast.literal_eval)\n",
    "\n",
    "texts = df['Tokens']\n",
    "texts_bow = [' '.join(tokens) for tokens in df['Tokens']]\n",
    "df['Lyrics'] = df['Lyrics'].apply(utils.light_preprocessing)\n",
    "documents = df['Lyrics']"
   ],
   "id": "183e051038fa4356",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:30:52.381769Z",
     "start_time": "2025-05-07T20:30:52.360737Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "8e5d726a25c30370",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Artist                                Album  \\\n",
       "0      Big L  Lifestylez Ov Da Poor and Dangerous   \n",
       "1      Big L  Lifestylez Ov Da Poor and Dangerous   \n",
       "2      Big L  Lifestylez Ov Da Poor and Dangerous   \n",
       "3      Big L  Lifestylez Ov Da Poor and Dangerous   \n",
       "4      Big L  Lifestylez Ov Da Poor and Dangerous   \n",
       "...      ...                                  ...   \n",
       "1363  Dr.Dre                          The Chronic   \n",
       "1364  Dr.Dre                          The Chronic   \n",
       "1365  Dr.Dre                          The Chronic   \n",
       "1366  Dr.Dre                          The Chronic   \n",
       "1367  Dr.Dre                          The Chronic   \n",
       "\n",
       "                                                   Song       Coast  \\\n",
       "0                                        8 Iz Enuff.mp3  east_coast   \n",
       "1                                      Da Graveyard.mp3  east_coast   \n",
       "2                             I Don't Understand It.mp3  east_coast   \n",
       "3                                 No Endz, No Skinz.mp3  east_coast   \n",
       "4                                               MVP.mp3  east_coast   \n",
       "...                                                 ...         ...   \n",
       "1363  Dr. Dre - The Day the Niggaz Took Over (feat. ...  west_coast   \n",
       "1364  Dr. Dre - Bitches Ain't Shit (feat. Jewell, Sn...  west_coast   \n",
       "1365  Dr. Dre - Stranded On Death Row (feat. Bushwic...  west_coast   \n",
       "1366  Dr. Dre - Nuthin' but a ＂G＂ Thang (feat. Snoop...  west_coast   \n",
       "1367  Dr. Dre - The Roach (ft. Ruben Cruz, Daz Dilli...  west_coast   \n",
       "\n",
       "      Release Year      Tempo1     Tempo2  Duration (s)  Sample Rate (Hz)  \\\n",
       "0             1995   96.774194  48.000000    298.840000             48000   \n",
       "1             1995   93.750000  46.511628    323.760000             48000   \n",
       "2             1995   93.750000  47.244094    260.226667             48000   \n",
       "3             1995  100.000000  50.420168    208.733333             48000   \n",
       "4             1995   86.956522  43.478261    218.866667             48000   \n",
       "...            ...         ...        ...           ...               ...   \n",
       "1363          1992   93.750000  46.875000    273.206000             48000   \n",
       "1364          1992   92.307692  46.153846    287.207625             48000   \n",
       "1365          1992   90.909091  45.801527    287.335333             48000   \n",
       "1366          1992   95.238095  47.244094    238.677917             48000   \n",
       "1367          1992   89.552239  44.117647    277.072125             48000   \n",
       "\n",
       "                                                   Path  \\\n",
       "0     /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1     /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "2     /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "3     /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "4     /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "...                                                 ...   \n",
       "1363  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1364  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1365  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1366  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1367  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "\n",
       "                                                 Lyrics  \\\n",
       "0     yo my crew is in the house terra herb mcgruff ...   \n",
       "1     it's the number one crew in the area big l be ...   \n",
       "2     there are too many mc's who are overrated you ...   \n",
       "3     let me get to the point real quick when ya poc...   \n",
       "4     a yo spark up the phillies and pass the stout ...   \n",
       "...                                                 ...   \n",
       "1363  i'ma say this and i'ma end mine if you ain't d...   \n",
       "1364  bitches ain't shit but hoes and tricks bitches...   \n",
       "1365  yes it is i \" says me and all who agree are mo...   \n",
       "1366  one two three and to the four snoop doggy dogg...   \n",
       "1367  cannabis sativa ha ha or in the heart of la kn...   \n",
       "\n",
       "                                                 Tokens  \\\n",
       "0     [crew, house, bless, big, mike, imma, set, fol...   \n",
       "1     [number, one, crew, big, nigga, men, win, kill...   \n",
       "2     [many, mcs, ask, even, supposed, make, rap, kn...   \n",
       "3     [let, point, real, quick, pocket, thick, mad, ...   \n",
       "4     [pass, make, quick, money, grip, ass, street, ...   \n",
       "...                                                 ...   \n",
       "1363  [say, end, mine, point, one, south, shit, need...   \n",
       "1364  [bitch, shit, hoe, trick, bitch, shit, hoe, tr...   \n",
       "1365  [yes, say, three, yes, house, sure, want, talk...   \n",
       "1366  [one, two, three, four, dog, dr, dre, door, re...   \n",
       "1367  [heart, la, know, even, though, six, million, ...   \n",
       "\n",
       "                                       Processed_Lyrics  \n",
       "0     crew house terra herb mcgruff buddah bless big...  \n",
       "1     number one crew area big lightin nigga incense...  \n",
       "2     many mcs overrated ask even supposed make rap ...  \n",
       "3     let get point real quick pocket thick mad chic...  \n",
       "4     spark phillies pass stout make quick money gri...  \n",
       "...                                                 ...  \n",
       "1363  say end mine africans united states period poi...  \n",
       "1364  bitch shit hoe trick bitch shit hoe trick lick...  \n",
       "1365  yes say agree three yes house sure want talk h...  \n",
       "1366  one two three four snoop doggy dog dr dre door...  \n",
       "1367  cannabis sativa heart la know chronic confused...  \n",
       "\n",
       "[1368 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Song</th>\n",
       "      <th>Coast</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Tempo1</th>\n",
       "      <th>Tempo2</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Sample Rate (Hz)</th>\n",
       "      <th>Path</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Processed_Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big L</td>\n",
       "      <td>Lifestylez Ov Da Poor and Dangerous</td>\n",
       "      <td>8 Iz Enuff.mp3</td>\n",
       "      <td>east_coast</td>\n",
       "      <td>1995</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>298.840000</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>yo my crew is in the house terra herb mcgruff ...</td>\n",
       "      <td>[crew, house, bless, big, mike, imma, set, fol...</td>\n",
       "      <td>crew house terra herb mcgruff buddah bless big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big L</td>\n",
       "      <td>Lifestylez Ov Da Poor and Dangerous</td>\n",
       "      <td>Da Graveyard.mp3</td>\n",
       "      <td>east_coast</td>\n",
       "      <td>1995</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>46.511628</td>\n",
       "      <td>323.760000</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>it's the number one crew in the area big l be ...</td>\n",
       "      <td>[number, one, crew, big, nigga, men, win, kill...</td>\n",
       "      <td>number one crew area big lightin nigga incense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big L</td>\n",
       "      <td>Lifestylez Ov Da Poor and Dangerous</td>\n",
       "      <td>I Don't Understand It.mp3</td>\n",
       "      <td>east_coast</td>\n",
       "      <td>1995</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>47.244094</td>\n",
       "      <td>260.226667</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>there are too many mc's who are overrated you ...</td>\n",
       "      <td>[many, mcs, ask, even, supposed, make, rap, kn...</td>\n",
       "      <td>many mcs overrated ask even supposed make rap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big L</td>\n",
       "      <td>Lifestylez Ov Da Poor and Dangerous</td>\n",
       "      <td>No Endz, No Skinz.mp3</td>\n",
       "      <td>east_coast</td>\n",
       "      <td>1995</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.420168</td>\n",
       "      <td>208.733333</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>let me get to the point real quick when ya poc...</td>\n",
       "      <td>[let, point, real, quick, pocket, thick, mad, ...</td>\n",
       "      <td>let get point real quick pocket thick mad chic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big L</td>\n",
       "      <td>Lifestylez Ov Da Poor and Dangerous</td>\n",
       "      <td>MVP.mp3</td>\n",
       "      <td>east_coast</td>\n",
       "      <td>1995</td>\n",
       "      <td>86.956522</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>218.866667</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>a yo spark up the phillies and pass the stout ...</td>\n",
       "      <td>[pass, make, quick, money, grip, ass, street, ...</td>\n",
       "      <td>spark phillies pass stout make quick money gri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Dr.Dre</td>\n",
       "      <td>The Chronic</td>\n",
       "      <td>Dr. Dre - The Day the Niggaz Took Over (feat. ...</td>\n",
       "      <td>west_coast</td>\n",
       "      <td>1992</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>46.875000</td>\n",
       "      <td>273.206000</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>i'ma say this and i'ma end mine if you ain't d...</td>\n",
       "      <td>[say, end, mine, point, one, south, shit, need...</td>\n",
       "      <td>say end mine africans united states period poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Dr.Dre</td>\n",
       "      <td>The Chronic</td>\n",
       "      <td>Dr. Dre - Bitches Ain't Shit (feat. Jewell, Sn...</td>\n",
       "      <td>west_coast</td>\n",
       "      <td>1992</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>287.207625</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>bitches ain't shit but hoes and tricks bitches...</td>\n",
       "      <td>[bitch, shit, hoe, trick, bitch, shit, hoe, tr...</td>\n",
       "      <td>bitch shit hoe trick bitch shit hoe trick lick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Dr.Dre</td>\n",
       "      <td>The Chronic</td>\n",
       "      <td>Dr. Dre - Stranded On Death Row (feat. Bushwic...</td>\n",
       "      <td>west_coast</td>\n",
       "      <td>1992</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>45.801527</td>\n",
       "      <td>287.335333</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>yes it is i \" says me and all who agree are mo...</td>\n",
       "      <td>[yes, say, three, yes, house, sure, want, talk...</td>\n",
       "      <td>yes say agree three yes house sure want talk h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>Dr.Dre</td>\n",
       "      <td>The Chronic</td>\n",
       "      <td>Dr. Dre - Nuthin' but a ＂G＂ Thang (feat. Snoop...</td>\n",
       "      <td>west_coast</td>\n",
       "      <td>1992</td>\n",
       "      <td>95.238095</td>\n",
       "      <td>47.244094</td>\n",
       "      <td>238.677917</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>one two three and to the four snoop doggy dogg...</td>\n",
       "      <td>[one, two, three, four, dog, dr, dre, door, re...</td>\n",
       "      <td>one two three four snoop doggy dog dr dre door...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>Dr.Dre</td>\n",
       "      <td>The Chronic</td>\n",
       "      <td>Dr. Dre - The Roach (ft. Ruben Cruz, Daz Dilli...</td>\n",
       "      <td>west_coast</td>\n",
       "      <td>1992</td>\n",
       "      <td>89.552239</td>\n",
       "      <td>44.117647</td>\n",
       "      <td>277.072125</td>\n",
       "      <td>48000</td>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>cannabis sativa ha ha or in the heart of la kn...</td>\n",
       "      <td>[heart, la, know, even, though, six, million, ...</td>\n",
       "      <td>cannabis sativa heart la know chronic confused...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1368 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:32:30.972568Z",
     "start_time": "2025-05-07T20:30:54.497179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tp = TopicModelDataPreparation(\"all-mpnet-base-v2\", max_seq_length=512)\n",
    "training_dataset = tp.fit(text_for_contextual=documents, text_for_bow=texts_bow)"
   ],
   "id": "727caaf1bebe0cab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7868f804af9c489e8beae85fa00d8f4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3fea505336c421fb372de28246c4f6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a704bbd17945ab9b51c80a6e56eeb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ffedff4eb3b4b3d8ac9daa074f7523d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1add46b729c94e359009b23474f97cf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56de2a0a26344df4bf6561be36947670"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c88fd6d097b14db9b7efaf6e4b817ba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d20cafb24bef47d2b82755e2f7336187"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e7fc6d97c614488a6b64b862d912e12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19341337cb5d4a96b3f066d5af4fe56e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c2e6550258e4475939df36c863bbfe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/contextualized_topic_models/utils/data_preparation.py:64: UserWarning: the longest document in your collection has 1919 words, the model instead truncates to 512 tokens.\n",
      "  warnings.warn(\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "/Users/abelboros/.pyenv/versions/thesis_env/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8616b5dcfd1246299bf725e15cf8d426"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:40:18.174586Z",
     "start_time": "2025-05-07T20:40:18.062809Z"
    }
   },
   "cell_type": "code",
   "source": "dictionary = corpora.Dictionary(texts)",
   "id": "8c113371d24b16e9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:43:13.638192Z",
     "start_time": "2025-05-07T20:40:24.459226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to evaluate CTM models and save results into a DataFrame\n",
    "def evaluate_ctm_models(training_dataset, tp, texts, dictionary, ctm_param_grid, metrics=('coherence',), save_dir='saved_models'):\n",
    "    \"\"\"\n",
    "    Evaluate CTM models with a given set of hyperparameters and metrics, and save results to a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - training_dataset: The training dataset prepared by TopicModelDataPreparation.\n",
    "    - tp: The TopicModelDataPreparation object with vocabulary info.\n",
    "    - texts: The list of tokenized texts.\n",
    "    - dictionary: The Gensim dictionary.\n",
    "    - ctm_param_grid: List of tuples for hyperparameters (num_topics, epochs, learning_rate, batch_size).\n",
    "    - metrics: Tuple of metrics to evaluate ('coherence', 'diversity', or both).\n",
    "    - save_dir: Directory to save the results DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: A DataFrame containing the evaluation results.\n",
    "    \"\"\"\n",
    "    ctm_results = []\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Iterate through each parameter combination\n",
    "    for idx, (num_topics, epochs, learning_rate, batch_size) in enumerate(ctm_param_grid):\n",
    "        try:\n",
    "            print(f\"Training CTM model {idx+1}/{len(ctm_param_grid)} with num_topics={num_topics}, epochs={epochs}, learning_rate={learning_rate}, batch_size={batch_size}\")\n",
    "\n",
    "            # Initialize the model\n",
    "            ctm_model = CombinedTM(\n",
    "                bow_size=len(tp.vocab),\n",
    "                contextual_size=768,\n",
    "                n_components=num_topics,\n",
    "                num_epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                activation='softplus',\n",
    "                dropout=0.2,\n",
    "                solver='adam',\n",
    "                num_data_loader_workers=0,\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            ctm_model.fit(training_dataset)\n",
    "\n",
    "            # Get topics\n",
    "            ctm_topics = ctm_model.get_topic_lists(10)\n",
    "\n",
    "            # Initialize result dictionary\n",
    "            result = {\n",
    "                'model_id': idx + 1,\n",
    "                'num_topics': num_topics,\n",
    "                'epochs': epochs,\n",
    "                'learning_rate': learning_rate,\n",
    "                'batch_size': batch_size\n",
    "            }\n",
    "\n",
    "            # Evaluate the model based on specified metrics\n",
    "            if 'coherence' in metrics:\n",
    "                coherence_model_ctm = CoherenceModel(\n",
    "                    topics=ctm_topics,\n",
    "                    texts=texts,\n",
    "                    dictionary=dictionary,\n",
    "                    coherence='c_v'\n",
    "                )\n",
    "                coherence_ctm = coherence_model_ctm.get_coherence()\n",
    "                result['coherence_score'] = coherence_ctm\n",
    "\n",
    "            if 'diversity' in metrics:\n",
    "                unique_words = set()\n",
    "                total_words = 0\n",
    "\n",
    "                for topic in ctm_topics:\n",
    "                    unique_words.update(topic)\n",
    "                    total_words += len(topic)\n",
    "\n",
    "                topic_diversity = len(unique_words) / total_words if total_words > 0 else 0\n",
    "                result['topic_diversity'] = topic_diversity\n",
    "\n",
    "            # Save the result\n",
    "            ctm_results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while training model {idx+1}: {e}\")\n",
    "            continue  # Skip this iteration if there's an error\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(ctm_results)\n",
    "\n",
    "    # Sort by coherence_score if it is one of the metrics\n",
    "    if 'coherence' in metrics:\n",
    "        results_df = results_df.sort_values(by='coherence_score', ascending=False)\n",
    "\n",
    "    # Save results DataFrame for future reference\n",
    "    results_df_path = os.path.join(save_dir, 'ctm_model_results_summary.csv')\n",
    "    results_df.to_csv(results_df_path, index=False)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Example Usage\n",
    "results_df = evaluate_ctm_models(\n",
    "    training_dataset=training_dataset,\n",
    "    tp=tp,\n",
    "    texts=texts,\n",
    "    dictionary=dictionary,\n",
    "    ctm_param_grid=ctm_param_grid,\n",
    "    metrics=('coherence', 'diversity'),\n",
    "    save_dir='../saved_models'\n",
    ")"
   ],
   "id": "53d4dcca10d0e83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 1/54 with num_topics=2, epochs=5, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1241.8724946521577\tTime: 0:00:00.119209: : 5it [00:00,  6.41it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 236.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 2/54 with num_topics=2, epochs=5, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1258.1615356445313\tTime: 0:00:00.101649: : 5it [00:00,  9.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 130.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 3/54 with num_topics=2, epochs=5, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1235.10888671875\tTime: 0:00:00.120076: : 5it [00:00,  8.01it/s]  \n",
      "100%|██████████| 22/22 [00:00<00:00, 264.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 4/54 with num_topics=2, epochs=5, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1259.3992309570312\tTime: 0:00:00.098110: : 5it [00:00, 10.18it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 136.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 5/54 with num_topics=2, epochs=5, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1236.5592099144346\tTime: 0:00:00.126337: : 5it [00:00,  8.04it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 269.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 6/54 with num_topics=2, epochs=5, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1260.1540771484374\tTime: 0:00:00.094907: : 5it [00:00, 10.42it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 137.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 7/54 with num_topics=2, epochs=10, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1210.8092273530506\tTime: 0:00:00.127307: : 10it [00:01,  7.93it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 264.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 8/54 with num_topics=2, epochs=10, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1221.9465454101562\tTime: 0:00:00.095662: : 10it [00:00, 10.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 142.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 9/54 with num_topics=2, epochs=10, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1202.1378115699404\tTime: 0:00:00.124235: : 10it [00:01,  8.09it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 266.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 10/54 with num_topics=2, epochs=10, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1240.77265625\tTime: 0:00:00.099481: : 10it [00:00, 10.34it/s]   \n",
      "100%|██████████| 11/11 [00:00<00:00, 133.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 11/54 with num_topics=2, epochs=10, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1207.7511625744048\tTime: 0:00:00.121807: : 10it [00:01,  8.13it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 263.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 12/54 with num_topics=2, epochs=10, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1224.7128173828125\tTime: 0:00:00.093406: : 10it [00:00, 10.20it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 141.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 13/54 with num_topics=2, epochs=20, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1198.3558989025298\tTime: 0:00:00.120650: : 20it [00:02,  8.21it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 280.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 14/54 with num_topics=2, epochs=20, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1202.6122314453125\tTime: 0:00:00.095210: : 20it [00:01, 10.34it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 144.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 15/54 with num_topics=2, epochs=20, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1198.0026274181548\tTime: 0:00:00.120149: : 20it [00:02,  8.05it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 257.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 16/54 with num_topics=2, epochs=20, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1211.5788330078126\tTime: 0:00:00.096753: : 20it [00:01, 10.32it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 134.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 17/54 with num_topics=2, epochs=20, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1199.840099516369\tTime: 0:00:00.120568: : 20it [00:02,  8.12it/s] \n",
      "100%|██████████| 22/22 [00:00<00:00, 270.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 18/54 with num_topics=2, epochs=20, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1213.1697387695312\tTime: 0:00:00.091557: : 20it [00:01, 10.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 141.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 19/54 with num_topics=3, epochs=5, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1239.553187779018\tTime: 0:00:00.119681: : 5it [00:00,  8.14it/s] \n",
      "100%|██████████| 22/22 [00:00<00:00, 277.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 20/54 with num_topics=3, epochs=5, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1253.5057006835937\tTime: 0:00:00.096733: : 5it [00:00, 10.39it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 137.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 21/54 with num_topics=3, epochs=5, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1239.830101376488\tTime: 0:00:00.119009: : 5it [00:00,  8.18it/s] \n",
      "100%|██████████| 22/22 [00:00<00:00, 267.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 22/54 with num_topics=3, epochs=5, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1256.6966186523437\tTime: 0:00:00.095865: : 5it [00:00, 10.70it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 138.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 23/54 with num_topics=3, epochs=5, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1238.2548130580358\tTime: 0:00:00.126091: : 5it [00:00,  8.02it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 266.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 24/54 with num_topics=3, epochs=5, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1245.9014404296875\tTime: 0:00:00.100756: : 5it [00:00, 10.01it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 141.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 25/54 with num_topics=3, epochs=10, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1228.2755301339287\tTime: 0:00:00.127816: : 10it [00:01,  7.98it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 256.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 26/54 with num_topics=3, epochs=10, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1233.3036499023438\tTime: 0:00:00.095026: : 10it [00:00, 10.37it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 135.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 27/54 with num_topics=3, epochs=10, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1211.2647588820685\tTime: 0:00:00.123737: : 10it [00:01,  8.10it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 266.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 28/54 with num_topics=3, epochs=10, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1234.9972778320312\tTime: 0:00:00.111077: : 10it [00:00, 10.32it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 117.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 29/54 with num_topics=3, epochs=10, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1217.3282005673364\tTime: 0:00:00.121976: : 10it [00:01,  8.20it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 278.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 30/54 with num_topics=3, epochs=10, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1245.8925048828125\tTime: 0:00:00.093002: : 10it [00:00, 10.41it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 137.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 31/54 with num_topics=3, epochs=20, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1200.0855596633185\tTime: 0:00:00.121270: : 20it [00:02,  8.18it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 267.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 32/54 with num_topics=3, epochs=20, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1198.1055908203125\tTime: 0:00:00.094883: : 20it [00:01, 10.40it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 138.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 33/54 with num_topics=3, epochs=20, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1197.5319010416667\tTime: 0:00:00.116978: : 20it [00:02,  8.36it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 268.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 34/54 with num_topics=3, epochs=20, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1205.55419921875\tTime: 0:00:00.096354: : 20it [00:01, 10.53it/s]  \n",
      "100%|██████████| 11/11 [00:00<00:00, 137.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 35/54 with num_topics=3, epochs=20, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1190.2181512741815\tTime: 0:00:00.122582: : 20it [00:02,  8.20it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 265.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 36/54 with num_topics=3, epochs=20, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1207.8763549804687\tTime: 0:00:00.097111: : 20it [00:01, 10.43it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 135.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 37/54 with num_topics=4, epochs=5, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1225.882545107887\tTime: 0:00:00.116633: : 5it [00:00,  8.31it/s] \n",
      "100%|██████████| 22/22 [00:00<00:00, 272.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 38/54 with num_topics=4, epochs=5, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1238.5932373046876\tTime: 0:00:00.094471: : 5it [00:00, 10.42it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 143.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 39/54 with num_topics=4, epochs=5, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1229.3214111328125\tTime: 0:00:00.141143: : 5it [00:00,  6.95it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 239.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 40/54 with num_topics=4, epochs=5, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1244.2259643554687\tTime: 0:00:00.099435: : 5it [00:00,  9.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 130.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 41/54 with num_topics=4, epochs=5, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6720/6840]\tTrain Loss: 1232.2129603794642\tTime: 0:00:00.128805: : 5it [00:00,  7.03it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 251.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 42/54 with num_topics=4, epochs=5, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5]\t Seen Samples: [6400/6840]\tTrain Loss: 1247.4148681640625\tTime: 0:00:00.097348: : 5it [00:00,  9.85it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 135.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 43/54 with num_topics=4, epochs=10, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1209.7703508649554\tTime: 0:00:00.120511: : 10it [00:01,  7.78it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 249.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 44/54 with num_topics=4, epochs=10, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1227.0463500976562\tTime: 0:00:00.100503: : 10it [00:01,  9.76it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 129.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 45/54 with num_topics=4, epochs=10, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1205.677501860119\tTime: 0:00:00.130837: : 10it [00:01,  7.95it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 258.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 46/54 with num_topics=4, epochs=10, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1217.5405029296876\tTime: 0:00:00.095766: : 10it [00:00, 10.22it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 134.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 47/54 with num_topics=4, epochs=10, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [13440/13680]\tTrain Loss: 1209.0902273995537\tTime: 0:00:00.128254: : 10it [00:01,  7.98it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 264.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 48/54 with num_topics=4, epochs=10, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1224.0424438476562\tTime: 0:00:00.093272: : 10it [00:01,  9.36it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 123.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 49/54 with num_topics=4, epochs=20, learning_rate=0.002, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1195.8507486979167\tTime: 0:00:00.117515: : 20it [00:02,  8.29it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 266.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 50/54 with num_topics=4, epochs=20, learning_rate=0.002, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1197.8334716796876\tTime: 0:00:00.092513: : 20it [00:01, 10.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 51/54 with num_topics=4, epochs=20, learning_rate=0.005, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1193.073218936012\tTime: 0:00:00.118083: : 20it [00:02,  8.02it/s] \n",
      "100%|██████████| 22/22 [00:00<00:00, 262.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 52/54 with num_topics=4, epochs=20, learning_rate=0.005, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1219.894189453125\tTime: 0:00:00.094912: : 20it [00:01, 10.39it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 138.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 53/54 with num_topics=4, epochs=20, learning_rate=0.01, batch_size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [26880/27360]\tTrain Loss: 1192.7959914434523\tTime: 0:00:00.124781: : 20it [00:02,  8.34it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 272.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CTM model 54/54 with num_topics=4, epochs=20, learning_rate=0.01, batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\t Seen Samples: [25600/27360]\tTrain Loss: 1211.399365234375\tTime: 0:00:00.095559: : 20it [00:01, 10.34it/s] \n",
      "100%|██████████| 11/11 [00:00<00:00, 132.35it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:49:31.842233Z",
     "start_time": "2025-05-07T20:49:31.825399Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "1453e523195612ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    model_id  num_topics  epochs  learning_rate  batch_size  coherence_score  \\\n",
       "25        26           3      10          0.002         128         0.342825   \n",
       "5          6           2       5          0.010         128         0.337699   \n",
       "43        44           4      10          0.002         128         0.333079   \n",
       "46        47           4      10          0.010          64         0.313800   \n",
       "28        29           3      10          0.010          64         0.311028   \n",
       "52        53           4      20          0.010          64         0.308045   \n",
       "36        37           4       5          0.002          64         0.307307   \n",
       "24        25           3      10          0.002          64         0.304547   \n",
       "35        36           3      20          0.010         128         0.301273   \n",
       "51        52           4      20          0.005         128         0.298688   \n",
       "50        51           4      20          0.005          64         0.297887   \n",
       "44        45           4      10          0.005          64         0.296685   \n",
       "29        30           3      10          0.010         128         0.289638   \n",
       "23        24           3       5          0.010         128         0.288598   \n",
       "0          1           2       5          0.002          64         0.288556   \n",
       "40        41           4       5          0.010          64         0.288538   \n",
       "1          2           2       5          0.002         128         0.286252   \n",
       "17        18           2      20          0.010         128         0.283708   \n",
       "10        11           2      10          0.010          64         0.282909   \n",
       "14        15           2      20          0.005          64         0.282904   \n",
       "22        23           3       5          0.010          64         0.281456   \n",
       "2          3           2       5          0.005          64         0.280707   \n",
       "48        49           4      20          0.002          64         0.280442   \n",
       "27        28           3      10          0.005         128         0.279598   \n",
       "47        48           4      10          0.010         128         0.278789   \n",
       "6          7           2      10          0.002          64         0.278585   \n",
       "34        35           3      20          0.010          64         0.276874   \n",
       "30        31           3      20          0.002          64         0.275925   \n",
       "9         10           2      10          0.005         128         0.275799   \n",
       "19        20           3       5          0.002         128         0.274212   \n",
       "13        14           2      20          0.002         128         0.270298   \n",
       "42        43           4      10          0.002          64         0.270158   \n",
       "8          9           2      10          0.005          64         0.269758   \n",
       "15        16           2      20          0.005         128         0.269623   \n",
       "45        46           4      10          0.005         128         0.269059   \n",
       "32        33           3      20          0.005          64         0.266442   \n",
       "18        19           3       5          0.002          64         0.265098   \n",
       "16        17           2      20          0.010          64         0.263315   \n",
       "26        27           3      10          0.005          64         0.263239   \n",
       "49        50           4      20          0.002         128         0.260899   \n",
       "7          8           2      10          0.002         128         0.254680   \n",
       "39        40           4       5          0.005         128         0.253649   \n",
       "4          5           2       5          0.010          64         0.253101   \n",
       "20        21           3       5          0.005          64         0.252337   \n",
       "37        38           4       5          0.002         128         0.251301   \n",
       "21        22           3       5          0.005         128         0.248297   \n",
       "33        34           3      20          0.005         128         0.248018   \n",
       "38        39           4       5          0.005          64         0.244918   \n",
       "3          4           2       5          0.005         128         0.243462   \n",
       "12        13           2      20          0.002          64         0.242929   \n",
       "53        54           4      20          0.010         128         0.234223   \n",
       "41        42           4       5          0.010         128         0.230786   \n",
       "31        32           3      20          0.002         128         0.225729   \n",
       "11        12           2      10          0.010         128         0.219576   \n",
       "\n",
       "    topic_diversity  \n",
       "25         0.966667  \n",
       "5          1.000000  \n",
       "43         1.000000  \n",
       "46         0.925000  \n",
       "28         1.000000  \n",
       "52         0.950000  \n",
       "36         0.975000  \n",
       "24         0.933333  \n",
       "35         0.966667  \n",
       "51         0.875000  \n",
       "50         0.900000  \n",
       "44         0.975000  \n",
       "29         1.000000  \n",
       "23         1.000000  \n",
       "0          1.000000  \n",
       "40         0.950000  \n",
       "1          1.000000  \n",
       "17         1.000000  \n",
       "10         1.000000  \n",
       "14         1.000000  \n",
       "22         1.000000  \n",
       "2          1.000000  \n",
       "48         0.925000  \n",
       "27         1.000000  \n",
       "47         0.950000  \n",
       "6          1.000000  \n",
       "34         0.900000  \n",
       "30         0.866667  \n",
       "9          1.000000  \n",
       "19         1.000000  \n",
       "13         1.000000  \n",
       "42         0.900000  \n",
       "8          1.000000  \n",
       "15         1.000000  \n",
       "45         0.925000  \n",
       "32         1.000000  \n",
       "18         0.933333  \n",
       "16         1.000000  \n",
       "26         1.000000  \n",
       "49         0.950000  \n",
       "7          1.000000  \n",
       "39         0.975000  \n",
       "4          1.000000  \n",
       "20         0.966667  \n",
       "37         0.975000  \n",
       "21         0.966667  \n",
       "33         1.000000  \n",
       "38         0.950000  \n",
       "3          1.000000  \n",
       "12         1.000000  \n",
       "53         0.900000  \n",
       "41         0.925000  \n",
       "31         1.000000  \n",
       "11         1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>topic_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.342825</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.337699</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.333079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.311028</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.308045</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.307307</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.304547</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.301273</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.298688</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.297887</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.296685</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.289638</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.288598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.288556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.288538</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.286252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.283708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.282909</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.282904</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.281456</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.280707</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.280442</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.279598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.278789</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.278585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.276874</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.275925</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.275799</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.274212</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.270298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.270158</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.269758</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.269623</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.269059</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.266442</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.265098</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.263315</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.263239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.260899</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.254680</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.253649</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.253101</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.252337</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.251301</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.248297</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.248018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>64</td>\n",
       "      <td>0.244918</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>128</td>\n",
       "      <td>0.243462</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>64</td>\n",
       "      <td>0.242929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.234223</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.230786</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002</td>\n",
       "      <td>128</td>\n",
       "      <td>0.225729</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.219576</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T20:49:46.962892Z",
     "start_time": "2025-05-07T20:49:45.804087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = pd.read_csv('../saved_models/ctm_model_results_summary.csv')\n",
    "best_params = results_df.iloc[0]  # Assuming the first row has the best score after sorting\n",
    "\n",
    "# Extract hyperparameters\n",
    "best_num_topics = int(best_params['num_topics'])\n",
    "best_epochs = int(best_params['epochs'])\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "best_batch_size = int(best_params['batch_size'])\n",
    "\n",
    "best_ctm_model = CombinedTM(\n",
    "    bow_size=len(tp.vocab),\n",
    "    contextual_size=768,\n",
    "    n_components=best_num_topics,\n",
    "    num_epochs=best_epochs,\n",
    "    batch_size=best_batch_size,\n",
    "    activation='softplus',\n",
    "    dropout=0.2,\n",
    "    solver='adam',\n",
    "    num_data_loader_workers=0,\n",
    ")\n",
    "\n",
    "# Train the model using the original training dataset\n",
    "best_ctm_model.fit(training_dataset)"
   ],
   "id": "be2d94f05fa06b6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10]\t Seen Samples: [12800/13680]\tTrain Loss: 1219.2812255859376\tTime: 0:00:00.100820: : 10it [00:01,  9.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 132.15it/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38f36d37af954df7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
