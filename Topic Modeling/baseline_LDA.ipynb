{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:13.553651Z",
     "start_time": "2024-10-19T16:21:13.530774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from urllib3.exceptions import NotOpenSSLWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=NotOpenSSLWarning)"
   ],
   "id": "fc3f3b3bd294dd6b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:22.196018Z",
     "start_time": "2024-10-19T16:21:21.688919Z"
    }
   },
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Text processing\n",
    "from gensim import corpora\n",
    "\n",
    "# Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gensim import models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "data = './preprocessed_df.pkl'"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:22.406854Z",
     "start_time": "2024-10-19T16:21:22.197913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_pickle(data)\n",
    "df[['Artist', 'Song', 'Tokens', 'Lyrics', 'Coast']].head()"
   ],
   "id": "f2660c040bd72de1",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:22.515142Z",
     "start_time": "2024-10-19T16:21:22.407880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(df['Tokens'])\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "print(f\"Number of unique tokens: {len(dictionary)}\")"
   ],
   "id": "143514f57d9c8a2e",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:25.647069Z",
     "start_time": "2024-10-19T16:21:25.552387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert documents to a bag-of-words representation\n",
    "corpus = [dictionary.doc2bow(text) for text in df['Tokens']]"
   ],
   "id": "1d16f9c2c26ac682",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:25.923047Z",
     "start_time": "2024-10-19T16:21:25.917943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, start, limit, step, chunksize, passes, iterations, eval_every):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "\n",
    "    # Add tqdm for progress tracking\n",
    "    for num_topics in tqdm(range(start, limit, step), desc=\"Computing coherence\"):\n",
    "        model = models.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            random_state=42,\n",
    "            chunksize=chunksize,\n",
    "            passes=passes,\n",
    "            iterations=iterations,\n",
    "            alpha='auto',\n",
    "            eta='auto',\n",
    "            eval_every=eval_every\n",
    "        )\n",
    "        model_list.append(model)\n",
    "\n",
    "        # Applies a sliding window and evaluates similarity of the top words in each topic. \n",
    "        coherencemodel = CoherenceModel(\n",
    "            model=model,\n",
    "            texts=texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_v'\n",
    "        )\n",
    "\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ],
   "id": "e512d4e3c00e40e2",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:59.418487Z",
     "start_time": "2024-10-19T16:21:27.694472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = 2\n",
    "limit = 6\n",
    "step = 1\n",
    "chunksize = 200\n",
    "passes = 15\n",
    "iterations = 100\n",
    "eval_every = 10\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(\n",
    "    dictionary=dictionary,\n",
    "    corpus=corpus,\n",
    "    texts=df['Tokens'],\n",
    "    start=start,\n",
    "    limit=limit,\n",
    "    step=step,\n",
    "    chunksize=chunksize,\n",
    "    passes=passes,\n",
    "    iterations=iterations,\n",
    "    eval_every=eval_every\n",
    ")"
   ],
   "id": "fbbef797391c9dbc",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:21:59.652606Z",
     "start_time": "2024-10-19T16:21:59.421534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data for Seaborn\n",
    "x = list(range(start, limit, step))\n",
    "\n",
    "# Create a barplot with Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=x, y=coherence_values)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Scores for Different Numbers of Topics\")\n",
    "\n",
    "# Ensure integer values on the x-axis\n",
    "plt.xticks(ticks=range(start, limit, step))\n",
    "\n",
    "plt.show()"
   ],
   "id": "1d615cd04185e696",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:14.111018Z",
     "start_time": "2024-10-19T16:22:14.107263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the model with highest coherence\n",
    "optimal_index = coherence_values.index(max(coherence_values))\n",
    "optimal_model = model_list[optimal_index]\n",
    "optimal_num_topics = x[optimal_index]\n",
    "\n",
    "print(f'Optimal Number of Topics: {optimal_num_topics}')\n",
    "print(f'Highest Coherence Score: {coherence_values[optimal_index]:.4f}')"
   ],
   "id": "48071e2fe87f2f30",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:36.256039Z",
     "start_time": "2024-10-19T16:22:35.709342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the visualization\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(optimal_model, corpus, dictionary)\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(vis)"
   ],
   "id": "93cc9fae3837ae9e",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:38.365033Z",
     "start_time": "2024-10-19T16:22:37.758906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row_list, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the dominant topic, its percentage, and keywords\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # Only the dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "\n",
    "                # Creating a temporary DataFrame to hold the new row\n",
    "                temp_df = pd.DataFrame([[int(topic_num), round(prop_topic, 4), topic_keywords]],\n",
    "                                       columns=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords'])\n",
    "\n",
    "                # Use pd.concat() instead of append\n",
    "                sent_topics_df = pd.concat([sent_topics_df, temp_df], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Add original text to the DataFrame\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents.rename('Text')], axis=1)\n",
    "\n",
    "    return sent_topics_df\n",
    "\n",
    "# Apply the updated function\n",
    "df_topic_sents_keywords = format_topics_sentences(\n",
    "    ldamodel=optimal_model,\n",
    "    corpus=corpus,\n",
    "    texts=df['Lyrics']\n",
    ")\n",
    "\n",
    "# Format the output\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Display the result\n",
    "df_dominant_topic.head()"
   ],
   "id": "40fd12776f4eb9d9",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:51.665117Z",
     "start_time": "2024-10-19T16:22:51.630063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you have a 'Region' column indicating 'East' or 'West'\n",
    "df_dominant_topic['Coast'] = df['Coast']\n",
    "\n",
    "# Calculate the distribution of topics by region (East vs West) in percentages\n",
    "topic_region_dist = pd.crosstab(df_dominant_topic['Dominant_Topic'],\n",
    "                                df_dominant_topic['Coast'],\n",
    "                                normalize='index') * 100\n",
    "print(topic_region_dist)"
   ],
   "id": "bd13b4cea73ca753",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:54.317426Z",
     "start_time": "2024-10-19T16:22:54.113300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reset the index to convert 'Dominant_Topic' from index to column\n",
    "topic_region_dist = topic_region_dist.reset_index()\n",
    "\n",
    "# Melt the DataFrame for easier plotting with seaborn\n",
    "topic_region_dist_melted = topic_region_dist.melt(id_vars='Dominant_Topic',\n",
    "                                                  value_vars=['east_coast', 'west_coast'],\n",
    "                                                  var_name='Coast',\n",
    "                                                  value_name='Percentage')\n",
    "\n",
    "# Define custom colors for East Coast (blue) and West Coast (red)\n",
    "palette = {\"east_coast\": \"blue\", \"west_coast\": \"red\"}\n",
    "\n",
    "# Create the bar plot with custom colors\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Dominant_Topic', y='Percentage', hue='Coast', data=topic_region_dist_melted, palette=palette)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel(\"Dominant Topic\")\n",
    "plt.ylabel(\"Percentage Contribution\")\n",
    "plt.title(\"Percentage Contribution of East and West Coast to Each Topic\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "8d9662bc11e19eea",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:22:55.592571Z",
     "start_time": "2024-10-19T16:22:55.578524Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "a8da7b53267d4f1f",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "ff1e7a0e62b2c6c4",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
