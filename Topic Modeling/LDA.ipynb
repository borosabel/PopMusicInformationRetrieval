{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:45:35.218853Z",
     "start_time": "2024-10-21T13:45:35.209724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)"
   ],
   "id": "4cb2a3628ed8d3d9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:24:23.664536Z",
     "start_time": "2024-10-21T15:24:23.463139Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "save_dir = './saved_models'\n",
    "\n",
    "df = pd.read_pickle('preprocessed_df.pkl')\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(df['Tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['Tokens']]\n",
    "texts = df['Tokens']"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:45:36.991745Z",
     "start_time": "2024-10-21T13:45:36.989584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_topics_list = [2, 3, 4]\n",
    "alpha_list = ['symmetric']\n",
    "beta_list = ['symmetric']\n",
    "passes_list = [10, 20]\n",
    "iterations_list = [50, 100]\n",
    "results = []"
   ],
   "id": "9f315eb19d8f48e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T16:24:23.107069Z",
     "start_time": "2024-10-21T15:31:37.389391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_lda_models(corpus, dictionary, texts, num_topics_list, alpha_list, beta_list, passes_list, iterations_list, metrics=('coherence', 'diversity')):\n",
    "    \"\"\"\n",
    "    Train LDA models with a given set of hyperparameters and metrics, then save the model parameters and evaluation metrics in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - corpus: The BoW corpus.\n",
    "    - dictionary: The Gensim dictionary.\n",
    "    - texts: The list of tokenized texts.\n",
    "    - num_topics_list: List of values for the number of topics to try.\n",
    "    - alpha_list: List of values for the alpha hyperparameter.\n",
    "    - beta_list: List of values for the beta hyperparameter.\n",
    "    - passes_list: List of values for the number of passes during training.\n",
    "    - iterations_list: List of values for the number of iterations during training.\n",
    "    - metrics: Tuple of metrics to evaluate ('coherence', 'diversity', or both).\n",
    "    \n",
    "    Returns:\n",
    "    - results_df: A DataFrame containing the evaluation results and model parameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Generate all combinations of the hyperparameters\n",
    "    param_grid = list(itertools.product(num_topics_list, alpha_list, beta_list, passes_list, iterations_list))\n",
    "\n",
    "    # Iterate through each parameter combination\n",
    "    for idx, (num_topics, alpha, beta, passes, iterations) in enumerate(param_grid):\n",
    "        try:\n",
    "            print(f\"Training model {idx+1}/{len(param_grid)} with num_topics={num_topics}, alpha={alpha}, beta={beta}, passes={passes}, iterations={iterations}\")\n",
    "\n",
    "            # Train the LDA model\n",
    "            lda_model = LdaModel(\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=num_topics,\n",
    "                alpha=alpha,\n",
    "                eta=beta,\n",
    "                passes=passes,\n",
    "                iterations=iterations,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            # Initialize result dictionary\n",
    "            result = {\n",
    "                'model_id': idx + 1,\n",
    "                'num_topics': num_topics,\n",
    "                'alpha': alpha,\n",
    "                'beta': beta,\n",
    "                'passes': passes,\n",
    "                'iterations': iterations,\n",
    "            }\n",
    "\n",
    "            # Evaluate the model based on specified metrics\n",
    "            if 'coherence' in metrics:\n",
    "                coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "                coherence_lda = coherence_model_lda.get_coherence()\n",
    "                result['coherence_score'] = coherence_lda\n",
    "\n",
    "            if 'diversity' in metrics:\n",
    "                topic_words = lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False)\n",
    "                unique_words = set()\n",
    "                total_words = 0\n",
    "\n",
    "                for _, words in topic_words:\n",
    "                    words = [word for word, _ in words]\n",
    "                    unique_words.update(words)\n",
    "                    total_words += len(words)\n",
    "\n",
    "                topic_diversity = len(unique_words) / total_words if total_words > 0 else 0\n",
    "                result['topic_diversity'] = topic_diversity\n",
    "\n",
    "            # Append the result to the results list\n",
    "            results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while training model {idx+1}: {e}\")\n",
    "            continue  # Skip this iteration if there's an error\n",
    "\n",
    "    # Convert results to a DataFrame and sort by coherence_score or other metric\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if 'coherence' in metrics:\n",
    "        results_df = results_df.sort_values(by='coherence_score', ascending=False)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Example Usage\n",
    "results_df = evaluate_lda_models(\n",
    "    corpus=corpus,\n",
    "    dictionary=dictionary,\n",
    "    texts=texts,\n",
    "    num_topics_list=[2, 3, 4],\n",
    "    alpha_list=[0.01, 0.1, 'auto'],\n",
    "    beta_list=[0.01, 0.1, 'auto'],\n",
    "    passes_list=[10, 20],\n",
    "    iterations_list=[100, 200],\n",
    "    metrics=('coherence', 'diversity')\n",
    ")\n",
    "\n",
    "# Display the top 5 results\n",
    "print(results_df.head(5))\n",
    "\n",
    "# Save the results DataFrame for future reference\n",
    "results_df_path = 'saved_models/lda_model_results_summary.csv'\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "results_df.to_csv(results_df_path, index=False)"
   ],
   "id": "524fd2d47e7e41be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/144 with num_topics=2, alpha=0.01, beta=0.01, passes=10, iterations=100\n",
      "Training model 2/144 with num_topics=2, alpha=0.01, beta=0.01, passes=10, iterations=200\n",
      "Training model 3/144 with num_topics=2, alpha=0.01, beta=0.01, passes=20, iterations=100\n",
      "Training model 4/144 with num_topics=2, alpha=0.01, beta=0.01, passes=20, iterations=200\n",
      "Training model 5/144 with num_topics=2, alpha=0.01, beta=0.1, passes=10, iterations=100\n",
      "Training model 6/144 with num_topics=2, alpha=0.01, beta=0.1, passes=10, iterations=200\n",
      "Training model 7/144 with num_topics=2, alpha=0.01, beta=0.1, passes=20, iterations=100\n",
      "Training model 8/144 with num_topics=2, alpha=0.01, beta=0.1, passes=20, iterations=200\n",
      "Training model 9/144 with num_topics=2, alpha=0.01, beta=auto, passes=10, iterations=100\n",
      "Training model 10/144 with num_topics=2, alpha=0.01, beta=auto, passes=10, iterations=200\n",
      "Training model 11/144 with num_topics=2, alpha=0.01, beta=auto, passes=20, iterations=100\n",
      "Training model 12/144 with num_topics=2, alpha=0.01, beta=auto, passes=20, iterations=200\n",
      "Training model 13/144 with num_topics=2, alpha=0.1, beta=0.01, passes=10, iterations=100\n",
      "Training model 14/144 with num_topics=2, alpha=0.1, beta=0.01, passes=10, iterations=200\n",
      "Training model 15/144 with num_topics=2, alpha=0.1, beta=0.01, passes=20, iterations=100\n",
      "Training model 16/144 with num_topics=2, alpha=0.1, beta=0.01, passes=20, iterations=200\n",
      "Training model 17/144 with num_topics=2, alpha=0.1, beta=0.1, passes=10, iterations=100\n",
      "Training model 18/144 with num_topics=2, alpha=0.1, beta=0.1, passes=10, iterations=200\n",
      "Training model 19/144 with num_topics=2, alpha=0.1, beta=0.1, passes=20, iterations=100\n",
      "Training model 20/144 with num_topics=2, alpha=0.1, beta=0.1, passes=20, iterations=200\n",
      "Training model 21/144 with num_topics=2, alpha=0.1, beta=auto, passes=10, iterations=100\n",
      "Training model 22/144 with num_topics=2, alpha=0.1, beta=auto, passes=10, iterations=200\n",
      "Training model 23/144 with num_topics=2, alpha=0.1, beta=auto, passes=20, iterations=100\n",
      "Training model 24/144 with num_topics=2, alpha=0.1, beta=auto, passes=20, iterations=200\n",
      "Training model 25/144 with num_topics=2, alpha=auto, beta=0.01, passes=10, iterations=100\n",
      "Training model 26/144 with num_topics=2, alpha=auto, beta=0.01, passes=10, iterations=200\n",
      "Training model 27/144 with num_topics=2, alpha=auto, beta=0.01, passes=20, iterations=100\n",
      "Training model 28/144 with num_topics=2, alpha=auto, beta=0.01, passes=20, iterations=200\n",
      "Training model 29/144 with num_topics=2, alpha=auto, beta=0.1, passes=10, iterations=100\n",
      "Training model 30/144 with num_topics=2, alpha=auto, beta=0.1, passes=10, iterations=200\n",
      "Training model 31/144 with num_topics=2, alpha=auto, beta=0.1, passes=20, iterations=100\n",
      "Training model 32/144 with num_topics=2, alpha=auto, beta=0.1, passes=20, iterations=200\n",
      "Training model 33/144 with num_topics=2, alpha=auto, beta=auto, passes=10, iterations=100\n",
      "Training model 34/144 with num_topics=2, alpha=auto, beta=auto, passes=10, iterations=200\n",
      "Training model 35/144 with num_topics=2, alpha=auto, beta=auto, passes=20, iterations=100\n",
      "Training model 36/144 with num_topics=2, alpha=auto, beta=auto, passes=20, iterations=200\n",
      "Training model 37/144 with num_topics=3, alpha=0.01, beta=0.01, passes=10, iterations=100\n",
      "Training model 38/144 with num_topics=3, alpha=0.01, beta=0.01, passes=10, iterations=200\n",
      "Training model 39/144 with num_topics=3, alpha=0.01, beta=0.01, passes=20, iterations=100\n",
      "Training model 40/144 with num_topics=3, alpha=0.01, beta=0.01, passes=20, iterations=200\n",
      "Training model 41/144 with num_topics=3, alpha=0.01, beta=0.1, passes=10, iterations=100\n",
      "Training model 42/144 with num_topics=3, alpha=0.01, beta=0.1, passes=10, iterations=200\n",
      "Training model 43/144 with num_topics=3, alpha=0.01, beta=0.1, passes=20, iterations=100\n",
      "Training model 44/144 with num_topics=3, alpha=0.01, beta=0.1, passes=20, iterations=200\n",
      "Training model 45/144 with num_topics=3, alpha=0.01, beta=auto, passes=10, iterations=100\n",
      "Training model 46/144 with num_topics=3, alpha=0.01, beta=auto, passes=10, iterations=200\n",
      "Training model 47/144 with num_topics=3, alpha=0.01, beta=auto, passes=20, iterations=100\n",
      "Training model 48/144 with num_topics=3, alpha=0.01, beta=auto, passes=20, iterations=200\n",
      "Training model 49/144 with num_topics=3, alpha=0.1, beta=0.01, passes=10, iterations=100\n",
      "Training model 50/144 with num_topics=3, alpha=0.1, beta=0.01, passes=10, iterations=200\n",
      "Training model 51/144 with num_topics=3, alpha=0.1, beta=0.01, passes=20, iterations=100\n",
      "Training model 52/144 with num_topics=3, alpha=0.1, beta=0.01, passes=20, iterations=200\n",
      "Training model 53/144 with num_topics=3, alpha=0.1, beta=0.1, passes=10, iterations=100\n",
      "Training model 54/144 with num_topics=3, alpha=0.1, beta=0.1, passes=10, iterations=200\n",
      "Training model 55/144 with num_topics=3, alpha=0.1, beta=0.1, passes=20, iterations=100\n",
      "Training model 56/144 with num_topics=3, alpha=0.1, beta=0.1, passes=20, iterations=200\n",
      "Training model 57/144 with num_topics=3, alpha=0.1, beta=auto, passes=10, iterations=100\n",
      "Training model 58/144 with num_topics=3, alpha=0.1, beta=auto, passes=10, iterations=200\n",
      "Training model 59/144 with num_topics=3, alpha=0.1, beta=auto, passes=20, iterations=100\n",
      "Training model 60/144 with num_topics=3, alpha=0.1, beta=auto, passes=20, iterations=200\n",
      "Training model 61/144 with num_topics=3, alpha=auto, beta=0.01, passes=10, iterations=100\n",
      "Training model 62/144 with num_topics=3, alpha=auto, beta=0.01, passes=10, iterations=200\n",
      "Training model 63/144 with num_topics=3, alpha=auto, beta=0.01, passes=20, iterations=100\n",
      "Training model 64/144 with num_topics=3, alpha=auto, beta=0.01, passes=20, iterations=200\n",
      "Training model 65/144 with num_topics=3, alpha=auto, beta=0.1, passes=10, iterations=100\n",
      "Training model 66/144 with num_topics=3, alpha=auto, beta=0.1, passes=10, iterations=200\n",
      "Training model 67/144 with num_topics=3, alpha=auto, beta=0.1, passes=20, iterations=100\n",
      "Training model 68/144 with num_topics=3, alpha=auto, beta=0.1, passes=20, iterations=200\n",
      "Training model 69/144 with num_topics=3, alpha=auto, beta=auto, passes=10, iterations=100\n",
      "Training model 70/144 with num_topics=3, alpha=auto, beta=auto, passes=10, iterations=200\n",
      "Training model 71/144 with num_topics=3, alpha=auto, beta=auto, passes=20, iterations=100\n",
      "Training model 72/144 with num_topics=3, alpha=auto, beta=auto, passes=20, iterations=200\n",
      "Training model 73/144 with num_topics=4, alpha=0.01, beta=0.01, passes=10, iterations=100\n",
      "Training model 74/144 with num_topics=4, alpha=0.01, beta=0.01, passes=10, iterations=200\n",
      "Training model 75/144 with num_topics=4, alpha=0.01, beta=0.01, passes=20, iterations=100\n",
      "Training model 76/144 with num_topics=4, alpha=0.01, beta=0.01, passes=20, iterations=200\n",
      "Training model 77/144 with num_topics=4, alpha=0.01, beta=0.1, passes=10, iterations=100\n",
      "Training model 78/144 with num_topics=4, alpha=0.01, beta=0.1, passes=10, iterations=200\n",
      "Training model 79/144 with num_topics=4, alpha=0.01, beta=0.1, passes=20, iterations=100\n",
      "Training model 80/144 with num_topics=4, alpha=0.01, beta=0.1, passes=20, iterations=200\n",
      "Training model 81/144 with num_topics=4, alpha=0.01, beta=auto, passes=10, iterations=100\n",
      "Training model 82/144 with num_topics=4, alpha=0.01, beta=auto, passes=10, iterations=200\n",
      "Training model 83/144 with num_topics=4, alpha=0.01, beta=auto, passes=20, iterations=100\n",
      "Training model 84/144 with num_topics=4, alpha=0.01, beta=auto, passes=20, iterations=200\n",
      "Training model 85/144 with num_topics=4, alpha=0.1, beta=0.01, passes=10, iterations=100\n",
      "Training model 86/144 with num_topics=4, alpha=0.1, beta=0.01, passes=10, iterations=200\n",
      "Training model 87/144 with num_topics=4, alpha=0.1, beta=0.01, passes=20, iterations=100\n",
      "Training model 88/144 with num_topics=4, alpha=0.1, beta=0.01, passes=20, iterations=200\n",
      "Training model 89/144 with num_topics=4, alpha=0.1, beta=0.1, passes=10, iterations=100\n",
      "Training model 90/144 with num_topics=4, alpha=0.1, beta=0.1, passes=10, iterations=200\n",
      "Training model 91/144 with num_topics=4, alpha=0.1, beta=0.1, passes=20, iterations=100\n",
      "Training model 92/144 with num_topics=4, alpha=0.1, beta=0.1, passes=20, iterations=200\n",
      "Training model 93/144 with num_topics=4, alpha=0.1, beta=auto, passes=10, iterations=100\n",
      "Training model 94/144 with num_topics=4, alpha=0.1, beta=auto, passes=10, iterations=200\n",
      "Training model 95/144 with num_topics=4, alpha=0.1, beta=auto, passes=20, iterations=100\n",
      "Training model 96/144 with num_topics=4, alpha=0.1, beta=auto, passes=20, iterations=200\n",
      "Training model 97/144 with num_topics=4, alpha=auto, beta=0.01, passes=10, iterations=100\n",
      "Training model 98/144 with num_topics=4, alpha=auto, beta=0.01, passes=10, iterations=200\n",
      "Training model 99/144 with num_topics=4, alpha=auto, beta=0.01, passes=20, iterations=100\n",
      "Training model 100/144 with num_topics=4, alpha=auto, beta=0.01, passes=20, iterations=200\n",
      "Training model 101/144 with num_topics=4, alpha=auto, beta=0.1, passes=10, iterations=100\n",
      "Training model 102/144 with num_topics=4, alpha=auto, beta=0.1, passes=10, iterations=200\n",
      "Training model 103/144 with num_topics=4, alpha=auto, beta=0.1, passes=20, iterations=100\n",
      "Training model 104/144 with num_topics=4, alpha=auto, beta=0.1, passes=20, iterations=200\n",
      "Training model 105/144 with num_topics=4, alpha=auto, beta=auto, passes=10, iterations=100\n",
      "Training model 106/144 with num_topics=4, alpha=auto, beta=auto, passes=10, iterations=200\n",
      "Training model 107/144 with num_topics=4, alpha=auto, beta=auto, passes=20, iterations=100\n",
      "Training model 108/144 with num_topics=4, alpha=auto, beta=auto, passes=20, iterations=200\n",
      "Training model 109/144 with num_topics=5, alpha=0.01, beta=0.01, passes=10, iterations=100\n",
      "Training model 110/144 with num_topics=5, alpha=0.01, beta=0.01, passes=10, iterations=200\n",
      "Training model 111/144 with num_topics=5, alpha=0.01, beta=0.01, passes=20, iterations=100\n",
      "Training model 112/144 with num_topics=5, alpha=0.01, beta=0.01, passes=20, iterations=200\n",
      "Training model 113/144 with num_topics=5, alpha=0.01, beta=0.1, passes=10, iterations=100\n",
      "Training model 114/144 with num_topics=5, alpha=0.01, beta=0.1, passes=10, iterations=200\n",
      "Training model 115/144 with num_topics=5, alpha=0.01, beta=0.1, passes=20, iterations=100\n",
      "Training model 116/144 with num_topics=5, alpha=0.01, beta=0.1, passes=20, iterations=200\n",
      "Training model 117/144 with num_topics=5, alpha=0.01, beta=auto, passes=10, iterations=100\n",
      "Training model 118/144 with num_topics=5, alpha=0.01, beta=auto, passes=10, iterations=200\n",
      "Training model 119/144 with num_topics=5, alpha=0.01, beta=auto, passes=20, iterations=100\n",
      "Training model 120/144 with num_topics=5, alpha=0.01, beta=auto, passes=20, iterations=200\n",
      "Training model 121/144 with num_topics=5, alpha=0.1, beta=0.01, passes=10, iterations=100\n",
      "Training model 122/144 with num_topics=5, alpha=0.1, beta=0.01, passes=10, iterations=200\n",
      "Training model 123/144 with num_topics=5, alpha=0.1, beta=0.01, passes=20, iterations=100\n",
      "Training model 124/144 with num_topics=5, alpha=0.1, beta=0.01, passes=20, iterations=200\n",
      "Training model 125/144 with num_topics=5, alpha=0.1, beta=0.1, passes=10, iterations=100\n",
      "Training model 126/144 with num_topics=5, alpha=0.1, beta=0.1, passes=10, iterations=200\n",
      "Training model 127/144 with num_topics=5, alpha=0.1, beta=0.1, passes=20, iterations=100\n",
      "Training model 128/144 with num_topics=5, alpha=0.1, beta=0.1, passes=20, iterations=200\n",
      "Training model 129/144 with num_topics=5, alpha=0.1, beta=auto, passes=10, iterations=100\n",
      "Training model 130/144 with num_topics=5, alpha=0.1, beta=auto, passes=10, iterations=200\n",
      "Training model 131/144 with num_topics=5, alpha=0.1, beta=auto, passes=20, iterations=100\n",
      "Training model 132/144 with num_topics=5, alpha=0.1, beta=auto, passes=20, iterations=200\n",
      "Training model 133/144 with num_topics=5, alpha=auto, beta=0.01, passes=10, iterations=100\n",
      "Training model 134/144 with num_topics=5, alpha=auto, beta=0.01, passes=10, iterations=200\n",
      "Training model 135/144 with num_topics=5, alpha=auto, beta=0.01, passes=20, iterations=100\n",
      "Training model 136/144 with num_topics=5, alpha=auto, beta=0.01, passes=20, iterations=200\n",
      "Training model 137/144 with num_topics=5, alpha=auto, beta=0.1, passes=10, iterations=100\n",
      "Training model 138/144 with num_topics=5, alpha=auto, beta=0.1, passes=10, iterations=200\n",
      "Training model 139/144 with num_topics=5, alpha=auto, beta=0.1, passes=20, iterations=100\n",
      "Training model 140/144 with num_topics=5, alpha=auto, beta=0.1, passes=20, iterations=200\n",
      "Training model 141/144 with num_topics=5, alpha=auto, beta=auto, passes=10, iterations=100\n",
      "Training model 142/144 with num_topics=5, alpha=auto, beta=auto, passes=10, iterations=200\n",
      "Training model 143/144 with num_topics=5, alpha=auto, beta=auto, passes=20, iterations=100\n",
      "Training model 144/144 with num_topics=5, alpha=auto, beta=auto, passes=20, iterations=200\n",
      "     model_id  num_topics alpha  beta  passes  iterations  coherence_score  \\\n",
      "111       112           5  0.01  0.01      20         200         0.213740   \n",
      "123       124           5   0.1  0.01      20         200         0.213740   \n",
      "127       128           5   0.1   0.1      20         200         0.213740   \n",
      "131       132           5   0.1  auto      20         200         0.213740   \n",
      "135       136           5  auto  0.01      20         200         0.213358   \n",
      "\n",
      "     topic_diversity  \n",
      "111              0.6  \n",
      "123              0.6  \n",
      "127              0.6  \n",
      "131              0.6  \n",
      "135              0.6  \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:52:42.680036Z",
     "start_time": "2024-10-21T19:52:42.604523Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "824c6a8736d5bbb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     model_id  num_topics alpha  beta  passes  iterations  coherence_score  \\\n",
       "111       112           5  0.01  0.01      20         200         0.213740   \n",
       "123       124           5   0.1  0.01      20         200         0.213740   \n",
       "127       128           5   0.1   0.1      20         200         0.213740   \n",
       "131       132           5   0.1  auto      20         200         0.213740   \n",
       "135       136           5  auto  0.01      20         200         0.213358   \n",
       "..        ...         ...   ...   ...     ...         ...              ...   \n",
       "28         29           2  auto   0.1      10         100         0.182687   \n",
       "29         30           2  auto   0.1      10         200         0.182687   \n",
       "32         33           2  auto  auto      10         100         0.182687   \n",
       "33         34           2  auto  auto      10         200         0.182687   \n",
       "0           1           2  0.01  0.01      10         100         0.182687   \n",
       "\n",
       "     topic_diversity  \n",
       "111              0.6  \n",
       "123              0.6  \n",
       "127              0.6  \n",
       "131              0.6  \n",
       "135              0.6  \n",
       "..               ...  \n",
       "28               0.8  \n",
       "29               0.8  \n",
       "32               0.8  \n",
       "33               0.8  \n",
       "0                0.8  \n",
       "\n",
       "[144 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>passes</th>\n",
       "      <th>iterations</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>topic_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>0.213358</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bbcb03c992b042f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
