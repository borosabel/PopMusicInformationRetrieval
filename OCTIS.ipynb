{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T14:51:23.789836Z",
     "start_time": "2024-10-13T14:51:23.335046Z"
    }
   },
   "source": [
    "import string\n",
    "import spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import utility_functions as utils\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy.sparse import dok_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "\n",
    "# Octis is the library which can use different implemented topic modelling techniques\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.models.LDA import LDA\n",
    "from octis.models.CTM import CTM\n",
    "from octis.models.ETM import ETM\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.models.NMF import NMF\n",
    "\n",
    "importlib.reload(utils)\n",
    "data = './preprocessed_df.pkl'"
   ],
   "execution_count": 77,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_pickle(data)\n",
    "df[['Artist', 'Song', 'Tokens', 'Lyrics', 'Coast']].head()"
   ],
   "id": "93f27912d1cc82c5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the corpus required by OCTIS to build up the dataset\n",
    "with open('corpus.tsv', 'w', encoding='utf-8') as file:\n",
    "    for lyrics in df['Lyrics']:\n",
    "        if pd.notna(lyrics):\n",
    "            file.write(lyrics + '\\n')"
   ],
   "id": "197d2eab0e57aef4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Flatten all tokens to create a single list of words\n",
    "vocab = set(chain.from_iterable(df['Tokens'].tolist()))\n",
    "\n",
    "# Save as vocabulary.json\n",
    "with open(\"./vocabulary.json\", 'w') as f:\n",
    "    json.dump(list(vocab), f)"
   ],
   "id": "b66e5c9fe5e4a722",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the document-term matrix\n",
    "num_docs = len(df)\n",
    "num_terms = len(vocab)\n",
    "doc_term_matrix = dok_matrix((num_docs, num_terms), dtype=np.int32)\n",
    "\n",
    "# Build the matrix\n",
    "token_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "for doc_idx, tokens in enumerate(df['Tokens']):\n",
    "    for token in tokens:\n",
    "        if token in token_to_index:\n",
    "            word_idx = token_to_index[token]\n",
    "            doc_term_matrix[doc_idx, word_idx] += 1\n",
    "\n",
    "# Convert the matrix to a sparse format JSON\n",
    "sparse_matrix = []\n",
    "for (doc_idx, word_idx), freq in doc_term_matrix.items():\n",
    "    sparse_matrix.append([doc_idx, word_idx, int(freq)])\n",
    "\n",
    "# Save as doc_term_matrix.json\n",
    "with open(\"./doc_term_matrix.json\", 'w') as f:\n",
    "    json.dump(sparse_matrix, f)"
   ],
   "id": "5fa354b7af283132",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize preprocessing\n",
    "preprocessor = Preprocessing(\n",
    "    vocabulary=None,\n",
    "    max_features=None,\n",
    "    remove_punctuation=True,\n",
    "    punctuation=string.punctuation,\n",
    "    lemmatize=True,\n",
    "    min_chars=2,\n",
    "    min_words_docs=0,\n",
    "    save_original_indexes=True,\n",
    "    min_df=0.05,\n",
    "    max_df=0.8,\n",
    "    split=True\n",
    ")\n",
    "\n",
    "dataset = preprocessor.preprocess_dataset(documents_path=\"./corpus.tsv\")"
   ],
   "id": "51b8dacd377937e6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:39:27.046309Z",
     "start_time": "2024-10-13T14:39:22.652694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "\n",
    "# Initialize the coherence and diversity metrics\n",
    "coherence_cv = Coherence(topk=10, measure='c_v')\n",
    "coherence_umass = Coherence(topk=10, measure='u_mass')\n",
    "topic_diversity = TopicDiversity(topk=10)"
   ],
   "id": "e32ab34c87baa12c",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:54:05.559596Z",
     "start_time": "2024-10-13T14:54:05.550135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    'LDA': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'iterations': [500, 1000],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'CTM': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [5, 10],\n",
    "    },\n",
    "    'ETM': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [50, 100],\n",
    "    },\n",
    "    'NeuralLDA': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'num_epochs': [50, 100],\n",
    "        'lr': [2e-3, 1e-3],\n",
    "    },\n",
    "    'NMF': {\n",
    "        'num_topics': [2, 3, 4, 5],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "def evaluate_coherence(model_output):\n",
    "    # Initialize the coherence metric\n",
    "    coherence_cv = Coherence(topk=10, measure='c_v')\n",
    "\n",
    "    # Calculate and return coherence score\n",
    "    coherence_score = coherence_cv.score(model_output)\n",
    "    return coherence_score\n",
    "\n",
    "def parameter_search(model_name, dataset, param_grid):\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_score = -float('inf')\n",
    "    best_params = None\n",
    "    best_model_output = None\n",
    "\n",
    "    # Use tqdm to track progress in parameter search\n",
    "    for params in tqdm(param_combinations, desc=f\"Searching {model_name} Params\"):\n",
    "        # Create parameter dict\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "\n",
    "        # Initialize and train the model based on model name and params\n",
    "        if model_name == 'LDA':\n",
    "            model = LDA(**param_dict)\n",
    "        elif model_name == 'CTM':\n",
    "            model = CTM(**param_dict)\n",
    "        elif model_name == 'ETM':\n",
    "            model = ETM(**param_dict)\n",
    "        elif model_name == 'NeuralLDA':\n",
    "            model = NeuralLDA(**param_dict)\n",
    "        elif model_name == 'NMF':\n",
    "            model = NMF(**param_dict)\n",
    "\n",
    "        # Train the model\n",
    "        model_output = model.train_model(dataset)\n",
    "\n",
    "        # Evaluate the model (e.g., using coherence score)\n",
    "        score = evaluate_coherence(model_output)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = param_dict\n",
    "            best_model_output = model_output\n",
    "\n",
    "    return best_model_output, best_params, best_score"
   ],
   "id": "cc12e975684d3e24",
   "execution_count": 84,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:56:38.873498Z",
     "start_time": "2024-10-13T14:54:06.426308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_models = {}\n",
    "\n",
    "# Perform hyperparameter search for each model with progress bars\n",
    "for model_name, param_grid in tqdm(param_grids.items(), desc=\"Overall Model Parameter Search\"):\n",
    "    best_output, best_params, best_score = parameter_search(model_name, dataset, param_grid)\n",
    "    best_models[model_name] = {'output': best_output, 'params': best_params, 'score': best_score}\n",
    "    print(f\"Best {model_name} Params: {best_params} with Score: {best_score}\")"
   ],
   "id": "1f6c5676c3834fef",
   "execution_count": 85,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:56:56.016330Z",
     "start_time": "2024-10-13T14:56:56.007705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Summarize results\n",
    "import pandas as pd\n",
    "\n",
    "summary = []\n",
    "for model_name, model_info in best_models.items():\n",
    "    summary.append({\n",
    "        'Model': model_name,\n",
    "        'Best_Params': model_info['params'],\n",
    "        'Best_Score': model_info['score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df)"
   ],
   "id": "8305f9444374804e",
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T14:59:53.072946Z",
     "start_time": "2024-10-13T14:59:53.065946Z"
    }
   },
   "cell_type": "code",
   "source": "best_models['LDA']",
   "id": "de60ceeb19d39127",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:00:09.616488Z",
     "start_time": "2024-10-13T15:00:09.610658Z"
    }
   },
   "cell_type": "code",
   "source": "best_models['CTM']",
   "id": "e454f82503bd1f99",
   "execution_count": 96,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "52a4951d01d4e1b8",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
