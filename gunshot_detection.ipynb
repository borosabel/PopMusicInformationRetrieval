{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T16:20:15.131658Z",
     "start_time": "2024-10-12T16:20:15.126821Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create monkey patches\n",
    "np.float = float\n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:20:15.269752Z",
     "start_time": "2024-10-12T16:20:15.262408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gunshot_utils as utils\n",
    "import importlib\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "importlib.reload(utils)"
   ],
   "id": "30ec1e4f3c907ee3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gunshot_utils' from '/Users/borosabel/Documents/Uni/Thesis/PopMusicInformationRetrieval/gunshot_utils.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:14:33.800023Z",
     "start_time": "2024-10-12T16:14:33.787953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gunshot_df = pd.read_csv('./filtered_gunshot_metadata_glocks.csv')\n",
    "gunshot_df = gunshot_df[['filename', 'gunshot_location_in_seconds', 'num_gunshots']]\n",
    "gunshot_df.head()"
   ],
   "id": "248141f128afd6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filename  \\\n",
       "0  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "1  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "2  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "3  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "4  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...   \n",
       "\n",
       "          gunshot_location_in_seconds  num_gunshots  \n",
       "0                        [1.72269841]             1  \n",
       "1                        [1.67290249]             1  \n",
       "2  [1.61977324 3.50795918 5.42746032]             3  \n",
       "3  [1.75       1.98768707 2.26022676]             3  \n",
       "4  [1.75       2.61845805 3.06664399]             3  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gunshot_location_in_seconds</th>\n",
       "      <th>num_gunshots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>[1.72269841]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>[1.67290249]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>[1.61977324 3.50795918 5.42746032]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>[1.75       1.98768707 2.26022676]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>[1.75       2.61845805 3.06664399]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:13:32.201468Z",
     "start_time": "2024-10-12T16:13:28.636787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_df = pd.read_excel('/Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Excel/baseline_data_w_topics_w_features.xlsx', engine='openpyxl')\n",
    "music_df = music_df[['Path', 'Sample Rate (Hz)']]\n",
    "music_df.head()"
   ],
   "id": "ef62985a0a1d1027",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                Path  Sample Rate (Hz)\n",
       "0  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...             48000\n",
       "1  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...             48000\n",
       "2  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...             48000\n",
       "3  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...             48000\n",
       "4  /Users/borosabel/Documents/Uni/Thesis/PopMIR/D...             48000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sample Rate (Hz)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/borosabel/Documents/Uni/Thesis/PopMIR/D...</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:13:32.208264Z",
     "start_time": "2024-10-12T16:13:32.203605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "music_train_df, music_valid_df = train_test_split(music_df, test_size=0.2, random_state=42)\n",
    "gunshot_train_df, gunshot_valid_df = train_test_split(gunshot_df, test_size=0.2, random_state=42)"
   ],
   "id": "85913fb23cc8e10d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:13:32.237115Z",
     "start_time": "2024-10-12T16:13:32.210414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GunshotDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_frames):\n",
    "        super(GunshotDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "\n",
    "        dummy_input = th.zeros(1, 3, 80, num_frames) \n",
    "        dummy_output = self.pool2(F.relu(self.conv2(self.pool1(F.relu(self.conv1(dummy_input))))))\n",
    "        output_size = dummy_output.view(-1).shape[0]\n",
    "\n",
    "        self.fc1 = nn.Linear(output_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = GunshotDetectionCNN(num_frames=utils.NUM_FRAMES)"
   ],
   "id": "375039e3f516b75b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:13:32.273707Z",
     "start_time": "2024-10-12T16:13:32.264742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GunshotDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, music_df, gunshot_df, excerpt_len=5.0, gunshot_placement_sec=2.0, gunshot_prob=1.0, min_db=3, max_db=5, max_non_gunshot_samples=1, mean=None, std=None):\n",
    "        \"\"\"\n",
    "        :param music_df: DataFrame containing paths to music files.\n",
    "        :param gunshot_df: DataFrame containing paths to gunshot files and timing info.\n",
    "        :param excerpt_len: Length of the music segment in seconds.\n",
    "        :param gunshot_placement_sec: Time in seconds where to place the gunshot in the music.\n",
    "        :param gunshot_prob: Probability of adding a gunshot to the segment.\n",
    "        :param min_db: Minimum gain (in dB) to apply to the gunshot.\n",
    "        :param max_db: Maximum gain (in dB) to apply to the gunshot.\n",
    "        :param max_non_gunshot_samples: Max number of non-gunshot samples to extract when no gunshots are present.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.music_paths = music_df['Path'].tolist()\n",
    "        self.gunshot_paths = gunshot_df['filename'].tolist()\n",
    "        self.gunshot_truth = gunshot_df['gunshot_location_in_seconds'].apply(\n",
    "            lambda x: utils.preprocess_gunshot_times(x, include_first_gunshot_only=True)\n",
    "        ).tolist()\n",
    "        self.excerpt_len = excerpt_len\n",
    "        self.gunshot_placement_sec = gunshot_placement_sec\n",
    "        self.gunshot_prob = gunshot_prob\n",
    "        self.min_db = min_db\n",
    "        self.max_db = max_db\n",
    "        self.max_non_gunshot_samples = max_non_gunshot_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn_music = self.music_paths[idx]\n",
    "        print(f\"Music: {fn_music}\")\n",
    "        add_gunshot = (np.random.rand() < self.gunshot_prob)\n",
    "        print(f\"Should add gunshot on the music excerpt? {'yes' if add_gunshot else 'no'}\")\n",
    "        sample_rate = 44100\n",
    "\n",
    "        if add_gunshot:\n",
    "            gunshot_idx = np.random.randint(0, len(self.gunshot_paths) - 1)\n",
    "            fn_gunshot = self.gunshot_paths[gunshot_idx]\n",
    "            print(f\"Gunshot path: {fn_gunshot}\")\n",
    "            gunshot_times = self.gunshot_truth[gunshot_idx][0]\n",
    "            \n",
    "            music_segment, sr = utils.combine_music_and_gunshot(\n",
    "                music_file=fn_music,\n",
    "                gunshot_file=fn_gunshot,\n",
    "                gunshot_time=gunshot_times,\n",
    "                gunshot_volume_increase_dB=self.max_db,\n",
    "                gunshot_placement_sec=self.gunshot_placement_sec,\n",
    "                excerpt_len_sec=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 1\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label, gunshot_times)\n",
    "        else:\n",
    "            # Extract a segment of music without gunshots\n",
    "            music_segment, sr = utils.extract_music_segment(\n",
    "                music_file=fn_music,\n",
    "                excerpt_len=self.excerpt_len,\n",
    "                sample_rate=utils.SAMPLING_RATE\n",
    "            )\n",
    "            label = 0\n",
    "            spectrograms, labels = utils.preprocess_audio_train(music_segment, sr, label)\n",
    "\n",
    "        if not spectrograms or not labels:\n",
    "            raise ValueError(\"Spectrograms or labels are empty after preprocessing\")\n",
    "\n",
    "        return spectrograms[0], labels[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.music_paths)"
   ],
   "id": "18971f1c1625f911",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:18:33.417092Z",
     "start_time": "2024-10-12T16:18:33.407962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = GunshotDataset(music_train_df, gunshot_train_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=1)\n",
    "valid_dataset = GunshotDataset(music_valid_df, gunshot_valid_df, excerpt_len=5.0, gunshot_placement_sec=2.0, min_db=5, max_db=10, gunshot_prob=0.5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "897cc837ed645e36",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T16:20:19.012625Z",
     "start_time": "2024-10-12T16:20:18.682668Z"
    }
   },
   "cell_type": "code",
   "source": "spectogram, label = train_dataset[0]",
   "id": "23d7e367e823522",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music: /Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/west_coast/Pac/All Eyez On Me/2Pac - How Do You Want It (feat. JoJo & K-Ci).mp3\n",
      "Should add gunshot on the music excerpt? yes\n",
      "Gunshot path: /Users/borosabel/Documents/Uni/Thesis/PopMIR/Data/Audio/Gunshots/csv/edge-collected-gunshot-audio/edge-collected-gunshot-audio/glock_17_9mm(231).wav\n",
      "Resampling music from 48000 Hz to 44100 Hz.\n",
      "Extracted a 5.0 seconds music excerpt for processing.\n",
      "Loading the gunshot file...\n",
      "Applying a 10 dB volume increase to the gunshot.\n",
      "Combining the music and gunshot. The gunshot will be placed at 2.0 seconds.\n",
      "------PREPROCESSING AUDIO DATA------\n",
      "Waveform shape:  torch.Size([2, 220500])\n",
      "Sampling rate:  44100\n",
      "------SELECTING GUNSHOT SEGMENT WITH FRAME SIZE OF 43520------\n",
      "------SELECTING GUNSHOT SEGMENT------\n",
      "Segment shape after cutting 43520 size: torch.Size([2, 43520])\n",
      "MEL SPECTOGRAM shape of the segment torch.Size([3, 81, 86])\n",
      "------PREPROCESSING AUDIO DATA------\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2aac1047af50e6af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
